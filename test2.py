# 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
# ----------------------
import subprocess
import sys


# ----------------------
# 2. –ò–º–ø–æ—Ä—Ç—ã –∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
# ----------------------
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import json
from openai import AsyncOpenAI
import asyncio
import numpy as np
import os

### –ù–û–í–û–ï: –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Supabase
from supabase import create_client, Client

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è API DeepSeek
DEESEEK_API_URL = "https://api.studio.nebius.ai/v1/"

# ----------------------
# 3. –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
# ----------------------
@st.cache_data
def load_data(file_path: str) -> pd.DataFrame:
    df = pd.read_excel(file_path)
    # –ü—Ä–∏–≤–æ–¥–∏–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –∏ —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã
    df.columns = [str(col).strip().lower() if isinstance(col, str) else col for col in df.columns]
    if 'data' in df.columns:
        df['data'] = pd.to_datetime(df['data'], errors='coerce')
    return df

# ----------------------
# 4. –ë–õ–û–ö –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ö–ò –¢–ï–ö–°–¢–ê (NLP) - –£–î–ê–õ–ï–ù
# ----------------------

# ----------------------
# 5. DeepSeek API –∞–Ω–∞–ª–∏–∑ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
# ----------------------
async def analyze_reflection_with_deepseek(client: AsyncOpenAI, text: str) -> dict:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏ —Å –ø–æ–º–æ—â—å—é DeepSeek API.
    """
    error_result = {
        "sentiment_score": 0.0,
        "learning_feedback": "N/A",
        "teamwork_feedback": "N/A",
        "organization_feedback": "N/A",
        "learning_sentiment_score": 0.0,
        "teamwork_sentiment_score": 0.0,
        "organization_sentiment_score": 0.0,
    }
    if not text or not isinstance(text, str) or not text.strip():
        return error_result

    prompt = (
        "–¢—ã ‚Äî –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–æ–≤ —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–µ—Ñ–ª–µ–∫—Å–∏—é —à–∫–æ–ª—å–Ω–∏–∫–∞. "
        "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –≤–µ—Ä–Ω—É—Ç—å JSON-–æ–±—ä–µ–∫—Ç —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –∫–ª—é—á–∞–º–∏:\n"
        "1. 'sentiment_score': –æ–±—â–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞, —á–∏—Å–ª–æ –æ—Ç -1.0 (–Ω–µ–≥–∞—Ç–∏–≤) –¥–æ 1.0 (–ø–æ–∑–∏—Ç–∏–≤).\n"
        "2. 'learning_feedback': –∫—Ä–∞—Ç–∫–∞—è –≤—ã–∂–∏–º–∫–∞ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –∏–∑ —Ç–µ–∫—Å—Ç–∞ –æ–± –æ—Ü–µ–Ω–∫–µ —É—á–µ–±–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞.\n"
        "3. 'teamwork_feedback': –∫—Ä–∞—Ç–∫–∞—è –≤—ã–∂–∏–º–∫–∞ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –æ–± –æ—Ü–µ–Ω–∫–µ —Ä–∞–±–æ—Ç—ã –≤ –∫–æ–º–∞–Ω–¥–µ.\n"
        "4. 'organization_feedback': –∫—Ä–∞—Ç–∫–∞—è –≤—ã–∂–∏–º–∫–∞ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –æ–± –æ—Ü–µ–Ω–∫–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∏ –¥–æ—Å—É–≥–æ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤.\n"
        "5. 'learning_sentiment_score': —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –¢–û–õ–¨–ö–û —á–∞—Å—Ç–∏ –ø—Ä–æ —É—á—ë–±—É (–æ—Ç -1.0 –¥–æ 1.0). –ï—Å–ª–∏ –Ω–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è, –≤–µ—Ä–Ω–∏ 0.0.\n"
        "6. 'teamwork_sentiment_score': —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –¢–û–õ–¨–ö–û —á–∞—Å—Ç–∏ –ø—Ä–æ –∫–æ–º–∞–Ω–¥—É (–æ—Ç -1.0 –¥–æ 1.0). –ï—Å–ª–∏ –Ω–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è, –≤–µ—Ä–Ω–∏ 0.0.\n"
        "7. 'organization_sentiment_score': —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –¢–û–õ–¨–ö–û —á–∞—Å—Ç–∏ –ø—Ä–æ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é (–æ—Ç -1.0 –¥–æ 1.0). –ï—Å–ª–∏ –Ω–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è, –≤–µ—Ä–Ω–∏ 0.0.\n\n"
        "–ï—Å–ª–∏ –∫–∞–∫–æ–π-—Ç–æ –∞—Å–ø–µ–∫—Ç –≤ —Ç–µ–∫—Å—Ç–µ –Ω–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è, –¥–ª—è –∫–ª—é—á–µ–π feedback –æ—Å—Ç–∞–≤—å –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É, –∞ –¥–ª—è –∫–ª—é—á–µ–π sentiment_score –≤–µ—Ä–Ω–∏ 0.0.\n\n"
        f"–¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: \"{text}\""
    )

    try:
        response = await client.chat.completions.create(
            model="deepseek-ai/DeepSeek-V3",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            response_format={"type": "json_object"}
        )
        content = response.choices[0].message.content
        result = json.loads(content)
        for key, value in error_result.items():
            if key not in result:
                result[key] = value
        return result

    except Exception as e:
        print(f"Error processing text: '{text[:50]}...'. Error: {e}")
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ DeepSeek API: {e}")
        return error_result

# ----------------------
# 6. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
# ----------------------
def convert_sentiment_to_10_point(score: float) -> float:
    if not isinstance(score, (int, float)):
        return 5.5
    return (score + 1) * 4.5 + 1

# ----------------------
# 7. –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Supabase
# ----------------------

@st.cache_resource
def init_supabase_client():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–ª–∏–µ–Ω—Ç Supabase."""
    try:
        supabase_url = st.secrets["SUPABASE_URL"]
        supabase_key = st.secrets["SUPABASE_KEY"]
        return create_client(supabase_url, supabase_key)
    except KeyError as e:
        st.error(f"–û—à–∏–±–∫–∞: –∫–ª—é—á '{e.args[0]}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Å–µ–∫—Ä–µ—Ç–∞—Ö Streamlit. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–æ–±–∞–≤—å—Ç–µ –µ–≥–æ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.")
        return None
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Supabase: {e}")
        return None

@st.cache_data(ttl=300)
def get_report_list_from_supabase(_supabase: Client) -> list:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–º–µ–Ω –æ—Ç—á–µ—Ç–æ–≤ –∏–∑ Supabase."""
    try:
        response = _supabase.table('reports').select('report_name', count='exact').execute()
        if response.data:
            unique_names = sorted(list(set(item['report_name'] for item in response.data)), reverse=True)
            return unique_names
        return []
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –æ—Ç—á–µ—Ç–æ–≤ –∏–∑ Supabase: {e}")
        return []

@st.cache_data
def load_report_from_supabase(_supabase: Client, report_name: str) -> pd.DataFrame:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –∏–∑ Supabase –≤ DataFrame."""
    try:
        response = _supabase.table('reports').select('*').eq('report_name', report_name).execute()
        df = pd.DataFrame(response.data)
        if 'data' in df.columns:
            df['data'] = pd.to_datetime(df['data'], errors='coerce')
        if not df.empty:
            df = df.drop(columns=['id', 'created_at', 'report_name'], errors='ignore')
        return df
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –æ—Ç—á–µ—Ç–∞ '{report_name}': {e}")
        return pd.DataFrame()


# ----------------------
# 8. –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –∏ –¥–∞—à–±–æ—Ä–¥ –Ω–∞ Streamlit
# ----------------------
def main():
    st.set_page_config(layout="wide")
    st.title("–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –¥–∞—à–±–æ—Ä–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π —É—á–∞—â–∏—Ö—Å—è")

    with st.expander("‚ÑπÔ∏è –û –ø—Ä–æ–µ–∫—Ç–µ: —á—Ç–æ —ç—Ç–æ –∏ –∫–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è?", expanded=False):
        st.markdown("""
        **–¶–µ–ª—å –¥–∞—à–±–æ—Ä–¥–∞** ‚Äî –ø–æ–º–æ—á—å –ø–µ–¥–∞–≥–æ–≥–∞–º –∏ –∫—É—Ä–∞—Ç–æ—Ä–∞–º –±—ã—Å—Ç—Ä–æ –æ—Ü–µ–Ω–∏—Ç—å —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≥—Ä—É–ø–ø—ã, –≤—ã—è–≤–∏—Ç—å –æ–±—â–∏–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏ –∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —É—á–∞—â–∏—Ö—Å—è, —Ç—Ä–µ–±—É—é—â–∏—Ö –æ—Å–æ–±–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è, –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Ö –ø–∏—Å—å–º–µ–Ω–Ω—ã—Ö —Ä–µ—Ñ–ª–µ–∫—Å–∏–π.

        **–ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç?**
        1.  –î–ª—è **–Ω–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞** –∑–∞–≥—Ä—É–∑–∏—Ç–µ Excel-—Ñ–∞–π–ª —Å —Ç–µ–∫—Å—Ç–∞–º–∏ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π.
        2.  –ß—Ç–æ–±—ã –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å **—Å—Ç–∞—Ä—ã–π –æ—Ç—á–µ—Ç**, –≤—ã–±–µ—Ä–∏—Ç–µ –µ–≥–æ –∏–∑ –≤—ã–ø–∞–¥–∞—é—â–µ–≥–æ —Å–ø–∏—Å–∫–∞. –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∑—è—Ç—Å—è –∏–∑ –æ–±–ª–∞—á–Ω–æ–≥–æ –∞—Ä—Ö–∏–≤–∞.
        3.  –ü—Ä–∏ –Ω–æ–≤–æ–º –∞–Ω–∞–ª–∏–∑–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç (DeepSeek) –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞–∂–¥—ã–π —Ç–µ–∫—Å—Ç.
        4.  –ü–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞ –≤—ã –º–æ–∂–µ—Ç–µ **—Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –∞—Ä—Ö–∏–≤**, –Ω–∞–∂–∞–≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –∫–Ω–æ–ø–∫—É. –û—Ç—á–µ—Ç —Å—Ç–∞–Ω–µ—Ç –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –≤—ã–±–æ—Ä–∞ –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º –∑–∞–ø—É—Å–∫–µ.
        """)

    supabase = init_supabase_client()
    if not supabase:
        st.stop()

    st.sidebar.header("üóÇÔ∏è –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö")
    report_files = get_report_list_from_supabase(supabase)
    data_source_options = ["–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑"] + report_files
    selected_source = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –æ—Ç—á–µ—Ç –∏–∑ –∞—Ä—Ö–∏–≤–∞ –∏–ª–∏ –Ω–∞—á–Ω–∏—Ç–µ –Ω–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑:", data_source_options)

    df = None
    uploaded_file = None

    if selected_source != "–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑":
        st.sidebar.success(f"–ó–∞–≥—Ä—É–∂–µ–Ω –æ—Ç—á–µ—Ç –∏–∑ –∞—Ä—Ö–∏–≤–∞: {selected_source}")
        df = load_report_from_supabase(supabase, selected_source)
        st.session_state['current_file_name'] = selected_source
    else:
        st.sidebar.header("üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–ª—è –Ω–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
        uploaded_file = st.sidebar.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel-—Ñ–∞–π–ª —Å —Ä–µ—Ñ–ª–µ–∫—Å–∏—è–º–∏", type="xlsx")
        if uploaded_file:
            st.session_state['current_file_name'] = uploaded_file.name
            df = load_data(uploaded_file)
            df['text'] = df['text'].astype(str).fillna('')

    if df is None:
        st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –Ω–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –≥–æ—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏.")
        return

    client = None
    if selected_source == "–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑":
        try:
            api_key = st.secrets["DEEPSEEK_API_KEY"]
            client = AsyncOpenAI(base_url=DEESEEK_API_URL, api_key=api_key)
        except KeyError:
            st.sidebar.error("API-–∫–ª—é—á DeepSeek –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.")
            st.error("–û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á `DEEPSEEK_API_KEY`. "
                     "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–æ–±–∞–≤—å—Ç–µ –µ–≥–æ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–µ–∫—Ä–µ—Ç–æ–≤ –≤ Streamlit Cloud.")
            st.stop()

    session_key = f"df_processed_{st.session_state.get('current_file_name', 'default')}"

    if session_key not in st.session_state:
        if selected_source == "–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑" and client:
            with st.spinner('–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∞–Ω–∞–ª–∏–∑ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π... –≠—Ç–æ –∑–∞–π–º–µ—Ç –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è.'):
                tasks = [analyze_reflection_with_deepseek(client, text) for text in df['text']]
                async def gather_tasks():
                    return await asyncio.gather(*tasks)
                results = asyncio.run(gather_tasks())
                results_df = pd.DataFrame(results)
                df = pd.concat([df.reset_index(drop=True), results_df.reset_index(drop=True)], axis=1)
        
        for col in ['sentiment_score', 'learning_sentiment_score', 'teamwork_sentiment_score', 'organization_sentiment_score']:
            if col in df.columns:
                 df[col.replace('_score', '_10_point')] = df[col].apply(convert_sentiment_to_10_point)
        
        st.session_state[session_key] = df
    else:
        df = st.session_state[session_key]

    if selected_source == "–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑" and uploaded_file:
        st.sidebar.header("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ")
        if st.sidebar.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –∞—Ä—Ö–∏–≤"):
            with st.spinner("–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –≤ –æ–±–ª–∞–∫–æ..."):
                timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M")
                base_filename = os.path.splitext(uploaded_file.name)[0]
                report_filename = f"{base_filename}_processed_{timestamp}"
                
                processed_df_to_save = st.session_state[session_key].copy()
                processed_df_to_save['report_name'] = report_filename

                # --- –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –û–®–ò–ë–ö–ò JSON SERIALIZABLE ---
                # 1. –Ø–≤–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–æ–ª–æ–Ω–∫—É —Å –¥–∞—Ç–æ–π –≤ —Å—Ç—Ä–æ–∫—É —Ñ–æ—Ä–º–∞—Ç–∞ ISO
                if 'data' in processed_df_to_save.columns:
                    processed_df_to_save['data'] = pd.to_datetime(processed_df_to_save['data']).dt.strftime('%Y-%m-%dT%H:%M:%S')

                # 2. –ó–∞–º–µ–Ω—è–µ–º –≤—Å–µ "–ø—É—Å—Ç—ã–µ" –∑–Ω–∞—á–µ–Ω–∏—è Python (NaN, NaT) –Ω–∞ None (—ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç NULL –≤ –±–∞–∑–∞—Ö –¥–∞–Ω–Ω—ã—Ö)
                df_for_upload = processed_df_to_save.replace({pd.NaT: None, np.nan: None})
                
                # 3. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
                data_to_upload = df_for_upload.to_dict(orient='records')
                # -----------------------------------------------
                
                try:
                    supabase.table('reports').insert(data_to_upload).execute()
                    st.sidebar.success(f"–ê–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫:\n**{report_filename}**")
                    st.cache_data.clear()
                    st.rerun()
                except Exception as e:
                    st.sidebar.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ Supabase: {e}")

    if df.empty:
        st.error("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏–∑–º–µ–Ω–∏—Ç–µ —Ñ–∏–ª—å—Ç—Ä—ã –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª.")
        return
        
    filtered_df = df.copy()

    st.sidebar.header("üìä –§–∏–ª—å—Ç—Ä—ã")
    if 'data' in filtered_df.columns and not filtered_df['data'].dropna().empty:
        min_date = filtered_df['data'].min().date()
        max_date = filtered_df['data'].max().date()
        if min_date != max_date:
            date_range = st.sidebar.slider(
                "–í—ã–±–µ—Ä–∏—Ç–µ –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç:",
                min_value=min_date, max_value=max_date,
                value=(min_date, max_date), format="DD.MM.YYYY"
            )
            start_date, end_date = date_range
            mask = (filtered_df['data'].dt.date >= start_date) & (filtered_df['data'].dt.date <= end_date)
            filtered_df = filtered_df.loc[mask]
        else:
             st.sidebar.info("–í –¥–∞–Ω–Ω—ã—Ö —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –¥–µ–Ω—å, —Ñ–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ –Ω–µ–∞–∫—Ç–∏–≤–µ–Ω.")
    else:
        st.sidebar.warning("–í —Ñ–∞–π–ª–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞—Ç—ã –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.")

    if filtered_df.empty:
        st.error("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º.")
        return

    # --- –î–∞–ª—å–Ω–µ–π—à–∏–π –∫–æ–¥ –¥–∞—à–±–æ—Ä–¥–∞ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π ---

    st.header("–û–±—â–∞—è –¥–∏–Ω–∞–º–∏–∫–∞ –∏ –≥—Ä—É–ø–ø–æ–≤–æ–π –∞–Ω–∞–ª–∏–∑")
    daily_groups = filtered_df.groupby(filtered_df['data'].dt.date)
    daily_df = daily_groups.agg(
        avg_emotion=('emotion', np.mean),
        avg_sentiment_10_point=('sentiment_10_point', np.mean),
        avg_learning_sentiment=('learning_sentiment_10_point', np.mean),
        avg_teamwork_sentiment=('teamwork_sentiment_10_point', np.mean),
        avg_organization_sentiment=('organization_sentiment_10_point', np.mean)
    ).reset_index()
    daily_df.rename(columns={'data': '–î–∞—Ç–∞'}, inplace=True)

    if not daily_df.empty:
        daily_df.sort_values('–î–∞—Ç–∞', inplace=True)
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("–û–±—â–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å vs. –°–∞–º–æ–æ—Ü–µ–Ω–∫–∞")
            fig = px.line(
                daily_df, x='–î–∞—Ç–∞', y=['avg_sentiment_10_point', 'avg_emotion'],
                labels={'value': '–û—Ü–µ–Ω–∫–∞ (1-10)', 'variable': '–ú–µ—Ç—Ä–∏–∫–∞'},
                title='–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∏ —Å–∞–º–æ–æ—Ü–µ–Ω–∫–∏'
            )
            st.plotly_chart(fig, use_container_width=True)
        with col2:
            st.subheader("–î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –ø–æ –∞—Å–ø–µ–∫—Ç–∞–º")
            fig_details = px.line(
                daily_df, x='–î–∞—Ç–∞', y=['avg_learning_sentiment', 'avg_teamwork_sentiment', 'avg_organization_sentiment'],
                labels={'value': '–û—Ü–µ–Ω–∫–∞ (1-10)', 'variable': '–ê—Å–ø–µ–∫—Ç'},
                title='–î–∏–Ω–∞–º–∏–∫–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –ø–æ –∞—Å–ø–µ–∫—Ç–∞–º'
            )
            new_names = {'avg_learning_sentiment': '–£—á—ë–±–∞', 'avg_teamwork_sentiment': '–ö–æ–º–∞–Ω–¥–∞', 'avg_organization_sentiment': '–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è'}
            fig_details.for_each_trace(lambda t: t.update(name = new_names.get(t.name, t.name)))
            st.plotly_chart(fig_details, use_container_width=True)

    st.subheader("–¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –≥—Ä—É–ø–ø—ã")
    heatmap_data = filtered_df.pivot_table(
        index='username',
        columns=filtered_df['data'].dt.date,
        values='sentiment_10_point',
        aggfunc='mean'
    )
    if not heatmap_data.empty:
        fig_heatmap = px.imshow(
            heatmap_data,
            labels=dict(x="–î–∞—Ç–∞", y="–£—á–µ–Ω–∏–∫", color="–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å"),
            title="–û–±—â–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å (1-10) –ø–æ –¥–Ω—è–º –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É—á–µ–Ω–∏–∫–∞",
            color_continuous_scale='RdYlGn',
            aspect="auto"
        )
        st.plotly_chart(fig_heatmap, use_container_width=True)
    else:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã.")

    st.header("–ê–Ω–∞–ª–∏–∑ –ø–æ –æ—Ç–¥–µ–ª—å–Ω—ã–º —É—á–∞—â–∏–º—Å—è")
    student_list = sorted(filtered_df['username'].unique())
    if student_list:
        student = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —É—á–µ–Ω–∏–∫–∞:", student_list)
        if student:
            student_df = filtered_df[filtered_df['username'] == student].sort_values('data')
            col1, col2 = st.columns([3, 2])
            with col1:
                st.subheader(f"–î–∏–Ω–∞–º–∏–∫–∞ –æ—Ü–µ–Ω–æ–∫ –¥–ª—è {student}")
                fig2 = px.line(
                    student_df, x='data', y=['sentiment_10_point', 'emotion'],
                    labels={'value': '–û—Ü–µ–Ω–∫–∞ (1-10)', 'data': '–î–∞—Ç–∞'},
                    title=f'–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å vs. –°–∞–º–æ–æ—Ü–µ–Ω–∫–∞'
                )
                st.plotly_chart(fig2, use_container_width=True)
            with col2:
                st.subheader(f"–ü—Ä–æ—Ñ–∏–ª—å —É—á–µ–Ω–∏–∫–∞")
                categories = ['–°–∞–º–æ–æ—Ü–µ–Ω–∫–∞', '–£—á—ë–±–∞', '–ö–æ–º–∞–Ω–¥–∞', '–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è']
                values = [
                    student_df['emotion'].mean(),
                    student_df['learning_sentiment_10_point'].mean(),
                    student_df['teamwork_sentiment_10_point'].mean(),
                    student_df['organization_sentiment_10_point'].mean()
                ]
                fig_radar = go.Figure()
                fig_radar.add_trace(go.Scatterpolar(r=values, theta=categories, fill='toself', name='–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞'))
                fig_radar.update_layout(
                    polar=dict(radialaxis=dict(visible=True, range=[1, 10])),
                    showlegend=False,
                    title=f"–°—Ä–µ–¥–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏ –¥–ª—è {student}",
                    margin=dict(l=40, r=40, t=80, b=40)
                )
                st.plotly_chart(fig_radar, use_container_width=True)

            st.subheader("–î–µ—Ç–∞–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π")
            with st.expander("–ü–æ–∫–∞–∑–∞—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤ —Ç–∞–±–ª–∏—Ü—ã"):
                st.markdown("""
                - **data**: –î–∞—Ç–∞ –Ω–∞–ø–∏—Å–∞–Ω–∏—è —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏.
                - **text**: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏.
                - **emotion**: –°–∞–º–æ–æ—Ü–µ–Ω–∫–∞ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è, –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–∞—è —É—á–µ–Ω–∏–∫–æ–º (–æ—Ç 1 –¥–æ 10).
                - **sentiment_10_point**: –û–±—â–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞, –æ—Ü–µ–Ω–µ–Ω–Ω–∞—è –ò–ò –∏ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–∞—è –≤ 10-–±–∞–ª–ª—å–Ω—É—é —à–∫–∞–ª—É.
                - **learning_sentiment_10_point**: –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —á–∞—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞, –∫–∞—Å–∞—é—â–µ–π—Å—è *—É—á–µ–±–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞* (1-10).
                - **teamwork_sentiment_10_point**: –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —á–∞—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞, –∫–∞—Å–∞—é—â–µ–π—Å—è *—Ä–∞–±–æ—Ç—ã –≤ –∫–æ–º–∞–Ω–¥–µ* (1-10).
                - **organization_sentiment_10_point**: –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —á–∞—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞, –∫–∞—Å–∞—é—â–µ–π—Å—è *–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏ –¥–æ—Å—É–≥–∞* (1-10).
                - **learning_feedback**: –ö—Ä–∞—Ç–∫–∞—è –≤—ã–∂–∏–º–∫–∞ –æ—Ç –ò–ò –ø–æ —É—á–µ–±–Ω–æ–º—É –ø—Ä–æ—Ü–µ—Å—Å—É.
                - **teamwork_feedback**: –ö—Ä–∞—Ç–∫–∞—è –≤—ã–∂–∏–º–∫–∞ –æ—Ç –ò–ò –ø–æ —Ä–∞–±–æ—Ç–µ –≤ –∫–æ–º–∞–Ω–¥–µ.
                - **organization_feedback**: –ö—Ä–∞—Ç–∫–∞—è –≤—ã–∂–∏–º–∫–∞ –æ—Ç –ò–ò –ø–æ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏ –¥–æ—Å—É–≥—É.
                """)
            display_columns = [
                'data', 'text', 'emotion', 'sentiment_10_point',
                'learning_sentiment_10_point', 'teamwork_sentiment_10_point', 'organization_sentiment_10_point',
                'learning_feedback', 'teamwork_feedback', 'organization_feedback'
            ]
            st.dataframe(student_df[[col for col in display_columns if col in student_df.columns]])

    if st.sidebar.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–ª–Ω—É—é —Ç–∞–±–ª–∏—Ü—É —Å –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏"):
        st.header("–ü–æ–ª–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –¥–∞–Ω–Ω—ã—Ö")
        st.dataframe(filtered_df)

    st.header("–ê–Ω–∞–ª–∏–∑ \"–ó–æ–Ω—ã —Ä–∏—Å–∫–∞\": —É—á–∞—Å—Ç–Ω–∏–∫–∏ —Å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–º—Å—è –Ω–µ–≥–∞—Ç–∏–≤–æ–º")
    if 'sentiment_score' in filtered_df.columns:
        negative_reflections = filtered_df[filtered_df['sentiment_score'] < 0]
        at_risk_users = pd.DataFrame(columns=['username', 'negative_count'])
        if not negative_reflections.empty:
            negative_counts = negative_reflections.groupby('username').size().reset_index(name='negative_count')
            at_risk_users = negative_counts[negative_counts['negative_count'] > 1].sort_values('negative_count', ascending=False)

        if not at_risk_users.empty:
            st.warning("–í–Ω–∏–º–∞–Ω–∏–µ! –í—ã—è–≤–ª–µ–Ω—ã —É—á–∞—Å—Ç–Ω–∏–∫–∏ —Å –º–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω–æ–π –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–π —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é –≤ —Ä–µ—Ñ–ª–µ–∫—Å–∏—è—Ö –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.")
            st.dataframe(at_risk_users)
        else:
            st.success("–ó–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –Ω–µ –≤—ã—è–≤–ª–µ–Ω–æ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤, —É –∫–æ—Ç–æ—Ä—ã—Ö —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Ä–µ—Ñ–ª–µ–∫—Å–∏–π –±—ã–ª–∞ –±—ã –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–π –±–æ–ª–µ–µ –æ–¥–Ω–æ–≥–æ —Ä–∞–∑–∞.")

if __name__ == "__main__":
    main()
