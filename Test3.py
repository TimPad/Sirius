
# 1. –ò–º–ø–æ—Ä—Ç—ã –∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
# ----------------------
import os
import json
import asyncio
from datetime import datetime
import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from openai import OpenAI

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
DEESEEK_API_URL = "https://api.studio.nebius.ai/v1/"
ARCHIVE_DIR = "archive"
os.makedirs(ARCHIVE_DIR, exist_ok=True)


# 2. –£—Ç–∏–ª–∏—Ç—ã
# ----------------------
@st.cache_data
def load_data(file_path: str) -> pd.DataFrame:
    df = pd.read_excel(file_path)
    df.columns = [str(c).strip().lower() for c in df.columns]
    if 'data' in df.columns:
        df['data'] = pd.to_datetime(df['data'], errors='coerce')
    df['text'] = df.get('text', '').astype(str).fillna('')
    return df

def convert_sentiment_to_10_point(score: float) -> float:
    if not isinstance(score, (int, float)):
        return 5.5
    return (score + 1) * 4.5 + 1

def analyze_reflection_with_deepseek(client: OpenAI, text: str) -> dict:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è-–æ–±—ë—Ä—Ç–∫–∞ –¥–ª—è DeepSeek."""
    base = {
        "sentiment_score": 0.0,
        "learning_feedback": "",
        "teamwork_feedback": "",
        "organization_feedback": "",
        "learning_sentiment_score": 0.0,
        "teamwork_sentiment_score": 0.0,
        "organization_sentiment_score": 0.0,
    }
    if not text.strip():
        return base
    prompt = (
        "–¢—ã ‚Äî –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–æ–≤ —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏. –í–µ—Ä–Ω–∏ JSON:\n"
        "‚Ä¶–∫–ª—é—á–∏ –∫–∞–∫ –≤ –±–∞–∑–æ–≤–æ–º —Å–ª–æ–≤–∞—Ä–µ‚Ä¶\n"
        f"–¢–µ–∫—Å—Ç: \"{text}\""
    )
    try:
        resp = client.chat.completions.create(
            model="deepseek-ai/DeepSeek-V3",
            messages=[{"role":"user","content":prompt}],
            temperature=0.2,
            response_format={"type":"json_object"}
        )
        result = json.loads(resp.choices[0].message.content)
        for k,v in base.items():
            result.setdefault(k, v)
        return result
    except Exception:
        return base

async def analyze_async(client: OpenAI, texts: list[str]) -> pd.DataFrame:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –∑–∞–ø—É—Å–∫–∞–µ—Ç –∞–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö —Ç–µ–∫—Å—Ç–æ–≤ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç DataFrame."""
    loop = asyncio.get_event_loop()
    tasks = [
        loop.run_in_executor(None, analyze_reflection_with_deepseek, client, t)
        for t in texts
    ]
    results = await asyncio.gather(*tasks)
    return pd.DataFrame(results)


# 3. –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
# ----------------------
def main():
    st.set_page_config(layout="wide")
    st.title("–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –¥–∞—à–±–æ—Ä–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π")

    # --- Sidebar: –≤—ã–±–æ—Ä –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –∏ –∑–∞–ø—É—Å–∫ ---
    with st.sidebar.form("data_form"):
        st.header("üóÇ –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö")
        archive_files = sorted([f for f in os.listdir(ARCHIVE_DIR) if f.endswith('.csv')], reverse=True)
        choice = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ –∏–ª–∏ –Ω–æ–≤—ã–π:", ["–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑"] + archive_files)
        if choice == "–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑":
            upload = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç—å Excel (.xlsx)", type="xlsx")
            api_key = st.text_input("API-–∫–ª—é—á DeepSeek", type="password")
        run_btn = st.form_submit_button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑")

    if not run_btn:
        st.info("–ó–∞–ø–æ–ª–Ω–∏—Ç–µ —Ñ–æ—Ä–º—É –∏ –Ω–∞–∂–º–∏—Ç–µ ¬´–ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑¬ª")
        return

    # --- –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ CSV ---
    if choice != "–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑":
        df = pd.read_csv(os.path.join(ARCHIVE_DIR, choice), parse_dates=['data'])
        current_name = choice
    else:
        df = load_data(upload)
        base_name = os.path.splitext(upload.name)[0]
        current_name = f"{base_name}_processed.csv"
        csv_path = os.path.join(ARCHIVE_DIR, current_name)
        if os.path.exists(csv_path):
            df = pd.read_csv(csv_path, parse_dates=['data'])
        else:
            # –Ω–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
            client = OpenAI(base_url=DEESEEK_API_URL, api_key=api_key)
            with st.spinner("–ò–¥—ë—Ç –∞–Ω–∞–ª–∏–∑..."):
                results_df = asyncio.run(analyze_async(client, df['text'].tolist()))
                df = pd.concat([df.reset_index(drop=True), results_df], axis=1)
                # –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
                for c in ['sentiment_score','learning_sentiment_score',
                          'teamwork_sentiment_score','organization_sentiment_score']:
                    df[c.replace('_score','_10_point')] = df[c].apply(convert_sentiment_to_10_point)
                df.to_csv(csv_path, index=False)
                st.success(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {current_name}")

    # --- –û—Å–Ω–æ–≤–Ω–æ–π dashboard ---
    st.sidebar.header("üìä –§–∏–ª—å—Ç—Ä—ã")
    if 'data' in df.columns and not df['data'].isna().all():
        min_d, max_d = df['data'].min().date(), df['data'].max().date()
        if min_d < max_d:
            start, end = st.sidebar.slider("–î–∞—Ç—ã", min_d, max_d, (min_d, max_d))
            mask = df['data'].dt.date.between(start, end)
            df = df[mask]
    if df.empty:
        st.error("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.")
        return

    # ... –∑–¥–µ—Å—å –≤—Å—Ç–∞–≤—å—Ç–µ –æ—Å—Ç–∞–≤—à—É—é—Å—è –ª–æ–≥–∏–∫—É –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π ...
    # (–≥—Ä–∞—Ñ–∏–∫–∏, —Ç–∞–±–ª–∏—Ü—ã, —Ç–µ–ø–ª–æ–≤—ã–µ –∫–∞—Ä—Ç—ã, —Ä–∞–¥–∞—Ä—ã –∏ —Ç.–¥.)
    st.write(df.head())

if __name__ == "__main__":
    main()
