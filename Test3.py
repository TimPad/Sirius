# filename: app.py

import os
import json
import asyncio
from datetime import datetime
import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from openai import OpenAI

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
DEESEEK_API_URL = "https://api.studio.nebius.ai/v1/"
ARCHIVE_DIR = "archive"
os.makedirs(ARCHIVE_DIR, exist_ok=True)


@st.cache_data
def load_data(file_path: str) -> pd.DataFrame:
    df = pd.read_excel(file_path)
    df.columns = [str(c).strip().lower() for c in df.columns]
    if 'data' in df.columns:
        df['data'] = pd.to_datetime(df['data'], errors='coerce')
    df['text'] = df.get('text', '').astype(str).fillna('')
    return df

def convert_sentiment_to_10_point(score: float) -> float:
    if not isinstance(score, (int, float)):
        return 5.5
    return (score + 1) * 4.5 + 1

def analyze_reflection_with_deepseek(client: OpenAI, text: str) -> dict:
    base = {
        "sentiment_score": 0.0,
        "learning_feedback": "",
        "teamwork_feedback": "",
        "organization_feedback": "",
        "learning_sentiment_score": 0.0,
        "teamwork_sentiment_score": 0.0,
        "organization_sentiment_score": 0.0,
    }
    if not text.strip():
        return base
    prompt = (
        "–¢—ã ‚Äî –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–æ–≤ —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏. –í–µ—Ä–Ω–∏ JSON:\n"
        "‚Ä¶–∫–ª—é—á–∏ –∫–∞–∫ –≤ –±–∞–∑–æ–≤–æ–º —Å–ª–æ–≤–∞—Ä–µ‚Ä¶\n"
        f"–¢–µ–∫—Å—Ç: \"{text}\""
    )
    try:
        resp = client.chat.completions.create(
            model="deepseek-ai/DeepSeek-V3",
            messages=[{"role":"user","content":prompt}],
            temperature=0.2,
            response_format={"type":"json_object"}
        )
        result = json.loads(resp.choices[0].message.content)
        for k,v in base.items():
            result.setdefault(k, v)
        return result
    except Exception:
        return base

async def analyze_async(client: OpenAI, texts: list[str]) -> pd.DataFrame:
    loop = asyncio.get_event_loop()
    tasks = [
        loop.run_in_executor(None, analyze_reflection_with_deepseek, client, t)
        for t in texts
    ]
    results = await asyncio.gather(*tasks)
    return pd.DataFrame(results)


def main():
    st.set_page_config(layout="wide")
    st.title("–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –¥–∞—à–±–æ—Ä–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π")

    with st.sidebar.form("data_form"):
        st.header("üóÇ –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö")
        archive_files = sorted([f for f in os.listdir(ARCHIVE_DIR) if f.endswith('.csv')], reverse=True)
        choice = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ –∏–ª–∏ –Ω–æ–≤—ã–π:", ["–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑"] + archive_files)
        if choice == "–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑":
            upload = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç—å Excel (.xlsx)", type="xlsx")
            api_key = st.text_input("API-–∫–ª—é—á DeepSeek", type="password")
        run_btn = st.form_submit_button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑")

    if not run_btn:
        st.info("–ó–∞–ø–æ–ª–Ω–∏—Ç–µ —Ñ–æ—Ä–º—É –∏ –Ω–∞–∂–º–∏—Ç–µ ¬´–ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑¬ª")
        return

    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–ª–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–µ —á—Ç–µ–Ω–∏–µ CSV
    if choice != "–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑":
        df = pd.read_csv(os.path.join(ARCHIVE_DIR, choice), parse_dates=['data'])
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏ –∫–æ–ª–æ–Ω–æ–∫
        df = df.loc[:, ~df.columns.duplicated()]
        current_name = choice

    else:
        df = load_data(upload)
        base_name = os.path.splitext(upload.name)[0]
        current_name = f"{base_name}_processed.csv"
        csv_path = os.path.join(ARCHIVE_DIR, current_name)

        if os.path.exists(csv_path):
            df = pd.read_csv(csv_path, parse_dates=['data'])
            df = df.loc[:, ~df.columns.duplicated()]
        else:
            client = OpenAI(base_url=DEESEEK_API_URL, api_key=api_key)
            with st.spinner("–ò–¥—ë—Ç –∞–Ω–∞–ª–∏–∑..."):
                results_df = asyncio.run(analyze_async(client, df['text'].tolist()))
                df = pd.concat([df.reset_index(drop=True), results_df.reset_index(drop=True)], axis=1)
                # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –¥—É–±–ª–∏ –ø–æ—Å–ª–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
                df = df.loc[:, ~df.columns.duplicated()]
                for c in ['sentiment_score','learning_sentiment_score',
                          'teamwork_sentiment_score','organization_sentiment_score']:
                    df[c.replace('_score','_10_point')] = df[c].apply(convert_sentiment_to_10_point)
                df.to_csv(csv_path, index=False)
                st.success(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {current_name}")

    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è
    st.sidebar.header("üìä –§–∏–ª—å—Ç—Ä—ã")
    if 'data' in df.columns and not df['data'].isna().all():
        min_d, max_d = df['data'].min().date(), df['data'].max().date()
        if min_d < max_d:
            start, end = st.sidebar.slider("–î–∞—Ç—ã", min_d, max_d, (min_d, max_d))
            mask = df['data'].dt.date.between(start, end)
            df = df[mask]

    if df.empty:
        st.error("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.")
        return

    # –ó–¥–µ—Å—å ‚Äî –æ—Å—Ç–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ (–≥—Ä–∞—Ñ–∏–∫–∏, —Ç–∞–±–ª–∏—Ü—ã –∏ —Ç.–¥.)
    st.dataframe(df.head())

if __name__ == "__main__":
    main()
