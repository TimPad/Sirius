# 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
# ----------------------
import subprocess
import sys


# ----------------------
# 2. –ò–º–ø–æ—Ä—Ç—ã –∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
# ----------------------
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import json
from openai import AsyncOpenAI
import asyncio
import numpy as np
import os

### –ù–û–í–û–ï: –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Supabase
from supabase import create_client, Client

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è API DeepSeek
DEESEEK_API_URL = "https://api.studio.nebius.ai/v1/"

# ----------------------
# 3. –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
# ----------------------
@st.cache_data
def load_data(file_path: str) -> pd.DataFrame:
    df = pd.read_excel(file_path)
    # –ü—Ä–∏–≤–æ–¥–∏–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –∏ —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã
    df.columns = [str(col).strip().lower() if isinstance(col, str) else col for col in df.columns]
    if 'data' in df.columns:
        df['data'] = pd.to_datetime(df['data'], errors='coerce')
    return df

# ----------------------
# 4. –ë–õ–û–ö –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ö–ò –¢–ï–ö–°–¢–ê (NLP) - –£–î–ê–õ–ï–ù
# ----------------------

# ----------------------
# 5. DeepSeek API –∞–Ω–∞–ª–∏–∑ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
# ----------------------
async def analyze_reflection_with_deepseek(client: AsyncOpenAI, text: str) -> dict:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏ —Å –ø–æ–º–æ—â—å—é DeepSeek API.
    """
    error_result = {
        "sentiment_score": 0.0,
        "learning_feedback": "N/A",
        "teamwork_feedback": "N/A",
        "organization_feedback": "N/A",
        "learning_sentiment_score": 0.0,
        "teamwork_sentiment_score": 0.0,
        "organization_sentiment_score": 0.0,
    }
    if not text or not isinstance(text, str) or not text.strip():
        return error_result

    prompt = (
        "–¢—ã ‚Äî –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–æ–≤ —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–µ—Ñ–ª–µ–∫—Å–∏—é —à–∫–æ–ª—å–Ω–∏–∫–∞. "
        "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –≤–µ—Ä–Ω—É—Ç—å JSON-–æ–±—ä–µ–∫—Ç —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –∫–ª—é—á–∞–º–∏:\n"
        "1. 'sentiment_score': –æ–±—â–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞, —á–∏—Å–ª–æ –æ—Ç -1.0 (–Ω–µ–≥–∞—Ç–∏–≤) –¥–æ 1.0 (–ø–æ–∑–∏—Ç–∏–≤).\n"
        "2. 'learning_feedback': –∫—Ä–∞—Ç–∫–∞—è –≤—ã–∂–∏–º–∫–∞ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –∏–∑ —Ç–µ–∫—Å—Ç–∞ –æ–± –æ—Ü–µ–Ω–∫–µ —É—á–µ–±–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞.\n"
        "3. 'teamwork_feedback': –∫—Ä–∞—Ç–∫–∞—è –≤—ã–∂–∏–º–∫–∞ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –æ–± –æ—Ü–µ–Ω–∫–µ —Ä–∞–±–æ—Ç—ã –≤ –∫–æ–º–∞–Ω–¥–µ.\n"
        "4. 'organization_feedback': –∫—Ä–∞—Ç–∫–∞—è –≤—ã–∂–∏–º–∫–∞ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –æ–± –æ—Ü–µ–Ω–∫–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∏ –¥–æ—Å—É–≥–æ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤.\n"
        "5. 'learning_sentiment_score': —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –¢–û–õ–¨–ö–û —á–∞—Å—Ç–∏ –ø—Ä–æ —É—á—ë–±—É (–æ—Ç -1.0 –¥–æ 1.0). –ï—Å–ª–∏ –Ω–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è, –≤–µ—Ä–Ω–∏ 0.0.\n"
        "6. 'teamwork_sentiment_score': —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –¢–û–õ–¨–ö–û —á–∞—Å—Ç–∏ –ø—Ä–æ –∫–æ–º–∞–Ω–¥—É (–æ—Ç -1.0 –¥–æ 1.0). –ï—Å–ª–∏ –Ω–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è, –≤–µ—Ä–Ω–∏ 0.0.\n"
        "7. 'organization_sentiment_score': —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –¢–û–õ–¨–ö–û —á–∞—Å—Ç–∏ –ø—Ä–æ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é (–æ—Ç -1.0 –¥–æ 1.0). –ï—Å–ª–∏ –Ω–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è, –≤–µ—Ä–Ω–∏ 0.0.\n\n"
        "–ï—Å–ª–∏ –∫–∞–∫–æ–π-—Ç–æ –∞—Å–ø–µ–∫—Ç –≤ —Ç–µ–∫—Å—Ç–µ –Ω–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è, –¥–ª—è –∫–ª—é—á–µ–π feedback –æ—Å—Ç–∞–≤—å –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É, –∞ –¥–ª—è –∫–ª—é—á–µ–π sentiment_score –≤–µ—Ä–Ω–∏ 0.0.\n\n"
        f"–¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: \"{text}\""
    )

    try:
        response = await client.chat.completions.create(
            model="deepseek-ai/DeepSeek-V3",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            response_format={"type": "json_object"}
        )
        content = response.choices[0].message.content
        result = json.loads(content)
        for key, value in error_result.items():
            if key not in result:
                result[key] = value
        return result

    except Exception as e:
        print(f"Error processing text: '{text[:50]}...'. Error: {e}")
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ DeepSeek API: {e}")
        return error_result

# ----------------------
# –ù–û–í–´–ï –§–£–ù–ö–¶–ò–ò –ì–ï–ù–ï–†–ê–¶–ò–ò
# ----------------------

async def _get_one_nomination(client: AsyncOpenAI, username: str, text: str) -> dict:
    """–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–¥–Ω–æ–π –Ω–æ–º–∏–Ω–∞—Ü–∏–∏."""
    prompt = (
        "–¢—ã ‚Äî –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏ —à–∫–æ–ª—å–Ω–∏–∫–æ–≤ —Å –º–æ—Ä—Å–∫–æ–π –Ω–∞—É—á–Ω–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–µ–∫—Ç–Ω–æ–π —Å–º–µ–Ω—ã. "
        f"–ù–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π —É—á–∞—Å—Ç–Ω–∏–∫–∞ –ø–æ –∏–º–µ–Ω–∏ {username}: \"{text}\", –ø—Ä–∏—Å–≤–æ–π —à—É—Ç–æ—á–Ω—É—é –Ω–æ–º–∏–Ω–∞—Ü–∏—é –≤ –º–æ—Ä—Å–∫–æ–π —Ç–µ–º–∞—Ç–∏–∫–µ "
        "(–Ω–∞–ø—Ä–∏–º–µ—Ä, '–ö–∞–ø–∏—Ç–∞–Ω –ì–µ–Ω–∏–∞–ª—å–Ω–æ—Å—Ç–∏', '–ò–Ω–∂–µ–Ω–µ—Ä –ì–ª—É–±–∏–Ω') –∏ –¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è), "
        "–ø–æ—á–µ–º—É –æ–Ω–∞ –ø–æ–¥—Ö–æ–¥–∏—Ç, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–∏ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π. –ù–æ–º–∏–Ω–∞—Ü–∏—è –∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–º–∏, "
        "–ø–æ–¥—Ö–æ–¥—è—â–∏–º–∏ –¥–ª—è —à–∫–æ–ª—å–Ω–∏–∫–æ–≤ –∏ —Å–≤—è–∑–∞–Ω–Ω—ã–º–∏ —Å –º–æ—Ä—Å–∫–æ–π/–Ω–∞—É—á–Ω–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π —Ç–µ–º–∞—Ç–∏–∫–æ–π. "
        "–í–µ—Ä–Ω–∏ JSON-–æ–±—ä–µ–∫—Ç: {\"nomination\": str, \"justification\": str}."
    )
    default_result = {"nomination": "–ú–æ—Ä—Å–∫–æ–π –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å", "justification": "–ó–∞ –∞–∫—Ç–∏–≤–Ω–æ–µ —É—á–∞—Å—Ç–∏–µ –≤ –ø—Ä–æ–µ–∫—Ç–µ!"}
    
    try:
        response = await client.chat.completions.create(
            model="deepseek-ai/DeepSeek-V3",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            response_format={"type": "json_object"}
        )
        result = json.loads(response.choices[0].message.content)
        if 'nomination' not in result or 'justification' not in result:
             return default_result
        return result
    except Exception as e:
        print(f"Error generating nomination for {username}: {e}")
        return default_result

@st.cache_data(show_spinner=False)
async def generate_nominations(_df: pd.DataFrame, client: AsyncOpenAI) -> pd.DataFrame:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —à—É—Ç–æ—á–Ω—ã–µ –Ω–æ–º–∏–Ω–∞—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É—á–∞—Å—Ç–Ω–∏–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ—Ö –µ–≥–æ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π."""
    user_reflections = _df.groupby('username')['text'].apply(lambda texts: ' '.join(texts.astype(str).str.strip())).reset_index()
    
    tasks = [
        _get_one_nomination(client, row['username'], row['text']) 
        for index, row in user_reflections.iterrows()
    ]
    
    results = await asyncio.gather(*tasks)
    
    results_df = pd.DataFrame(results)
    final_df = pd.concat([user_reflections[['username']], results_df], axis=1)
    final_df = final_df.rename(columns={'username': '–§–ò–û', 'nomination': '–ù–æ–º–∏–Ω–∞—Ü–∏—è', 'justification': '–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ'})
    return final_df

async def _get_one_friendly_reflection(client: AsyncOpenAI, username: str, text: str) -> dict:
    """–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–¥–Ω–æ–π –¥—Ä—É–∂–µ–ª—é–±–Ω–æ–π —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏."""
    prompt = (
        "–¢—ã ‚Äî –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, —Å—É–º–º–∏—Ä—É—é—â–∏–π —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏ —à–∫–æ–ª—å–Ω–∏–∫–æ–≤ —Å –º–æ—Ä—Å–∫–æ–π –Ω–∞—É—á–Ω–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–µ–∫—Ç–Ω–æ–π —Å–º–µ–Ω—ã. "
        f"–ù–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π —É—á–∞—Å—Ç–Ω–∏–∫–∞ –ø–æ –∏–º–µ–Ω–∏ {username}: \"{text}\", —Å–æ–∑–¥–∞–π –¥—Ä—É–∂–µ–ª—é–±–Ω–æ–µ, —à—É—Ç–æ—á–Ω–æ–µ —Ä–µ–∑—é–º–µ –µ–≥–æ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) "
        "–∏ –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–µ –Ω–∞–ø—É—Ç—Å—Ç–≤–∏–µ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –¥–ª—è –º–æ—Ç–∏–≤–∞—Ü–∏–∏. –¢–æ–Ω –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–º, –Ω–µ –æ–±–∏–¥–Ω—ã–º, "
        "–ø–æ–¥—Ö–æ–¥—è—â–∏–º –¥–ª—è —à–∫–æ–ª—å–Ω–∏–∫–æ–≤, —Å —É—á–µ—Ç–æ–º –º–æ—Ä—Å–∫–æ–π/–Ω–∞—É—á–Ω–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π —Ç–µ–º–∞—Ç–∏–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏—Å–ø–æ–ª—å–∑—É–π —Å–ª–æ–≤–∞ '–∫—É—Ä—Å', '–ø–ª–∞–≤–∞–Ω–∏–µ', '–≥–æ—Ä–∏–∑–æ–Ω—Ç—ã'). "
        "–í–µ—Ä–Ω–∏ JSON-–æ–±—ä–µ–∫—Ç: {\"reflection\": str, \"encouragement\": str}."
    )
    default_result = {"reflection": "–¢—ã –æ—Ç–ª–∏—á–Ω–æ —Å–ø—Ä–∞–≤–ª—è–µ—à—å—Å—è —Å –ø—Ä–æ–µ–∫—Ç–∞–º–∏!", "encouragement": "–ü—Ä–æ–¥–æ–ª–∂–∞–π –≤ —Ç–æ–º –∂–µ –¥—É—Ö–µ –∏ –ø–æ–∫–æ—Ä—è–π –Ω–æ–≤—ã–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç—ã!"}
    
    try:
        response = await client.chat.completions.create(
            model="deepseek-ai/DeepSeek-V3",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            response_format={"type": "json_object"}
        )
        result = json.loads(response.choices[0].message.content)
        if 'reflection' not in result or 'encouragement' not in result:
             return default_result
        return result
    except Exception as e:
        print(f"Error generating friendly reflection for {username}: {e}")
        return default_result

@st.cache_data(show_spinner=False)
async def generate_friendly_reflections(_df: pd.DataFrame, client: AsyncOpenAI) -> pd.DataFrame:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–µ —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏ –∏ –Ω–∞–ø—É—Ç—Å—Ç–≤–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É—á–∞—Å—Ç–Ω–∏–∫–∞."""
    user_reflections = _df.groupby('username')['text'].apply(lambda texts: ' '.join(texts.astype(str).str.strip())).reset_index()

    tasks = [
        _get_one_friendly_reflection(client, row['username'], row['text'])
        for index, row in user_reflections.iterrows()
    ]
    
    results = await asyncio.gather(*tasks)
    
    results_df = pd.DataFrame(results)
    final_df = pd.concat([user_reflections[['username']], results_df], axis=1)
    final_df = final_df.rename(columns={'username': '–§–ò–û', 'reflection': '–†–µ—Ñ–ª–µ–∫—Å–∏—è', 'encouragement': '–ü–æ–∂–µ–ª–∞–Ω–∏–µ'})
    return final_df


# ----------------------
# 6. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
# ----------------------
def convert_sentiment_to_10_point(score: float) -> float:
    if not isinstance(score, (int, float)):
        return 5.5
    return (score + 1) * 4.5 + 1

# ----------------------
# 7. –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Supabase (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
# ----------------------
@st.cache_resource
def init_supabase_client():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–ª–∏–µ–Ω—Ç Supabase."""
    try:
        supabase_url = st.secrets["SUPABASE_URL"]
        supabase_key = st.secrets["SUPABASE_KEY"]
        return create_client(supabase_url, supabase_key)
    except KeyError as e:
        st.error(f"–û—à–∏–±–∫–∞: –∫–ª—é—á '{e.args[0]}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Å–µ–∫—Ä–µ—Ç–∞—Ö Streamlit. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–æ–±–∞–≤—å—Ç–µ –µ–≥–æ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.")
        return None
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Supabase: {e}")
        return None

@st.cache_data(ttl=300)
def get_report_list_from_supabase(_supabase: Client) -> list:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–º–µ–Ω –æ—Ç—á–µ—Ç–æ–≤ –∏–∑ Supabase."""
    try:
        response = _supabase.table('reports').select('report_name', count='exact').execute()
        if response.data:
            unique_names = sorted(list(set(item['report_name'] for item in response.data)), reverse=True)
            return unique_names
        return []
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –æ—Ç—á–µ—Ç–æ–≤ –∏–∑ Supabase: {e}")
        return []

@st.cache_data
def load_report_from_supabase(_supabase: Client, report_name: str) -> pd.DataFrame:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –∏–∑ Supabase –≤ DataFrame."""
    try:
        response = _supabase.table('reports').select('*').eq('report_name', report_name).execute()
        df = pd.DataFrame(response.data)
        if 'data' in df.columns:
            df['data'] = pd.to_datetime(df['data'], errors='coerce')
        if not df.empty:
            df = df.drop(columns=['id', 'created_at', 'report_name'], errors='ignore')
        return df
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –æ—Ç—á–µ—Ç–∞ '{report_name}': {e}")
        return pd.DataFrame()


# ----------------------
# 8. –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –∏ –¥–∞—à–±–æ—Ä–¥ –Ω–∞ Streamlit (–ò–ó–ú–ï–ù–ï–ù–û)
# ----------------------
def main():
    st.set_page_config(layout="wide")
    st.title("–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –¥–∞—à–±–æ—Ä–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π —É—á–∞—â–∏—Ö—Å—è")

    with st.expander("‚ÑπÔ∏è –û –ø—Ä–æ–µ–∫—Ç–µ: —á—Ç–æ —ç—Ç–æ –∏ –∫–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è?", expanded=False):
        st.markdown("""
        **–¶–µ–ª—å –¥–∞—à–±–æ—Ä–¥–∞** ‚Äî –ø–æ–º–æ—á—å –ø–µ–¥–∞–≥–æ–≥–∞–º –∏ –∫—É—Ä–∞—Ç–æ—Ä–∞–º –±—ã—Å—Ç—Ä–æ –æ—Ü–µ–Ω–∏—Ç—å —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≥—Ä—É–ø–ø—ã, –≤—ã—è–≤–∏—Ç—å –æ–±—â–∏–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏ –∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —É—á–∞—â–∏—Ö—Å—è, —Ç—Ä–µ–±—É—é—â–∏—Ö –æ—Å–æ–±–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è, –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Ö –ø–∏—Å—å–º–µ–Ω–Ω—ã—Ö —Ä–µ—Ñ–ª–µ–∫—Å–∏–π.

        **–ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç?**
        1.  –î–ª—è **–Ω–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞** –∑–∞–≥—Ä—É–∑–∏—Ç–µ Excel-—Ñ–∞–π–ª —Å —Ç–µ–∫—Å—Ç–∞–º–∏ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π.
        2.  –ß—Ç–æ–±—ã –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å **—Å—Ç–∞—Ä—ã–π –æ—Ç—á–µ—Ç**, –≤—ã–±–µ—Ä–∏—Ç–µ –µ–≥–æ –∏–∑ –≤—ã–ø–∞–¥–∞—é—â–µ–≥–æ —Å–ø–∏—Å–∫–∞. –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∑—è—Ç—Å—è –∏–∑ –æ–±–ª–∞—á–Ω–æ–≥–æ –∞—Ä—Ö–∏–≤–∞.
        3.  –ü—Ä–∏ –Ω–æ–≤–æ–º –∞–Ω–∞–ª–∏–∑–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç (DeepSeek) –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞–∂–¥—ã–π —Ç–µ–∫—Å—Ç.
        4.  –ü–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞ –≤—ã –º–æ–∂–µ—Ç–µ **—Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –∞—Ä—Ö–∏–≤**, –Ω–∞–∂–∞–≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –∫–Ω–æ–ø–∫—É. –û—Ç—á–µ—Ç —Å—Ç–∞–Ω–µ—Ç –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –≤—ã–±–æ—Ä–∞ –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º –∑–∞–ø—É—Å–∫–µ.
        5.  –í **–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏—è—Ö** –º–æ–∂–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —à—É—Ç–æ—á–Ω—ã–µ –Ω–æ–º–∏–Ω–∞—Ü–∏–∏ –∏ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏ –¥–ª—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤.
        """)

    supabase = init_supabase_client()
    if not supabase:
        st.stop()

    st.sidebar.header("üóÇÔ∏è –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö")
    report_files = get_report_list_from_supabase(supabase)
    data_source_options = ["–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑"] + report_files
    selected_source = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –æ—Ç—á–µ—Ç –∏–∑ –∞—Ä—Ö–∏–≤–∞ –∏–ª–∏ –Ω–∞—á–Ω–∏—Ç–µ –Ω–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑:", data_source_options)

    df = None
    uploaded_file = None

    if selected_source != "–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑":
        st.sidebar.success(f"–ó–∞–≥—Ä—É–∂–µ–Ω –æ—Ç—á–µ—Ç –∏–∑ –∞—Ä—Ö–∏–≤–∞: {selected_source}")
        df = load_report_from_supabase(supabase, selected_source)
        st.session_state['current_file_name'] = selected_source
    else:
        st.sidebar.header("üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–ª—è –Ω–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
        uploaded_file = st.sidebar.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel-—Ñ–∞–π–ª —Å —Ä–µ—Ñ–ª–µ–∫—Å–∏—è–º–∏", type="xlsx")
        if uploaded_file:
            st.session_state['current_file_name'] = uploaded_file.name
            df = load_data(uploaded_file)
            df['text'] = df['text'].astype(str).fillna('')

    if df is None:
        st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –Ω–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –≥–æ—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏.")
        return

    client = None
    if selected_source == "–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑":
        try:
            api_key = st.secrets["DEEPSEEK_API_KEY"]
            client = AsyncOpenAI(base_url=DEESEEK_API_URL, api_key=api_key)
        except KeyError:
            st.sidebar.error("API-–∫–ª—é—á DeepSeek –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.")
            st.error("–û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á `DEEPSEEK_API_KEY`. "
                     "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–æ–±–∞–≤—å—Ç–µ –µ–≥–æ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–µ–∫—Ä–µ—Ç–æ–≤ –≤ Streamlit Cloud.")
            st.stop()

    session_key = f"df_processed_{st.session_state.get('current_file_name', 'default')}"

    if session_key not in st.session_state:
        if selected_source == "–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑" and client:
            with st.spinner('–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∞–Ω–∞–ª–∏–∑ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π... –≠—Ç–æ –∑–∞–π–º–µ—Ç –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è.'):
                tasks = [analyze_reflection_with_deepseek(client, text) for text in df['text']]
                async def gather_tasks():
                    return await asyncio.gather(*tasks)
                results = asyncio.run(gather_tasks())
                results_df = pd.DataFrame(results)
                df = pd.concat([df.reset_index(drop=True), results_df.reset_index(drop=True)], axis=1)
        
        for col in ['sentiment_score', 'learning_sentiment_score', 'teamwork_sentiment_score', 'organization_sentiment_score']:
            if col in df.columns:
                 df[col.replace('_score', '_10_point')] = df[col].apply(convert_sentiment_to_10_point)
        
        st.session_state[session_key] = df
    else:
        df = st.session_state[session_key]

    if selected_source == "–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑" and uploaded_file:
        st.sidebar.header("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ")
        if st.sidebar.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –∞—Ä—Ö–∏–≤"):
            with st.spinner("–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –≤ –æ–±–ª–∞–∫–æ..."):
                timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M")
                base_filename = os.path.splitext(uploaded_file.name)[0]
                report_filename = f"{base_filename}_processed_{timestamp}"
                processed_df_to_save = st.session_state[session_key].copy()
                processed_df_to_save['report_name'] = report_filename
                if 'data' in processed_df_to_save.columns:
                    processed_df_to_save['data'] = pd.to_datetime(processed_df_to_save['data']).dt.strftime('%Y-%m-%dT%H:%M:%S')
                df_for_upload = processed_df_to_save.replace({pd.NaT: None, np.nan: None})
                df_for_upload = df_for_upload.drop(columns=['id'], errors='ignore')
                data_to_upload = df_for_upload.to_dict(orient='records')
                try:
                    supabase.table('reports').upsert(data_to_upload, on_conflict='username,data').execute()
                    st.sidebar.success(f"–ê–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫:\n**{report_filename}**\n–î—É–±–ª–∏–∫–∞—Ç—ã –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω—ã.")
                    st.cache_data.clear()
                    st.rerun()
                except Exception as e:
                    st.sidebar.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ Supabase: {e}")
    if df.empty:
        st.error("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏–∑–º–µ–Ω–∏—Ç–µ —Ñ–∏–ª—å—Ç—Ä—ã –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª.")
        return
        
    filtered_df = df.copy()

    st.sidebar.header("üìä –§–∏–ª—å—Ç—Ä—ã")
    if 'data' in filtered_df.columns and not filtered_df['data'].dropna().empty:
        min_date = filtered_df['data'].min().date()
        max_date = filtered_df['data'].max().date()
        if min_date != max_date:
            date_range = st.sidebar.slider(
                "–í—ã–±–µ—Ä–∏—Ç–µ –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç:",
                min_value=min_date, max_value=max_date,
                value=(min_date, max_date), format="DD.MM.YYYY"
            )
            start_date, end_date = date_range
            mask = (filtered_df['data'].dt.date >= start_date) & (filtered_df['data'].dt.date <= end_date)
            filtered_df = filtered_df.loc[mask]
        else:
             st.sidebar.info("–í –¥–∞–Ω–Ω—ã—Ö —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –¥–µ–Ω—å, —Ñ–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ –Ω–µ–∞–∫—Ç–∏–≤–µ–Ω.")
    else:
        st.sidebar.warning("–í —Ñ–∞–π–ª–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞—Ç—ã –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.")

    if filtered_df.empty:
        st.error("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º.")
        return

    # --- –ù–û–í–´–ô –ë–õ–û–ö: –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º ---
    if 'view_mode' not in st.session_state:
        st.session_state.view_mode = 'dashboard'

    # –ö–Ω–æ–ø–∫–∏ –¥–ª—è –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –≤–∏–¥–∞ –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏
    st.sidebar.header("üéâ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏")
    if st.sidebar.button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —à—É—Ç–æ—á–Ω—ã–µ –Ω–æ–º–∏–Ω–∞—Ü–∏–∏"):
        st.session_state.view_mode = 'nominations'
        st.rerun()

    if st.sidebar.button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–µ —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏"):
        st.session_state.view_mode = 'reflections'
        st.rerun()

    # –ö–Ω–æ–ø–∫–∞ –≤–æ–∑–≤—Ä–∞—Ç–∞ –Ω–∞ –≥–ª–∞–≤–Ω—ã–π –¥–∞—à–±–æ—Ä–¥
    if st.session_state.view_mode != 'dashboard':
        if st.sidebar.button("‚óÄÔ∏è –í–µ—Ä–Ω—É—Ç—å—Å—è –∫ –æ—Å–Ω–æ–≤–Ω–æ–º—É –¥–∞—à–±–æ—Ä–¥—É"):
            st.session_state.view_mode = 'dashboard'
            st.rerun()
            
    # --- –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞ ---
    if st.session_state.view_mode == 'dashboard':
        # --- –ù–∞—á–∞–ª–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –±–ª–æ–∫–∞ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–∞—à–±–æ—Ä–¥–∞ ---
        st.header("–û–±—â–∞—è –¥–∏–Ω–∞–º–∏–∫–∞ –∏ –≥—Ä—É–ø–ø–æ–≤–æ–π –∞–Ω–∞–ª–∏–∑")
        daily_groups = filtered_df.groupby(filtered_df['data'].dt.date)
        agg_dict = {
            'avg_emotion': ('emotion', 'mean'),
            'avg_sentiment_10_point': ('sentiment_10_point', 'mean'),
            'avg_learning_sentiment': ('learning_sentiment_10_point', 'mean'),
            'avg_teamwork_sentiment': ('teamwork_sentiment_10_point', 'mean'),
            'avg_organization_sentiment': ('organization_sentiment_10_point', 'mean')
        }
        # –ò—Å–∫–ª—é—á–∞–µ–º –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –¥–ª—è –∫–æ–ª–æ–Ω–æ–∫, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç
        valid_agg_dict = {k: v for k, v in agg_dict.items() if v[0] in filtered_df.columns}
        if valid_agg_dict:
            daily_df = daily_groups.agg(**valid_agg_dict).reset_index()
            daily_df.rename(columns={'data': '–î–∞—Ç–∞'}, inplace=True)

            if not daily_df.empty:
                daily_df.sort_values('–î–∞—Ç–∞', inplace=True)
                col1, col2 = st.columns(2)
                with col1:
                    st.subheader("–û–±—â–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å vs. –°–∞–º–æ–æ—Ü–µ–Ω–∫–∞")
                    fig = px.line(
                        daily_df, x='–î–∞—Ç–∞', y=['avg_sentiment_10_point', 'avg_emotion'],
                        labels={'value': '–û—Ü–µ–Ω–∫–∞ (1-10)', 'variable': '–ú–µ—Ç—Ä–∏–∫–∞'},
                        title='–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∏ —Å–∞–º–æ–æ—Ü–µ–Ω–∫–∏'
                    )
                    st.plotly_chart(fig, use_container_width=True)
                with col2:
                    st.subheader("–î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –ø–æ –∞—Å–ø–µ–∫—Ç–∞–º")
                    fig_details = px.line(
                        daily_df, x='–î–∞—Ç–∞', y=['avg_learning_sentiment', 'avg_teamwork_sentiment', 'avg_organization_sentiment'],
                        labels={'value': '–û—Ü–µ–Ω–∫–∞ (1-10)', 'variable': '–ê—Å–ø–µ–∫—Ç'},
                        title='–î–∏–Ω–∞–º–∏–∫–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –ø–æ –∞—Å–ø–µ–∫—Ç–∞–º'
                    )
                    new_names = {'avg_learning_sentiment': '–£—á—ë–±–∞', 'avg_teamwork_sentiment': '–ö–æ–º–∞–Ω–¥–∞', 'avg_organization_sentiment': '–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è'}
                    fig_details.for_each_trace(lambda t: t.update(name = new_names.get(t.name, t.name)))
                    st.plotly_chart(fig_details, use_container_width=True)

        st.subheader("–¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –≥—Ä—É–ø–ø—ã")
        if 'sentiment_10_point' in filtered_df.columns:
            heatmap_data = filtered_df.pivot_table(
                index='username',
                columns=filtered_df['data'].dt.date,
                values='sentiment_10_point',
                aggfunc='mean'
            )
            if not heatmap_data.empty:
                fig_heatmap = px.imshow(
                    heatmap_data,
                    labels=dict(x="–î–∞—Ç–∞", y="–£—á–µ–Ω–∏–∫", color="–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å"),
                    title="–û–±—â–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å (1-10) –ø–æ –¥–Ω—è–º –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É—á–µ–Ω–∏–∫–∞",
                    color_continuous_scale='RdYlGn',
                    aspect="auto"
                )
                st.plotly_chart(fig_heatmap, use_container_width=True)
            else:
                st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã.")
        else:
            st.info("–î–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã (sentiment_10_point) –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç.")

        st.header("–ê–Ω–∞–ª–∏–∑ –ø–æ –æ—Ç–¥–µ–ª—å–Ω—ã–º —É—á–∞—â–∏–º—Å—è")
        student_list = sorted(filtered_df['username'].unique())
        if student_list:
            student = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —É—á–µ–Ω–∏–∫–∞:", student_list)
            if student:
                student_df = filtered_df[filtered_df['username'] == student].sort_values('data')
                col1, col2 = st.columns([3, 2])
                with col1:
                    st.subheader(f"–î–∏–Ω–∞–º–∏–∫–∞ –æ—Ü–µ–Ω–æ–∫ –¥–ª—è {student}")
                    fig2 = px.line(
                        student_df, x='data', y=['sentiment_10_point', 'emotion'],
                        labels={'value': '–û—Ü–µ–Ω–∫–∞ (1-10)', 'data': '–î–∞—Ç–∞'},
                        title=f'–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å vs. –°–∞–º–æ–æ—Ü–µ–Ω–∫–∞'
                    )
                    st.plotly_chart(fig2, use_container_width=True)
                with col2:
                    st.subheader(f"–ü—Ä–æ—Ñ–∏–ª—å —É—á–µ–Ω–∏–∫–∞")
                    categories = ['–°–∞–º–æ–æ—Ü–µ–Ω–∫–∞', '–£—á—ë–±–∞', '–ö–æ–º–∞–Ω–¥–∞', '–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è']
                    values = [
                        student_df['emotion'].mean(),
                        student_df['learning_sentiment_10_point'].mean(),
                        student_df['teamwork_sentiment_10_point'].mean(),
                        student_df['organization_sentiment_10_point'].mean()
                    ]
                    fig_radar = go.Figure()
                    fig_radar.add_trace(go.Scatterpolar(r=values, theta=categories, fill='toself', name='–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞'))
                    fig_radar.update_layout(
                        polar=dict(radialaxis=dict(visible=True, range=[1, 10])),
                        showlegend=False,
                        title=f"–°—Ä–µ–¥–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏ –¥–ª—è {student}",
                        margin=dict(l=40, r=40, t=80, b=40)
                    )
                    st.plotly_chart(fig_radar, use_container_width=True)

                st.subheader("–î–µ—Ç–∞–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π")
                display_columns = [
                    'data', 'text', 'emotion', 'sentiment_10_point',
                    'learning_sentiment_10_point', 'teamwork_sentiment_10_point', 'organization_sentiment_10_point',
                    'learning_feedback', 'teamwork_feedback', 'organization_feedback'
                ]
                st.dataframe(student_df[[col for col in display_columns if col in student_df.columns]])

        if st.sidebar.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–ª–Ω—É—é —Ç–∞–±–ª–∏—Ü—É —Å –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏"):
            st.header("–ü–æ–ª–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –¥–∞–Ω–Ω—ã—Ö")
            st.dataframe(filtered_df)

        st.header("–ê–Ω–∞–ª–∏–∑ \"–ó–æ–Ω—ã —Ä–∏—Å–∫–∞\": —É—á–∞—Å—Ç–Ω–∏–∫–∏ —Å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–º—Å—è –Ω–µ–≥–∞—Ç–∏–≤–æ–º")
        if 'sentiment_score' in filtered_df.columns:
            negative_reflections = filtered_df[filtered_df['sentiment_score'] < 0]
            if not negative_reflections.empty:
                negative_counts = negative_reflections.groupby('username').size().reset_index(name='negative_count')
                at_risk_users = negative_counts[negative_counts['negative_count'] > 1].sort_values('negative_count', ascending=False)
                if not at_risk_users.empty:
                    st.warning("–í–Ω–∏–º–∞–Ω–∏–µ! –í—ã—è–≤–ª–µ–Ω—ã —É—á–∞—Å—Ç–Ω–∏–∫–∏ —Å –º–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω–æ–π –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–π —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é –≤ —Ä–µ—Ñ–ª–µ–∫—Å–∏—è—Ö –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.")
                    st.dataframe(at_risk_users)
                else:
                    st.success("–ó–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –Ω–µ –≤—ã—è–≤–ª–µ–Ω–æ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤, —É –∫–æ—Ç–æ—Ä—ã—Ö —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Ä–µ—Ñ–ª–µ–∫—Å–∏–π –±—ã–ª–∞ –±—ã –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–π –±–æ–ª–µ–µ –æ–¥–Ω–æ–≥–æ —Ä–∞–∑–∞.")
            else:
                st.success("–ù–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Ä–µ—Ñ–ª–µ–∫—Å–∏–π –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        # --- –ö–æ–Ω–µ—Ü –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –±–ª–æ–∫–∞ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–∞—à–±–æ—Ä–¥–∞ ---

    elif st.session_state.view_mode == 'nominations':
        st.header("üèÜ –®—É—Ç–æ—á–Ω—ã–µ –Ω–æ–º–∏–Ω–∞—Ü–∏–∏ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤")
        nominations_key = f"nominations_{session_key}"
        
        if client is None:
            st.error("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –ø—Ä–∏ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ –æ—Ç—á–µ—Ç–∞ –∏–∑ –∞—Ä—Ö–∏–≤–∞. –í—ã–±–µ—Ä–∏—Ç–µ '–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑' –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏.")
        else:
            if nominations_key not in st.session_state:
                with st.spinner("–°–æ–∑–¥–∞–µ–º –Ω–æ–º–∏–Ω–∞—Ü–∏–∏... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç..."):
                    nominations_df = asyncio.run(generate_nominations(filtered_df, client))
                    st.session_state[nominations_key] = nominations_df
            
            st.dataframe(st.session_state[nominations_key], use_container_width=True)

    elif st.session_state.view_mode == 'reflections':
        st.header("üåü –î—Ä—É–∂–µ–ª—é–±–Ω—ã–µ —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏ –∏ –Ω–∞–ø—É—Ç—Å—Ç–≤–∏—è")
        reflections_key = f"friendly_reflections_{session_key}"

        if client is None:
            st.error("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –ø—Ä–∏ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ –æ—Ç—á–µ—Ç–∞ –∏–∑ –∞—Ä—Ö–∏–≤–∞. –í—ã–±–µ—Ä–∏—Ç–µ '–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑' –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏.")
        else:
            if reflections_key not in st.session_state:
                with st.spinner("–ü–∏—à–µ–º –¥—Ä—É–∂–µ—Å–∫–∏–µ –ø–æ—Å–ª–∞–Ω–∏—è... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç..."):
                    reflections_df = asyncio.run(generate_friendly_reflections(filtered_df, client))
                    st.session_state[reflections_key] = reflections_df

            df_to_display = st.session_state[reflections_key].copy()
            df_to_display['–†–µ—Ñ–ª–µ–∫—Å–∏—è –∏ –Ω–∞–ø—É—Ç—Å—Ç–≤–∏–µ'] = df_to_display['–†–µ—Ñ–ª–µ–∫—Å–∏—è'] + '\n\n**–ü–æ–∂–µ–ª–∞–Ω–∏–µ:** ' + df_to_display['–ü–æ–∂–µ–ª–∞–Ω–∏–µ']
            st.dataframe(df_to_display[['–§–ò–û', '–†–µ—Ñ–ª–µ–∫—Å–∏—è –∏ –Ω–∞–ø—É—Ç—Å—Ç–≤–∏–µ']], use_container_width=True)

if __name__ == "__main__":
    main()
