# 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
# ----------------------
import subprocess
import sys


# ----------------------
# 2. –ò–º–ø–æ—Ä—Ç—ã –∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
# ----------------------
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import json
from openai import AsyncOpenAI
import asyncio
import numpy as np
import os

### –ù–û–í–û–ï: –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Supabase
from supabase import create_client, Client

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è API DeepSeek
DEESEEK_API_URL = "https://api.studio.nebius.ai/v1/"

# ----------------------
# 3. –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
# ----------------------
@st.cache_data
def load_data(file_path: str) -> pd.DataFrame:
    df = pd.read_excel(file_path)
    # –ü—Ä–∏–≤–æ–¥–∏–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –∏ —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã
    df.columns = [str(col).strip().lower() if isinstance(col, str) else col for col in df.columns]
    if 'data' in df.columns:
        df['data'] = pd.to_datetime(df['data'], errors='coerce')
    return df

# ----------------------
# 4. –ë–õ–û–ö –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ö–ò –¢–ï–ö–°–¢–ê (NLP) - –£–î–ê–õ–ï–ù
# ----------------------

# ----------------------
# 5. DeepSeek API –∞–Ω–∞–ª–∏–∑ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
# ----------------------
async def analyze_reflection_with_deepseek(client: AsyncOpenAI, text: str) -> dict:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏ —Å –ø–æ–º–æ—â—å—é DeepSeek API.
    """
    error_result = {
        "sentiment_score": 0.0,
        "learning_feedback": "N/A",
        "teamwork_feedback": "N/A",
        "organization_feedback": "N/A",
        "learning_sentiment_score": 0.0,
        "teamwork_sentiment_score": 0.0,
        "organization_sentiment_score": 0.0,
    }
    if not text or not isinstance(text, str) or not text.strip():
        return error_result

    prompt = (
        "–¢—ã ‚Äî –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–æ–≤ —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–µ—Ñ–ª–µ–∫—Å–∏—é —à–∫–æ–ª—å–Ω–∏–∫–∞. "
        "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –≤–µ—Ä–Ω—É—Ç—å JSON-–æ–±—ä–µ–∫—Ç —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –∫–ª—é—á–∞–º–∏:\n"
        "1. 'sentiment_score': –æ–±—â–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞, —á–∏—Å–ª–æ –æ—Ç -1.0 (–Ω–µ–≥–∞—Ç–∏–≤) –¥–æ 1.0 (–ø–æ–∑–∏—Ç–∏–≤).\n"
        "2. 'learning_feedback': –∫—Ä–∞—Ç–∫–∞—è –≤—ã–∂–∏–º–∫–∞ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –∏–∑ —Ç–µ–∫—Å—Ç–∞ –æ–± –æ—Ü–µ–Ω–∫–µ —É—á–µ–±–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞.\n"
        "3. 'teamwork_feedback': –∫—Ä–∞—Ç–∫–∞—è –≤—ã–∂–∏–º–∫–∞ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –æ–± –æ—Ü–µ–Ω–∫–µ —Ä–∞–±–æ—Ç—ã –≤ –∫–æ–º–∞–Ω–¥–µ.\n"
        "4. 'organization_feedback': –∫—Ä–∞—Ç–∫–∞—è –≤—ã–∂–∏–º–∫–∞ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –æ–± –æ—Ü–µ–Ω–∫–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∏ –¥–æ—Å—É–≥–æ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤.\n"
        "5. 'learning_sentiment_score': —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –¢–û–õ–¨–ö–û —á–∞—Å—Ç–∏ –ø—Ä–æ —É—á—ë–±—É (–æ—Ç -1.0 –¥–æ 1.0). –ï—Å–ª–∏ –Ω–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è, –≤–µ—Ä–Ω–∏ 0.0.\n"
        "6. 'teamwork_sentiment_score': —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –¢–û–õ–¨–ö–û —á–∞—Å—Ç–∏ –ø—Ä–æ –∫–æ–º–∞–Ω–¥—É (–æ—Ç -1.0 –¥–æ 1.0). –ï—Å–ª–∏ –Ω–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è, –≤–µ—Ä–Ω–∏ 0.0.\n"
        "7. 'organization_sentiment_score': —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –¢–û–õ–¨–ö–û —á–∞—Å—Ç–∏ –ø—Ä–æ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é (–æ—Ç -1.0 –¥–æ 1.0). –ï—Å–ª–∏ –Ω–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è, –≤–µ—Ä–Ω–∏ 0.0.\n\n"
        "–ï—Å–ª–∏ –∫–∞–∫–æ–π-—Ç–æ –∞—Å–ø–µ–∫—Ç –≤ —Ç–µ–∫—Å—Ç–µ –Ω–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è, –¥–ª—è –∫–ª—é—á–µ–π feedback –æ—Å—Ç–∞–≤—å –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É, –∞ –¥–ª—è –∫–ª—é—á–µ–π sentiment_score –≤–µ—Ä–Ω–∏ 0.0.\n\n"
        f"–¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: \"{text}\""
    )

    try:
        response = await client.chat.completions.create(
            model="deepseek-ai/DeepSeek-V3",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            response_format={"type": "json_object"}
        )
        content = response.choices[0].message.content
        result = json.loads(content)
        for key, value in error_result.items():
            if key not in result:
                result[key] = value
        return result

    except Exception as e:
        print(f"Error processing text: '{text[:50]}...'. Error: {e}")
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ DeepSeek API: {e}")
        return error_result

# ----------------------
# –ù–û–í–´–ï –§–£–ù–ö–¶–ò–ò –ì–ï–ù–ï–†–ê–¶–ò–ò (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
# ----------------------
async def _get_one_nomination(client: AsyncOpenAI, username: str, text: str) -> dict:
    prompt = (
        "–¢—ã ‚Äî –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏ —à–∫–æ–ª—å–Ω–∏–∫–æ–≤ —Å –º–æ—Ä—Å–∫–æ–π –Ω–∞—É—á–Ω–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–µ–∫—Ç–Ω–æ–π —Å–º–µ–Ω—ã. "
        f"–ù–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π —É—á–∞—Å—Ç–Ω–∏–∫–∞ –ø–æ –∏–º–µ–Ω–∏ {username}: \"{text}\", –ø—Ä–∏—Å–≤–æ–π —à—É—Ç–æ—á–Ω—É—é –Ω–æ–º–∏–Ω–∞—Ü–∏—é –≤ –º–æ—Ä—Å–∫–æ–π —Ç–µ–º–∞—Ç–∏–∫–µ "
        "(–Ω–∞–ø—Ä–∏–º–µ—Ä, '–ö–∞–ø–∏—Ç–∞–Ω –ì–µ–Ω–∏–∞–ª—å–Ω–æ—Å—Ç–∏', '–ò–Ω–∂–µ–Ω–µ—Ä –ì–ª—É–±–∏–Ω') –∏ –¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è), "
        "–ø–æ—á–µ–º—É –æ–Ω–∞ –ø–æ–¥—Ö–æ–¥–∏—Ç, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–∏ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π. –ù–æ–º–∏–Ω–∞—Ü–∏—è –∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–º–∏, "
        "–ø–æ–¥—Ö–æ–¥—è—â–∏–º–∏ –¥–ª—è —à–∫–æ–ª—å–Ω–∏–∫–æ–≤ –∏ —Å–≤—è–∑–∞–Ω–Ω—ã–º–∏ —Å –º–æ—Ä—Å–∫–æ–π/–Ω–∞—É—á–Ω–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π —Ç–µ–º–∞—Ç–∏–∫–æ–π. "
        "–í–µ—Ä–Ω–∏ JSON-–æ–±—ä–µ–∫—Ç: {\"nomination\": str, \"justification\": str}."
    )
    default_result = {"nomination": "–ú–æ—Ä—Å–∫–æ–π –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å", "justification": "–ó–∞ –∞–∫—Ç–∏–≤–Ω–æ–µ —É—á–∞—Å—Ç–∏–µ –≤ –ø—Ä–æ–µ–∫—Ç–µ!"}
    try:
        response = await client.chat.completions.create(model="deepseek-ai/DeepSeek-V3", messages=[{"role": "user", "content": prompt}], temperature=0.7, response_format={"type": "json_object"})
        result = json.loads(response.choices[0].message.content)
        return result if 'nomination' in result and 'justification' in result else default_result
    except Exception as e:
        print(f"Error generating nomination for {username}: {e}")
        return default_result

async def _generate_nominations_async(_df: pd.DataFrame, client: AsyncOpenAI) -> pd.DataFrame:
    user_reflections = _df.groupby('username')['text'].apply(lambda texts: ' '.join(texts.astype(str).str.strip())).reset_index()
    tasks = [_get_one_nomination(client, row['username'], row['text']) for _, row in user_reflections.iterrows()]
    results = await asyncio.gather(*tasks)
    results_df = pd.DataFrame(results)
    final_df = pd.concat([user_reflections[['username']], results_df], axis=1).rename(columns={'username': '–§–ò–û', 'nomination': '–ù–æ–º–∏–Ω–∞—Ü–∏—è', 'justification': '–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ'})
    return final_df

@st.cache_data(show_spinner=False, hash_funcs={AsyncOpenAI: lambda _: None})
def get_cached_nominations(_df: pd.DataFrame, client: AsyncOpenAI) -> pd.DataFrame:
    return asyncio.run(_generate_nominations_async(_df, client))

async def _get_one_friendly_reflection(client: AsyncOpenAI, username: str, text: str) -> dict:
    prompt = (
        "–¢—ã ‚Äî –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, —Å—É–º–º–∏—Ä—É—é—â–∏–π —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏ —à–∫–æ–ª—å–Ω–∏–∫–æ–≤ —Å –º–æ—Ä—Å–∫–æ–π –Ω–∞—É—á–Ω–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–µ–∫—Ç–Ω–æ–π —Å–º–µ–Ω—ã. "
        f"–ù–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π —É—á–∞—Å—Ç–Ω–∏–∫–∞ –ø–æ –∏–º–µ–Ω–∏ {username}: \"{text}\", —Å–æ–∑–¥–∞–π –¥—Ä—É–∂–µ–ª—é–±–Ω–æ–µ, —à—É—Ç–æ—á–Ω–æ–µ —Ä–µ–∑—é–º–µ –µ–≥–æ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) "
        "–∏ –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–µ –Ω–∞–ø—É—Ç—Å—Ç–≤–∏–µ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –¥–ª—è –º–æ—Ç–∏–≤–∞—Ü–∏–∏. –¢–æ–Ω –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–º, –Ω–µ –æ–±–∏–¥–Ω—ã–º, "
        "–ø–æ–¥—Ö–æ–¥—è—â–∏–º –¥–ª—è —à–∫–æ–ª—å–Ω–∏–∫–æ–≤, —Å —É—á–µ—Ç–æ–º –º–æ—Ä—Å–∫–æ–π/–Ω–∞—É—á–Ω–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π —Ç–µ–º–∞—Ç–∏–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏—Å–ø–æ–ª—å–∑—É–π —Å–ª–æ–≤–∞ '–∫—É—Ä—Å', '–ø–ª–∞–≤–∞–Ω–∏–µ', '–≥–æ—Ä–∏–∑–æ–Ω—Ç—ã'). "
        "–í–µ—Ä–Ω–∏ JSON-–æ–±—ä–µ–∫—Ç: {\"reflection\": str, \"encouragement\": str}."
    )
    default_result = {"reflection": "–¢—ã –æ—Ç–ª–∏—á–Ω–æ —Å–ø—Ä–∞–≤–ª—è–µ—à—å—Å—è —Å –ø—Ä–æ–µ–∫—Ç–∞–º–∏!", "encouragement": "–ü—Ä–æ–¥–æ–ª–∂–∞–π –≤ —Ç–æ–º –∂–µ –¥—É—Ö–µ –∏ –ø–æ–∫–æ—Ä—è–π –Ω–æ–≤—ã–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç—ã!"}
    try:
        response = await client.chat.completions.create(model="deepseek-ai/DeepSeek-V3", messages=[{"role": "user", "content": prompt}], temperature=0.7, response_format={"type": "json_object"})
        result = json.loads(response.choices[0].message.content)
        return result if 'reflection' in result and 'encouragement' in result else default_result
    except Exception as e:
        print(f"Error generating friendly reflection for {username}: {e}")
        return default_result

async def _generate_friendly_reflections_async(_df: pd.DataFrame, client: AsyncOpenAI) -> pd.DataFrame:
    user_reflections = _df.groupby('username')['text'].apply(lambda texts: ' '.join(texts.astype(str).str.strip())).reset_index()
    tasks = [_get_one_friendly_reflection(client, row['username'], row['text']) for _, row in user_reflections.iterrows()]
    results = await asyncio.gather(*tasks)
    results_df = pd.DataFrame(results)
    final_df = pd.concat([user_reflections[['username']], results_df], axis=1).rename(columns={'username': '–§–ò–û', 'reflection': '–†–µ—Ñ–ª–µ–∫—Å–∏—è', 'encouragement': '–ü–æ–∂–µ–ª–∞–Ω–∏–µ'})
    return final_df

@st.cache_data(show_spinner=False, hash_funcs={AsyncOpenAI: lambda _: None})
def get_cached_friendly_reflections(_df: pd.DataFrame, client: AsyncOpenAI) -> pd.DataFrame:
    return asyncio.run(_generate_friendly_reflections_async(_df, client))

# ----------------------
# 6. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
# ----------------------
def convert_sentiment_to_10_point(score: float) -> float:
    if not isinstance(score, (int, float)):
        return 5.5
    return (score + 1) * 4.5 + 1

# ----------------------
# 7. –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Supabase (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
# ----------------------
@st.cache_resource
def init_supabase_client():
    try:
        supabase_url = st.secrets["SUPABASE_URL"]
        supabase_key = st.secrets["SUPABASE_KEY"]
        return create_client(supabase_url, supabase_key)
    except KeyError as e:
        st.error(f"–û—à–∏–±–∫–∞: –∫–ª—é—á '{e.args[0]}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Å–µ–∫—Ä–µ—Ç–∞—Ö Streamlit. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–æ–±–∞–≤—å—Ç–µ –µ–≥–æ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.")
        return None
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Supabase: {e}")
        return None

@st.cache_data(ttl=300)
def get_report_list_from_supabase(_supabase: Client) -> list:
    try:
        response = _supabase.table('reports').select('report_name', count='exact').execute()
        return sorted(list(set(item['report_name'] for item in response.data)), reverse=True) if response.data else []
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –æ—Ç—á–µ—Ç–æ–≤ –∏–∑ Supabase: {e}")
        return []

@st.cache_data
def load_report_from_supabase(_supabase: Client, report_name: str) -> pd.DataFrame:
    try:
        response = _supabase.table('reports').select('*').eq('report_name', report_name).execute()
        df = pd.DataFrame(response.data)
        if 'data' in df.columns:
            df['data'] = pd.to_datetime(df['data'], errors='coerce')
        if not df.empty:
            df = df.drop(columns=['id', 'created_at', 'report_name'], errors='ignore')
        return df
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –æ—Ç—á–µ—Ç–∞ '{report_name}': {e}")
        return pd.DataFrame()

# ----------------------
# 8. –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –∏ –¥–∞—à–±–æ—Ä–¥ –Ω–∞ Streamlit (–ò–ó–ú–ï–ù–ï–ù–û)
# ----------------------
def main():
    st.set_page_config(layout="wide")
    st.title("–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –¥–∞—à–±–æ—Ä–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π —É—á–∞—â–∏—Ö—Å—è")

    with st.expander("‚ÑπÔ∏è –û –ø—Ä–æ–µ–∫—Ç–µ: —á—Ç–æ —ç—Ç–æ –∏ –∫–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è?", expanded=False):
        st.markdown("""
        ... (—Ç–µ–∫—Å—Ç –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
        """)

    supabase = init_supabase_client()
    if not supabase:
        st.stop()

    st.sidebar.header("üóÇÔ∏è –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö")
    report_files = get_report_list_from_supabase(supabase)
    data_source_options = ["–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑"] + report_files
    selected_source = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –æ—Ç—á–µ—Ç –∏–∑ –∞—Ä—Ö–∏–≤–∞ –∏–ª–∏ –Ω–∞—á–Ω–∏—Ç–µ –Ω–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑:", data_source_options)

    # --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–ª–∞–≥–æ–≤ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ session_state –ø—Ä–∏ —Å–º–µ–Ω–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö ---
    # –≠—Ç–æ –Ω—É–∂–Ω–æ, —á—Ç–æ–±—ã –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞ —Å—Ç–∞—Ä—ã–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã –Ω–µ –æ—Ç–æ–±—Ä–∞–∂–∞–ª–∏—Å—å
    current_file_key = f"current_file_{selected_source}"
    if 'last_file_key' not in st.session_state or st.session_state.last_file_key != current_file_key:
        st.session_state.show_nominations = False
        st.session_state.show_reflections = False
        st.session_state.last_file_key = current_file_key
        
    df = None
    uploaded_file = None
    if selected_source != "–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑":
        st.sidebar.success(f"–ó–∞–≥—Ä—É–∂–µ–Ω –æ—Ç—á–µ—Ç –∏–∑ –∞—Ä—Ö–∏–≤–∞: {selected_source}")
        df = load_report_from_supabase(supabase, selected_source)
        st.session_state['current_file_name'] = selected_source
    else:
        st.sidebar.header("üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–ª—è –Ω–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
        uploaded_file = st.sidebar.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel-—Ñ–∞–π–ª —Å —Ä–µ—Ñ–ª–µ–∫—Å–∏—è–º–∏", type="xlsx")
        if uploaded_file:
            st.session_state['current_file_name'] = uploaded_file.name
            current_file_key = f"current_file_{uploaded_file.name}"
            if 'last_file_key' not in st.session_state or st.session_state.last_file_key != current_file_key:
                st.session_state.show_nominations = False
                st.session_state.show_reflections = False
                st.session_state.last_file_key = current_file_key
            df = load_data(uploaded_file)
            df['text'] = df['text'].astype(str).fillna('')

    if df is None:
        st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –Ω–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –≥–æ—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏.")
        return

    client = None
    if selected_source == "–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑":
        try:
            api_key = st.secrets["DEEPSEEK_API_KEY"]
            client = AsyncOpenAI(base_url=DEESEEK_API_URL, api_key=api_key)
        except KeyError:
            st.sidebar.error("API-–∫–ª—é—á DeepSeek –Ω–µ –Ω–∞–π–¥–µ–Ω.")
            st.stop()

    session_key = f"df_processed_{st.session_state.get('current_file_name', 'default')}"
    if session_key not in st.session_state:
        # ... (–ª–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è df –≤ session_state –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
        if selected_source == "–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑" and client:
            with st.spinner('–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∞–Ω–∞–ª–∏–∑ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π... –≠—Ç–æ –∑–∞–π–º–µ—Ç –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è.'):
                tasks = [analyze_reflection_with_deepseek(client, text) for text in df['text']]
                async def gather_tasks(): return await asyncio.gather(*tasks)
                results = asyncio.run(gather_tasks())
                results_df = pd.DataFrame(results)
                df = pd.concat([df.reset_index(drop=True), results_df.reset_index(drop=True)], axis=1)
        
        for col in ['sentiment_score', 'learning_sentiment_score', 'teamwork_sentiment_score', 'organization_sentiment_score']:
            if col in df.columns:
                 df[col.replace('_score', '_10_point')] = df[col].apply(convert_sentiment_to_10_point)
        st.session_state[session_key] = df
    else:
        df = st.session_state[session_key]

    if selected_source == "–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑" and uploaded_file:
        # ... (–ª–æ–≥–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –∞—Ä—Ö–∏–≤ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
        st.sidebar.header("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ")
        if st.sidebar.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –∞—Ä—Ö–∏–≤"):
            # ...
            pass # –ö–æ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è

    if df.empty:
        st.error("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
        return
        
    filtered_df = df.copy()

    st.sidebar.header("üìä –§–∏–ª—å—Ç—Ä—ã")
    # ... (–ª–æ–≥–∏–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
    if 'data' in filtered_df.columns and not filtered_df['data'].dropna().empty:
        #...
        pass
    
    if filtered_df.empty:
        st.error("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º.")
        return

    # --- –ò–ó–ú–ï–ù–ï–ù–ù–´–ô –ë–õ–û–ö: –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º —á–µ—Ä–µ–∑ —Ñ–ª–∞–≥–∏ ---
    st.sidebar.header("üéâ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏")
    if st.sidebar.button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —à—É—Ç–æ—á–Ω—ã–µ –Ω–æ–º–∏–Ω–∞—Ü–∏–∏"):
        st.session_state.show_nominations = True

    if st.sidebar.button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–µ —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏"):
        st.session_state.show_reflections = True
        
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–Ω–æ–ø–∫—É "–°–∫—Ä—ã—Ç—å", —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —á—Ç–æ —Å–∫—Ä—ã–≤–∞—Ç—å
    if st.session_state.get('show_nominations', False) or st.session_state.get('show_reflections', False):
        if st.sidebar.button("–°–∫—Ä—ã—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã"):
            st.session_state.show_nominations = False
            st.session_state.show_reflections = False


    # --- 1. –í–°–ï–ì–î–ê –û–¢–û–ë–†–ê–ñ–ê–ï–ú –û–°–ù–û–í–ù–û–ô –î–ê–®–ë–û–†–î ---
    st.header("–û–±—â–∞—è –¥–∏–Ω–∞–º–∏–∫–∞ –∏ –≥—Ä—É–ø–ø–æ–≤–æ–π –∞–Ω–∞–ª–∏–∑")
    # ... (–≤–µ—Å—å –∫–æ–¥ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –∏ —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã –¥–∞—à–±–æ—Ä–¥–∞) ...
    daily_groups = filtered_df.groupby(filtered_df['data'].dt.date)
    # ... –∏ —Ç–∞–∫ –¥–∞–ª–µ–µ
    st.header("–ê–Ω–∞–ª–∏–∑ –ø–æ –æ—Ç–¥–µ–ª—å–Ω—ã–º —É—á–∞—â–∏–º—Å—è")
    # ... (–≤–µ—Å—å –∫–æ–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ —É—á–∞—â–∏–º—Å—è, —Ä–∞–¥–∞—Ä–∞ –∏ —Ç–∞–±–ª–∏—Ü—ã) ...
    st.header("–ê–Ω–∞–ª–∏–∑ \"–ó–æ–Ω—ã —Ä–∏—Å–∫–∞\": —É—á–∞—Å—Ç–Ω–∏–∫–∏ —Å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–º—Å—è –Ω–µ–≥–∞—Ç–∏–≤–æ–º")
    # ... (–≤–µ—Å—å –∫–æ–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∑–æ–Ω —Ä–∏—Å–∫–∞) ...


    # --- 2. –£–°–õ–û–í–ù–û –û–¢–û–ë–†–ê–ñ–ê–ï–ú –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –¢–ê–ë–õ–ò–¶–´ ---
    # –ë–ª–æ–∫ –¥–ª—è –Ω–æ–º–∏–Ω–∞—Ü–∏–π
    if st.session_state.get('show_nominations', False):
        st.header("üèÜ –®—É—Ç–æ—á–Ω—ã–µ –Ω–æ–º–∏–Ω–∞—Ü–∏–∏ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤")
        nominations_key = f"nominations_{session_key}"
        
        if client is None:
            st.error("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –ø—Ä–∏ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ –æ—Ç—á–µ—Ç–∞ –∏–∑ –∞—Ä—Ö–∏–≤–∞. –í—ã–±–µ—Ä–∏—Ç–µ '–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑' –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏.")
        else:
            if nominations_key not in st.session_state:
                with st.spinner("–°–æ–∑–¥–∞–µ–º –Ω–æ–º–∏–Ω–∞—Ü–∏–∏... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç..."):
                    nominations_df = get_cached_nominations(filtered_df, client)
                    st.session_state[nominations_key] = nominations_df
            
            st.dataframe(st.session_state[nominations_key], use_container_width=True)

    # –ë–ª–æ–∫ –¥–ª—è —Ä–µ—Ñ–ª–µ–∫—Å–∏–π
    if st.session_state.get('show_reflections', False):
        st.header("üåü –î—Ä—É–∂–µ–ª—é–±–Ω—ã–µ —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏ –∏ –Ω–∞–ø—É—Ç—Å—Ç–≤–∏—è")
        reflections_key = f"friendly_reflections_{session_key}"

        if client is None:
            st.error("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –ø—Ä–∏ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ –æ—Ç—á–µ—Ç–∞ –∏–∑ –∞—Ä—Ö–∏–≤–∞. –í—ã–±–µ—Ä–∏—Ç–µ '–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑' –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏.")
        else:
            if reflections_key not in st.session_state:
                with st.spinner("–ü–∏—à–µ–º –¥—Ä—É–∂–µ—Å–∫–∏–µ –ø–æ—Å–ª–∞–Ω–∏—è... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç..."):
                    reflections_df = get_cached_friendly_reflections(filtered_df, client)
                    st.session_state[reflections_key] = reflections_df

            df_to_display = st.session_state[reflections_key].copy()
            df_to_display['–†–µ—Ñ–ª–µ–∫—Å–∏—è –∏ –Ω–∞–ø—É—Ç—Å—Ç–≤–∏–µ'] = df_to_display['–†–µ—Ñ–ª–µ–∫—Å–∏—è'] + '\n\n**–ü–æ–∂–µ–ª–∞–Ω–∏–µ:** ' + df_to_display['–ü–æ–∂–µ–ª–∞–Ω–∏–µ']
            st.dataframe(df_to_display[['–§–ò–û', '–†–µ—Ñ–ª–µ–∫—Å–∏—è –∏ –Ω–∞–ø—É—Ç—Å—Ç–≤–∏–µ']], use_container_width=True)


if __name__ == "__main__":
    main()
