# 1. Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹
# Ğ£Ğ±ĞµĞ´Ğ¸Ñ‚ĞµÑÑŒ, Ñ‡Ñ‚Ğ¾ Ğ²ÑĞµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ñ‹. Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚Ğµ Ğ² Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ°Ğ»Ğµ:
# pip install streamlit pandas plotly supabase openai openpyxl
# ----------------------
import subprocess
import sys
import io # Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Ñ„Ğ°Ğ¹Ğ»Ğ°Ğ¼Ğ¸ Ğ² Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸
import os
import json
import asyncio
from datetime import datetime

import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
from openai import AsyncOpenAI
from supabase import create_client, Client


# ----------------------
# 2. ĞšĞ¾Ğ½ÑÑ‚Ğ°Ğ½Ñ‚Ñ‹
# ----------------------
DEESEEK_API_URL = "https://api.studio.nebius.ai/v1/"


# ----------------------
# 3. Ğ’ÑĞ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸
# ----------------------

@st.cache_data
def load_data(file_path: str) -> pd.DataFrame:
    """Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ· Excel-Ñ„Ğ°Ğ¹Ğ»Ğ°."""
    df = pd.read_excel(file_path)
    df.columns = [str(col).strip().lower() if isinstance(col, str) else col for col in df.columns]
    if 'data' in df.columns:
        df['data'] = pd.to_datetime(df['data'], errors='coerce')
    return df

def to_excel(df: pd.DataFrame) -> bytes:
    """ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ DataFrame Ğ² Ğ±Ğ°Ğ¹Ñ‚Ñ‹ Excel-Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ´Ğ»Ñ ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ."""
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='Ğ¥Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸')
    return output.getvalue()

def run_async(coro):
    """Ğ‘ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°ĞµÑ‚ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½ÑƒÑ ĞºĞ¾Ñ€ÑƒÑ‚Ğ¸Ğ½Ñƒ Ğ² Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğ¸ Streamlit."""
    try:
        loop = asyncio.get_running_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
    return loop.run_until_complete(coro)

def convert_sentiment_to_10_point(score: float) -> float:
    """ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‚Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¸Ğ· Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğ° [-1, 1] Ğ² [1, 10]."""
    if not isinstance(score, (int, float)):
        return 5.5
    return (score + 1) * 4.5 + 1


# ----------------------
# 4. Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ API (Supabase Ğ¸ LLM)
# ----------------------

@st.cache_resource
def init_supabase_client():
    """Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¸ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ĞºĞ»Ğ¸ĞµĞ½Ñ‚ Supabase."""
    try:
        supabase_url = st.secrets["SUPABASE_URL"]
        supabase_key = st.secrets["SUPABASE_KEY"]
        return create_client(supabase_url, supabase_key)
    except KeyError as e:
        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ°: ĞºĞ»ÑÑ‡ '{e.args[0]}' Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ² ÑĞµĞºÑ€ĞµÑ‚Ğ°Ñ… Streamlit.")
        return None
    except Exception as e:
        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğº Supabase: {e}")
        return None

@st.cache_data(ttl=300)
def get_report_list_from_supabase(_supabase: Client) -> list:
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ ÑĞ¿Ğ¸ÑĞ¾Ğº ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¸Ğ¼ĞµĞ½ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ¾Ğ² Ğ¸Ğ· Supabase."""
    try:
        response = _supabase.table('reports').select('report_name', count='exact').execute()
        return sorted(list(set(item['report_name'] for item in response.data)), reverse=True) if response.data else []
    except Exception as e:
        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ ÑĞ¿Ğ¸ÑĞºĞ° Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ¾Ğ² Ğ¸Ğ· Supabase: {e}")
        return []

@st.cache_data
def load_report_from_supabase(_supabase: Client, report_name: str) -> pd.DataFrame:
    """Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ Ğ²ÑĞµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ° Ğ¸Ğ· Supabase Ğ² DataFrame."""
    try:
        response = _supabase.table('reports').select('*').eq('report_name', report_name).execute()
        df = pd.DataFrame(response.data)
        if 'data' in df.columns:
            df['data'] = pd.to_datetime(df['data'], errors='coerce')
        if not df.empty:
            df = df.drop(columns=['id', 'created_at', 'report_name'], errors='ignore')
        return df
    except Exception as e:
        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞµ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ° '{report_name}': {e}")
        return pd.DataFrame()

async def analyze_reflection_with_deepseek(client: AsyncOpenAI, text: str) -> dict:
    """ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‚ĞµĞºÑÑ‚ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¸ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…."""
    # ... (ĞºĞ¾Ğ´ ÑÑ‚Ğ¾Ğ¹ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹)
    error_result = {"sentiment_score": 0.0, "learning_feedback": "N/A", "teamwork_feedback": "N/A", "organization_feedback": "N/A", "learning_sentiment_score": 0.0, "teamwork_sentiment_score": 0.0, "organization_sentiment_score": 0.0}
    if not text or not isinstance(text, str) or not text.strip(): return error_result
    prompt = ("Ğ¢Ñ‹ â€” Ğ˜Ğ˜-Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚... (Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ Ğ²Ğ°ÑˆĞµĞ³Ğ¾ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ°)") # ĞÑÑ‚Ğ°Ğ²Ğ¸Ğ» ÑĞ¾ĞºÑ€Ğ°Ñ‰ĞµĞ½Ğ½Ğ¾ Ğ´Ğ»Ñ Ñ‡Ğ¸Ñ‚Ğ°ĞµĞ¼Ğ¾ÑÑ‚Ğ¸
    try:
        response = await client.chat.completions.create(model="deepseek-ai/DeepSeek-V3", messages=[{"role": "user", "content": prompt}], temperature=0.2, response_format={"type": "json_object"})
        result = json.loads(response.choices[0].message.content)
        for key, value in error_result.items(): result.setdefault(key, value)
        return result
    except Exception as e:
        print(f"Error processing text: '{text[:50]}...'. Error: {e}")
        return error_result

async def generate_nomination_with_llm(client: AsyncOpenAI, reflections: str) -> str:
    """Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑˆÑƒÑ‚Ğ¾Ñ‡Ğ½ÑƒÑ Ğ½Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¹ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ°."""
    if not reflections or not reflections.strip():
        reflections = "Ğ£Ñ‡Ğ°ÑÑ‚Ğ½Ğ¸Ğº Ğ±Ñ‹Ğ» ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ¿Ğ¾Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ğ² Ğ²ĞµĞ»Ğ¸ĞºĞ¸Ğµ Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ğµ Ğ´ĞµĞ»Ğ° Ğ¸ Ğ½Ğµ Ğ¾ÑÑ‚Ğ°Ğ²Ğ¸Ğ» Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¹."
    prompt = ( "Ğ¢Ñ‹ â€” ĞºÑ€ĞµĞ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ°Ğ¹Ñ‚ĞµÑ€ Ğ´Ğ»Ñ Ğ´ĞµÑ‚ÑĞºĞ¾Ğ³Ğ¾ Ğ½Ğ°ÑƒÑ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ»Ğ°Ğ³ĞµÑ€Ñ... (Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ Ğ²Ğ°ÑˆĞµĞ³Ğ¾ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ°)" ) # ĞÑÑ‚Ğ°Ğ²Ğ¸Ğ» ÑĞ¾ĞºÑ€Ğ°Ñ‰ĞµĞ½Ğ½Ğ¾
    try:
        response = await client.chat.completions.create(model="deepseek-ai/DeepSeek-V3", messages=[{"role": "user", "content": prompt}], temperature=0.7, max_tokens=50)
        return response.choices[0].message.content.strip().strip('"')
    except Exception as e:
        print(f"Error generating nomination: {e}")
        return "ĞœĞ°ÑÑ‚ĞµÑ€ ĞĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸"

async def generate_character_description_with_llm(client: AsyncOpenAI, name: str, reflections: str) -> str:
    """Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑˆÑƒÑ‚Ğ¾Ñ‡Ğ½ÑƒÑ, Ğ½Ğ¾ Ğ´Ğ¾Ğ±Ñ€ÑƒÑ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºÑƒ Ğ½Ğ° ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ°."""
    is_empty_reflection = not reflections or not reflections.strip()
    if is_empty_reflection:
        reflections = "Ğ ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¸ Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒÑÑ‚..." # ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ Ğ²Ğ°ÑˆĞµĞ³Ğ¾ "Ğ¿ÑƒÑÑ‚Ğ¾Ğ³Ğ¾" ÑĞ»ÑƒÑ‡Ğ°Ñ
    prompt = ( f"Ğ¢Ñ‹ â€” Ğ´Ğ¾Ğ±Ñ€Ñ‹Ğ¹ Ğ¸ Ğ¼ÑƒĞ´Ñ€Ñ‹Ğ¹ Ğ½Ğ°ÑÑ‚Ğ°Ğ²Ğ½Ğ¸Ğº... (Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ Ğ²Ğ°ÑˆĞµĞ³Ğ¾ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ° Ñ Ğ¸Ğ¼ĞµĞ½ĞµĞ¼ {name})" ) # ĞÑÑ‚Ğ°Ğ²Ğ¸Ğ» ÑĞ¾ĞºÑ€Ğ°Ñ‰ĞµĞ½Ğ½Ğ¾
    try:
        response = await client.chat.completions.create(model="deepseek-ai/DeepSeek-V3", messages=[{"role": "user", "content": prompt}], temperature=0.8, max_tokens=400)
        return response.choices[0].message.content
    except Exception as e:
        print(f"Error generating description: {e}")
        return f"Ğš ÑĞ¾Ğ¶Ğ°Ğ»ĞµĞ½Ğ¸Ñ, Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸ Ğ´Ğ»Ñ {name} Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ¾ÑˆĞ»Ğ° ĞºĞ¾ÑĞ¼Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ñ. ĞĞ¾ Ğ¼Ñ‹ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ·Ğ½Ğ°ĞµĞ¼, Ñ‡Ñ‚Ğ¾ {name} â€” Ğ·Ğ°Ğ¼ĞµÑ‡Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞº, Ğ¸ Ğ¶ĞµĞ»Ğ°ĞµĞ¼ ĞµĞ¼Ñƒ Ğ¾Ğ³Ñ€Ğ¾Ğ¼Ğ½Ñ‹Ñ… ÑƒÑĞ¿ĞµÑ…Ğ¾Ğ² Ğ²Ğ¾ Ğ²ÑĞµÑ… Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°Ğ½Ğ¸ÑÑ…!"


# ----------------------
# 5. ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° Ğ¸ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´ Ğ½Ğ° Streamlit
# ----------------------
def main():
    st.set_page_config(layout="wide", page_title="ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¹")
    st.title("Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¹ ÑƒÑ‡Ğ°Ñ‰Ğ¸Ñ…ÑÑ")

    with st.expander("â„¹ï¸ Ğ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğµ: Ñ‡Ñ‚Ğ¾ ÑÑ‚Ğ¾ Ğ¸ ĞºĞ°Ğº Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ?", expanded=False):
        st.markdown(""" ... (Ğ²Ğ°Ñˆ Ñ‚ĞµĞºÑÑ‚ Ğ¾ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğµ) ... """)

    # --- Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ² ---
    supabase = init_supabase_client()
    if not supabase:
        st.stop()
    try:
        api_key = st.secrets["DEEPSEEK_API_KEY"]
        client = AsyncOpenAI(base_url=DEESEEK_API_URL, api_key=api_key)
    except KeyError:
        st.error("ĞÑˆĞ¸Ğ±ĞºĞ° ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸: Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ ĞºĞ»ÑÑ‡ `DEEPSEEK_API_KEY` Ğ² ÑĞµĞºÑ€ĞµÑ‚Ğ°Ñ… Streamlit.")
        st.stop()

    # --- Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ---
    st.sidebar.header("ğŸ—‚ï¸ Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…")
    report_files = get_report_list_from_supabase(supabase)
    data_source_options = ["ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·"] + report_files
    selected_source = st.sidebar.selectbox("Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ¾Ñ‚Ñ‡ĞµÑ‚ Ğ¸Ğ»Ğ¸ Ğ½Ğ°Ñ‡Ğ½Ğ¸Ñ‚Ğµ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·:", data_source_options)

    df = None
    if selected_source != "ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·":
        df = load_report_from_supabase(supabase, selected_source)
        st.session_state['current_file_name'] = selected_source
    else:
        uploaded_file = st.sidebar.file_uploader("Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ Excel-Ñ„Ğ°Ğ¹Ğ»:", type="xlsx")
        if uploaded_file:
            st.session_state['current_file_name'] = uploaded_file.name
            df = load_data(uploaded_file)
            df['text'] = df['text'].astype(str).fillna('')

    if df is None:
        st.info("ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ Ñ„Ğ°Ğ¹Ğ» Ğ¸Ğ»Ğ¸ Ğ²Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ¾Ñ‚Ñ‡ĞµÑ‚ Ğ² Ğ±Ğ¾ĞºĞ¾Ğ²Ğ¾Ğ¹ Ğ¿Ğ°Ğ½ĞµĞ»Ğ¸.")
        st.stop()

    # --- ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¸ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ---
    session_key = f"df_processed_{st.session_state.get('current_file_name', 'default')}"
    if session_key not in st.session_state:
        if selected_source == "ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·":
            with st.spinner('Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ÑÑ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¹... Ğ­Ñ‚Ğ¾ Ğ·Ğ°Ğ¹Ğ¼ĞµÑ‚ Ğ½ĞµĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğµ Ğ²Ñ€ĞµĞ¼Ñ.'):
                tasks = [analyze_reflection_with_deepseek(client, text) for text in df['text']]
                results = run_async(asyncio.gather(*tasks))
                results_df = pd.DataFrame(results)
                df = pd.concat([df.reset_index(drop=True), results_df.reset_index(drop=True)], axis=1)

        for col in ['sentiment_score', 'learning_sentiment_score', 'teamwork_sentiment_score', 'organization_sentiment_score']:
            if col in df.columns:
                df[col.replace('_score', '_10_point')] = df[col].apply(convert_sentiment_to_10_point)
        st.session_state[session_key] = df
    
    df = st.session_state[session_key]

    # --- Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹ ---
    st.sidebar.header("ğŸ“Š Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹")
    filtered_df = df.copy()
    if 'data' in filtered_df.columns and not filtered_df['data'].dropna().empty:
        min_date, max_date = filtered_df['data'].min().date(), filtered_df['data'].max().date()
        if min_date != max_date:
            start_date, end_date = st.sidebar.slider("Ğ”Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ Ğ´Ğ°Ñ‚:", min_date, max_date, (min_date, max_date))
            mask = (filtered_df['data'].dt.date >= start_date) & (filtered_df['data'].dt.date <= end_date)
            filtered_df = filtered_df.loc[mask]

    if filtered_df.empty:
        st.warning("ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ñ‹Ğ¼ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ğ¼.")
        st.stop()

    # --- Ğ‘Ğ›ĞĞš ĞœĞĞ¡Ğ¡ĞĞ’ĞĞ™ Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ˜ Ğ˜ Ğ¡ĞšĞĞ§Ğ˜Ğ’ĞĞĞ˜Ğ¯ ---
    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ“ Ğ’Ñ‹Ğ¿ÑƒÑĞºĞ½Ñ‹Ğµ Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»Ñ‹")
    if st.sidebar.button("Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸ Ğ´Ğ»Ñ Ğ²ÑĞµÑ…"):
        unique_students = filtered_df['username'].unique()
        
        async def generate_all_creative_content():
            tasks = []
            for student_name in unique_students:
                student_reflections = " ".join(filtered_df[filtered_df['username'] == student_name]['text'].dropna().astype(str))
                tasks.append(generate_nomination_with_llm(client, student_reflections))
                tasks.append(generate_character_description_with_llm(client, student_name, student_reflections))
            
            all_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            final_data = []
            for i, student_name in enumerate(unique_students):
                nomination, description = all_results[i*2], all_results[i*2 + 1]
                final_data.append({
                    "Ğ£Ñ‡ĞµĞ½Ğ¸Ğº": student_name,
                    "ĞĞ¾Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ": "ĞÑˆĞ¸Ğ±ĞºĞ°" if isinstance(nomination, Exception) else nomination,
                    "Ğ¥Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ°": f"ĞÑˆĞ¸Ğ±ĞºĞ°: {description}" if isinstance(description, Exception) else description,
                })
            return pd.DataFrame(final_data)

        with st.sidebar.spinner(f"Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ° Ğ´Ğ»Ñ {len(unique_students)} ÑƒÑ‡ĞµĞ½Ğ¸ĞºĞ¾Ğ²..."):
            creative_df = run_async(generate_all_creative_content())
            if not creative_df.empty:
                st.session_state['downloadable_excel'] = to_excel(creative_df)
                st.session_state['excel_filename'] = f"Ğ¥Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸_{datetime.now().strftime('%Y-%m-%d')}.xlsx"
                st.sidebar.success("Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾! Ğ¤Ğ°Ğ¹Ğ» Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ ÑĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ.")
            else:
                st.sidebar.error("ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ.")

    if 'downloadable_excel' in st.session_state:
        st.sidebar.download_button(
            label="ğŸ“¥ Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ñ„Ğ°Ğ¹Ğ» Excel",
            data=st.session_state['downloadable_excel'],
            file_name=st.session_state['excel_filename'],
            mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )

    # --- ĞĞ¡ĞĞĞ’ĞĞĞ™ ĞšĞĞĞ¢Ğ•ĞĞ¢ Ğ”ĞĞ¨Ğ‘ĞĞ Ğ”Ğ ---
    st.header("ĞĞ±Ñ‰Ğ°Ñ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ° Ğ¸ Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ¾Ğ²Ğ¾Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·")
    # ... (Ğ²ĞµÑÑŒ Ğ²Ğ°Ñˆ ĞºĞ¾Ğ´ Ğ´Ğ»Ñ Ğ¾Ñ‚Ñ€Ğ¸ÑĞ¾Ğ²ĞºĞ¸ Ğ¾Ğ±Ñ‰Ğ¸Ñ… Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¾Ğ² Ğ¸ Ñ‚ĞµĞ¿Ğ»Ğ¾Ğ²Ğ¾Ğ¹ ĞºĞ°Ñ€Ñ‚Ñ‹)

    st.header("ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ğ¾ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğ¼ ÑƒÑ‡Ğ°Ñ‰Ğ¸Ğ¼ÑÑ")
    student_list = sorted(filtered_df['username'].unique())
    if student_list:
        student = st.selectbox("Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ ÑƒÑ‡ĞµĞ½Ğ¸ĞºĞ°:", student_list)
        if student:
            student_df = filtered_df[filtered_df['username'] == student].sort_values('data')
            # ... (Ğ²Ğ°Ñˆ ĞºĞ¾Ğ´ Ğ´Ğ»Ñ Ğ¾Ñ‚Ñ€Ğ¸ÑĞ¾Ğ²ĞºĞ¸ Ğ¸Ğ½Ğ´Ğ¸Ğ²Ğ¸Ğ´ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¾Ğ² ÑƒÑ‡ĞµĞ½Ğ¸ĞºĞ°)

            # --- Ğ‘Ğ›ĞĞš Ğ˜ĞĞ”Ğ˜Ğ’Ğ˜Ğ”Ğ£ĞĞ›Ğ¬ĞĞĞ™ Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ˜ ---
            st.markdown("---")
            st.subheader(f"âœ¨ ĞšÑ€ĞµĞ°Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ´Ğ»Ñ {student}")
            full_reflection_text = " ".join(student_df['text'].dropna().astype(str))
            if st.button(f"Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ´Ğ»Ñ {student}"):
                with st.spinner("ĞœĞ°Ğ³Ğ¸Ñ Ñ‚Ğ²Ğ¾Ñ€Ğ¸Ñ‚ÑÑ..."):
                    async def get_content():
                        return await asyncio.gather(
                            generate_nomination_with_llm(client, full_reflection_text),
                            generate_character_description_with_llm(client, student, full_reflection_text)
                        )
                    nomination, description = run_async(get_content())
                    st.session_state[f'nomination_{student}'] = nomination
                    st.session_state[f'description_{student}'] = description

            if f'nomination_{student}' in st.session_state:
                st.success(f"**ĞĞ¾Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ:** {st.session_state[f'nomination_{student}']}")
            if f'description_{student}' in st.session_state:
                st.markdown(st.session_state[f'description_{student}'])
            
            # --- Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° Ñ Ğ´ĞµÑ‚Ğ°Ğ»ÑĞ¼Ğ¸ ---
            st.markdown("---")
            st.subheader("Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¹")
            # ... (Ğ²Ğ°Ñˆ ĞºĞ¾Ğ´ Ğ´Ğ»Ñ expander Ğ¸ st.dataframe)

    # ... (Ğ²Ğ°Ñˆ ĞºĞ¾Ğ´ Ğ´Ğ»Ñ Ğ·Ğ¾Ğ½Ñ‹ Ñ€Ğ¸ÑĞºĞ° Ğ¸ Ñ‚.Ğ´.)


# ----------------------
# 6. Ğ¢Ğ¾Ñ‡ĞºĞ° Ğ²Ñ…Ğ¾Ğ´Ğ° Ğ² Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ
# ----------------------
if __name__ == "__main__":
    main()
