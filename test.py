# 1. Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹ (Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹)
# ----------------------
import subprocess
import sys


# ----------------------
# 2. Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ñ‹ Ğ¸ ĞºĞ¾Ğ½ÑÑ‚Ğ°Ğ½Ñ‚Ñ‹
# ----------------------
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import json
from openai import AsyncOpenAI
import asyncio
import numpy as np
import os

### ĞĞĞ’ĞĞ•: Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ñ‹ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Supabase
from supabase import create_client, Client

# ĞšĞ¾Ğ½ÑÑ‚Ğ°Ğ½Ñ‚Ñ‹ Ğ´Ğ»Ñ API DeepSeek
DEESEEK_API_URL = "https://api.studio.nebius.ai/v1/"

# ----------------------
# 3. Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… (Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹)
# ----------------------
@st.cache_data
def load_data(file_path: str) -> pd.DataFrame:
    df = pd.read_excel(file_path)
    # ĞŸÑ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ ĞºĞ¾Ğ»Ğ¾Ğ½Ğ¾Ğº Ğº Ğ½Ğ¸Ğ¶Ğ½ĞµĞ¼Ñƒ Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ñƒ Ğ¸ ÑƒĞ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ñ‹
    df.columns = [str(col).strip().lower() if isinstance(col, str) else col for col in df.columns]
    if 'data' in df.columns:
        df['data'] = pd.to_datetime(df['data'], errors='coerce')
    return df

# ----------------------
# 4. Ğ‘Ğ›ĞĞš ĞŸĞ Ğ•Ğ”ĞĞ‘Ğ ĞĞ‘ĞĞ¢ĞšĞ˜ Ğ¢Ğ•ĞšĞ¡Ğ¢Ğ (NLP) - Ğ£Ğ”ĞĞ›Ğ•Ğ
# ----------------------

# ----------------------
# 5. DeepSeek API Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· (Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹)
# ----------------------
async def analyze_reflection_with_deepseek(client: AsyncOpenAI, text: str) -> dict:
    """
    ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‚ĞµĞºÑÑ‚ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¸ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ DeepSeek API.
    """
    error_result = {
        "sentiment_score": 0.0,
        "learning_feedback": "N/A",
        "teamwork_feedback": "N/A",
        "organization_feedback": "N/A",
        "learning_sentiment_score": 0.0,
        "teamwork_sentiment_score": 0.0,
        "organization_sentiment_score": 0.0,
    }
    if not text or not isinstance(text, str) or not text.strip():
        return error_result

    prompt = (
        "Ğ¢Ñ‹ â€” Ğ˜Ğ˜-Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ² Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¸. ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ñ ÑˆĞºĞ¾Ğ»ÑŒĞ½Ğ¸ĞºĞ°. "
        "Ğ¢Ğ²Ğ¾Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ° â€” Ğ²ĞµÑ€Ğ½ÑƒÑ‚ÑŒ JSON-Ğ¾Ğ±ÑŠĞµĞºÑ‚ ÑĞ¾ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¼Ğ¸ ĞºĞ»ÑÑ‡Ğ°Ğ¼Ğ¸:\n"
        "1. 'sentiment_score': Ğ¾Ğ±Ñ‰Ğ°Ñ Ñ‚Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ñ‚ĞµĞºÑÑ‚Ğ°, Ñ‡Ğ¸ÑĞ»Ğ¾ Ğ¾Ñ‚ -1.0 (Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²) Ğ´Ğ¾ 1.0 (Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²).\n"
        "2. 'learning_feedback': ĞºÑ€Ğ°Ñ‚ĞºĞ°Ñ Ğ²Ñ‹Ğ¶Ğ¸Ğ¼ĞºĞ° (1-2 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ) Ğ¸Ğ· Ñ‚ĞµĞºÑÑ‚Ğ° Ğ¾Ğ± Ğ¾Ñ†ĞµĞ½ĞºĞµ ÑƒÑ‡ĞµĞ±Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ°.\n"
        "3. 'teamwork_feedback': ĞºÑ€Ğ°Ñ‚ĞºĞ°Ñ Ğ²Ñ‹Ğ¶Ğ¸Ğ¼ĞºĞ° (1-2 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ) Ğ¾Ğ± Ğ¾Ñ†ĞµĞ½ĞºĞµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ğ² ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğµ.\n"
        "4. 'organization_feedback': ĞºÑ€Ğ°Ñ‚ĞºĞ°Ñ Ğ²Ñ‹Ğ¶Ğ¸Ğ¼ĞºĞ° (1-2 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ) Ğ¾Ğ± Ğ¾Ñ†ĞµĞ½ĞºĞµ Ğ¾Ñ€Ğ³Ğ°Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ğ´Ğ¾ÑÑƒĞ³Ğ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ².\n"
        "5. 'learning_sentiment_score': Ñ‚Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¢ĞĞ›Ğ¬ĞšĞ Ñ‡Ğ°ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¾ ÑƒÑ‡Ñ‘Ğ±Ñƒ (Ğ¾Ñ‚ -1.0 Ğ´Ğ¾ 1.0). Ğ•ÑĞ»Ğ¸ Ğ½Ğµ ÑƒĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°ĞµÑ‚ÑÑ, Ğ²ĞµÑ€Ğ½Ğ¸ 0.0.\n"
        "6. 'teamwork_sentiment_score': Ñ‚Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¢ĞĞ›Ğ¬ĞšĞ Ñ‡Ğ°ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¾ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñƒ (Ğ¾Ñ‚ -1.0 Ğ´Ğ¾ 1.0). Ğ•ÑĞ»Ğ¸ Ğ½Ğµ ÑƒĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°ĞµÑ‚ÑÑ, Ğ²ĞµÑ€Ğ½Ğ¸ 0.0.\n"
        "7. 'organization_sentiment_score': Ñ‚Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¢ĞĞ›Ğ¬ĞšĞ Ñ‡Ğ°ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¾ Ğ¾Ñ€Ğ³Ğ°Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ (Ğ¾Ñ‚ -1.0 Ğ´Ğ¾ 1.0). Ğ•ÑĞ»Ğ¸ Ğ½Ğµ ÑƒĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°ĞµÑ‚ÑÑ, Ğ²ĞµÑ€Ğ½Ğ¸ 0.0.\n\n"
        "Ğ•ÑĞ»Ğ¸ ĞºĞ°ĞºĞ¾Ğ¹-Ñ‚Ğ¾ Ğ°ÑĞ¿ĞµĞºÑ‚ Ğ² Ñ‚ĞµĞºÑÑ‚Ğµ Ğ½Ğµ ÑƒĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°ĞµÑ‚ÑÑ, Ğ´Ğ»Ñ ĞºĞ»ÑÑ‡ĞµĞ¹ feedback Ğ¾ÑÑ‚Ğ°Ğ²ÑŒ Ğ¿ÑƒÑÑ‚ÑƒÑ ÑÑ‚Ñ€Ğ¾ĞºÑƒ, Ğ° Ğ´Ğ»Ñ ĞºĞ»ÑÑ‡ĞµĞ¹ sentiment_score Ğ²ĞµÑ€Ğ½Ğ¸ 0.0.\n\n"
        f"Ğ¢ĞµĞºÑÑ‚ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°: \"{text}\""
    )

    try:
        response = await client.chat.completions.create(
            model="deepseek-ai/DeepSeek-V3",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            response_format={"type": "json_object"}
        )
        content = response.choices[0].message.content
        result = json.loads(content)
        for key, value in error_result.items():
            if key not in result:
                result[key] = value
        return result

    except Exception as e:
        print(f"Error processing text: '{text[:50]}...'. Error: {e}")
        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğµ DeepSeek API: {e}")
        return error_result

# ----------------------
# ĞĞĞ’Ğ«Ğ• Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜ Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ˜ (Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ)
# ----------------------

async def _get_one_nomination(client: AsyncOpenAI, username: str, text: str) -> dict:
    """Ğ’ÑĞ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ½Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸."""
    prompt = (
        "Ğ¢Ñ‹ â€” Ğ˜Ğ˜-Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚, Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑÑ‰Ğ¸Ğ¹ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¸ ÑˆĞºĞ¾Ğ»ÑŒĞ½Ğ¸ĞºĞ¾Ğ² Ñ Ğ¼Ğ¾Ñ€ÑĞºĞ¾Ğ¹ Ğ½Ğ°ÑƒÑ‡Ğ½Ğ¾-Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ½Ğ¾Ğ¹ ÑĞ¼ĞµĞ½Ñ‹. "
        f"ĞĞ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¹ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ° Ğ¿Ğ¾ Ğ¸Ğ¼ĞµĞ½Ğ¸ {username}: \"{text}\", Ğ¿Ñ€Ğ¸ÑĞ²Ğ¾Ğ¹ ÑˆÑƒÑ‚Ğ¾Ñ‡Ğ½ÑƒÑ Ğ½Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ Ğ² Ğ¼Ğ¾Ñ€ÑĞºĞ¾Ğ¹ Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞµ "
        "(Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, 'ĞšĞ°Ğ¿Ğ¸Ñ‚Ğ°Ğ½ Ğ“ĞµĞ½Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸', 'Ğ˜Ğ½Ğ¶ĞµĞ½ĞµÑ€ Ğ“Ğ»ÑƒĞ±Ğ¸Ğ½') Ğ¸ Ğ´Ğ°Ğ¹ ĞºÑ€Ğ°Ñ‚ĞºĞ¾Ğµ Ğ¾Ğ±Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ (1-2 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ), "
        "Ğ¿Ğ¾Ñ‡ĞµĞ¼Ñƒ Ğ¾Ğ½Ğ° Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¸Ñ‚, Ğ¾ÑĞ½Ğ¾Ğ²Ñ‹Ğ²Ğ°ÑÑÑŒ Ğ½Ğ° ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ğ½Ğ¸Ğ¸ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¹. ĞĞ¾Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ Ğ¸ Ğ¾Ğ±Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼Ğ¸, "
        "Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğ¼Ğ¸ Ğ´Ğ»Ñ ÑˆĞºĞ¾Ğ»ÑŒĞ½Ğ¸ĞºĞ¾Ğ² Ğ¸ ÑĞ²ÑĞ·Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ñ Ğ¼Ğ¾Ñ€ÑĞºĞ¾Ğ¹/Ğ½Ğ°ÑƒÑ‡Ğ½Ğ¾-Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞ¾Ğ¹. "
        "Ğ’ĞµÑ€Ğ½Ğ¸ JSON-Ğ¾Ğ±ÑŠĞµĞºÑ‚: {\"nomination\": str, \"justification\": str}."
    )
    default_result = {"nomination": "ĞœĞ¾Ñ€ÑĞºĞ¾Ğ¹ Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ", "justification": "Ğ—Ğ° Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ ÑƒÑ‡Ğ°ÑÑ‚Ğ¸Ğµ Ğ² Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğµ!"}
    
    try:
        response = await client.chat.completions.create(
            model="deepseek-ai/DeepSeek-V3",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            response_format={"type": "json_object"}
        )
        result = json.loads(response.choices[0].message.content)
        if 'nomination' not in result or 'justification' not in result:
             return default_result
        return result
    except Exception as e:
        print(f"Error generating nomination for {username}: {e}")
        return default_result

# Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ˜Ğ•: Ğ­Ñ‚Ğ¾ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½ÑÑ async-Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ±ĞµĞ· Ğ´ĞµĞºĞ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ°
async def _generate_nominations_async(_df: pd.DataFrame, client: AsyncOpenAI) -> pd.DataFrame:
    """ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑˆÑƒÑ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ğ½Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ°."""
    user_reflections = _df.groupby('username')['text'].apply(lambda texts: ' '.join(texts.astype(str).str.strip())).reset_index()
    
    tasks = [
        _get_one_nomination(client, row['username'], row['text']) 
        for index, row in user_reflections.iterrows()
    ]
    results = await asyncio.gather(*tasks)
    
    results_df = pd.DataFrame(results)
    final_df = pd.concat([user_reflections[['username']], results_df], axis=1)
    final_df = final_df.rename(columns={'username': 'Ğ¤Ğ˜Ğ', 'nomination': 'ĞĞ¾Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ', 'justification': 'ĞĞ±Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ'})
    return final_df

# Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ˜Ğ•: Ğ­Ñ‚Ğ¾ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ-Ğ¾Ğ±ĞµÑ€Ñ‚ĞºĞ°, ĞºĞ¾Ñ‚Ğ¾Ñ€ÑƒÑ Ğ¼Ñ‹ ĞºĞµÑˆĞ¸Ñ€ÑƒĞµĞ¼
@st.cache_data(show_spinner=False, hash_funcs={AsyncOpenAI: lambda _: None})
def get_cached_nominations(_df: pd.DataFrame, client: AsyncOpenAI) -> pd.DataFrame:
    """Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµÑ‚ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½ÑƒÑ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ½Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¹ Ğ¸ ĞºĞµÑˆĞ¸Ñ€ÑƒĞµÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ (DataFrame)."""
    return asyncio.run(_generate_nominations_async(_df, client))

async def _get_one_friendly_reflection(client: AsyncOpenAI, username: str, text: str) -> dict:
    """Ğ’ÑĞ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ´Ñ€ÑƒĞ¶ĞµĞ»ÑĞ±Ğ½Ğ¾Ğ¹ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¸."""
    prompt = (
        "Ğ¢Ñ‹ â€” Ğ˜Ğ˜-Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚, ÑÑƒĞ¼Ğ¼Ğ¸Ñ€ÑƒÑÑ‰Ğ¸Ğ¹ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¸ ÑˆĞºĞ¾Ğ»ÑŒĞ½Ğ¸ĞºĞ¾Ğ² Ñ Ğ¼Ğ¾Ñ€ÑĞºĞ¾Ğ¹ Ğ½Ğ°ÑƒÑ‡Ğ½Ğ¾-Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ½Ğ¾Ğ¹ ÑĞ¼ĞµĞ½Ñ‹. "
        f"ĞĞ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¹ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ° Ğ¿Ğ¾ Ğ¸Ğ¼ĞµĞ½Ğ¸ {username}: \"{text}\", ÑĞ¾Ğ·Ğ´Ğ°Ğ¹ Ğ´Ñ€ÑƒĞ¶ĞµĞ»ÑĞ±Ğ½Ğ¾Ğµ, ÑˆÑƒÑ‚Ğ¾Ñ‡Ğ½Ğ¾Ğµ Ñ€ĞµĞ·ÑĞ¼Ğµ ĞµĞ³Ğ¾ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¹ (2-3 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ) "
        "Ğ¸ Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ½Ğ°Ğ¿ÑƒÑ‚ÑÑ‚Ğ²Ğ¸Ğµ (1-2 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ) Ğ´Ğ»Ñ Ğ¼Ğ¾Ñ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ğ¸. Ğ¢Ğ¾Ğ½ Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼, Ğ½Ğµ Ğ¾Ğ±Ğ¸Ğ´Ğ½Ñ‹Ğ¼, "
        "Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğ¼ Ğ´Ğ»Ñ ÑˆĞºĞ¾Ğ»ÑŒĞ½Ğ¸ĞºĞ¾Ğ², Ñ ÑƒÑ‡ĞµÑ‚Ğ¾Ğ¼ Ğ¼Ğ¾Ñ€ÑĞºĞ¾Ğ¹/Ğ½Ğ°ÑƒÑ‡Ğ½Ğ¾-Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞ¸ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ ÑĞ»Ğ¾Ğ²Ğ° 'ĞºÑƒÑ€Ñ', 'Ğ¿Ğ»Ğ°Ğ²Ğ°Ğ½Ğ¸Ğµ', 'Ğ³Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ½Ñ‚Ñ‹'). "
        "Ğ’ĞµÑ€Ğ½Ğ¸ JSON-Ğ¾Ğ±ÑŠĞµĞºÑ‚: {\"reflection\": str, \"encouragement\": str}."
    )
    default_result = {"reflection": "Ğ¢Ñ‹ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾ ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑˆÑŒÑÑ Ñ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°Ğ¼Ğ¸!", "encouragement": "ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°Ğ¹ Ğ² Ñ‚Ğ¾Ğ¼ Ğ¶Ğµ Ğ´ÑƒÑ…Ğµ Ğ¸ Ğ¿Ğ¾ĞºĞ¾Ñ€ÑĞ¹ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ³Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ½Ñ‚Ñ‹!"}
    
    try:
        response = await client.chat.completions.create(
            model="deepseek-ai/DeepSeek-V3",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            response_format={"type": "json_object"}
        )
        result = json.loads(response.choices[0].message.content)
        if 'reflection' not in result or 'encouragement' not in result:
             return default_result
        return result
    except Exception as e:
        print(f"Error generating friendly reflection for {username}: {e}")
        return default_result

# Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ˜Ğ•: Ğ­Ñ‚Ğ¾ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½ÑÑ async-Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ±ĞµĞ· Ğ´ĞµĞºĞ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ°
async def _generate_friendly_reflections_async(_df: pd.DataFrame, client: AsyncOpenAI) -> pd.DataFrame:
    """ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ´Ñ€ÑƒĞ¶ĞµĞ»ÑĞ±Ğ½Ñ‹Ğµ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¸ Ğ¸ Ğ½Ğ°Ğ¿ÑƒÑ‚ÑÑ‚Ğ²Ğ¸Ñ Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ°."""
    user_reflections = _df.groupby('username')['text'].apply(lambda texts: ' '.join(texts.astype(str).str.strip())).reset_index()

    tasks = [
        _get_one_friendly_reflection(client, row['username'], row['text'])
        for index, row in user_reflections.iterrows()
    ]
    results = await asyncio.gather(*tasks)
    
    results_df = pd.DataFrame(results)
    final_df = pd.concat([user_reflections[['username']], results_df], axis=1)
    final_df = final_df.rename(columns={'username': 'Ğ¤Ğ˜Ğ', 'reflection': 'Ğ ĞµÑ„Ğ»ĞµĞºÑĞ¸Ñ', 'encouragement': 'ĞŸĞ¾Ğ¶ĞµĞ»Ğ°Ğ½Ğ¸Ğµ'})
    return final_df

# Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ˜Ğ•: Ğ­Ñ‚Ğ¾ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ-Ğ¾Ğ±ĞµÑ€Ñ‚ĞºĞ°, ĞºĞ¾Ñ‚Ğ¾Ñ€ÑƒÑ Ğ¼Ñ‹ ĞºĞµÑˆĞ¸Ñ€ÑƒĞµĞ¼
@st.cache_data(show_spinner=False, hash_funcs={AsyncOpenAI: lambda _: None})
def get_cached_friendly_reflections(_df: pd.DataFrame, client: AsyncOpenAI) -> pd.DataFrame:
    """Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµÑ‚ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½ÑƒÑ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¹ Ğ¸ ĞºĞµÑˆĞ¸Ñ€ÑƒĞµÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ (DataFrame)."""
    return asyncio.run(_generate_friendly_reflections_async(_df, client))


# ----------------------
# 6. ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ñ Ñ‚Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ (Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹)
# ----------------------
def convert_sentiment_to_10_point(score: float) -> float:
    if not isinstance(score, (int, float)):
        return 5.5
    return (score + 1) * 4.5 + 1

# ----------------------
# 7. Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Supabase (Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹)
# ----------------------
@st.cache_resource
def init_supabase_client():
    """Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¸ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ĞºĞ»Ğ¸ĞµĞ½Ñ‚ Supabase."""
    try:
        supabase_url = st.secrets["SUPABASE_URL"]
        supabase_key = st.secrets["SUPABASE_KEY"]
        return create_client(supabase_url, supabase_key)
    except KeyError as e:
        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ°: ĞºĞ»ÑÑ‡ '{e.args[0]}' Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ² ÑĞµĞºÑ€ĞµÑ‚Ğ°Ñ… Streamlit. ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ´Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ ĞµĞ³Ğ¾ Ğ² Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸.")
        return None
    except Exception as e:
        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğº Supabase: {e}")
        return None

@st.cache_data(ttl=300)
def get_report_list_from_supabase(_supabase: Client) -> list:
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ ÑĞ¿Ğ¸ÑĞ¾Ğº ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¸Ğ¼ĞµĞ½ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ¾Ğ² Ğ¸Ğ· Supabase."""
    try:
        response = _supabase.table('reports').select('report_name', count='exact').execute()
        if response.data:
            unique_names = sorted(list(set(item['report_name'] for item in response.data)), reverse=True)
            return unique_names
        return []
    except Exception as e:
        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ ÑĞ¿Ğ¸ÑĞºĞ° Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ¾Ğ² Ğ¸Ğ· Supabase: {e}")
        return []

@st.cache_data
def load_report_from_supabase(_supabase: Client, report_name: str) -> pd.DataFrame:
    """Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ Ğ²ÑĞµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ° Ğ¸Ğ· Supabase Ğ² DataFrame."""
    try:
        response = _supabase.table('reports').select('*').eq('report_name', report_name).execute()
        df = pd.DataFrame(response.data)
        if 'data' in df.columns:
            df['data'] = pd.to_datetime(df['data'], errors='coerce')
        if not df.empty:
            df = df.drop(columns=['id', 'created_at', 'report_name'], errors='ignore')
        return df
    except Exception as e:
        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞµ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ° '{report_name}': {e}")
        return pd.DataFrame()


# ----------------------
# 8. ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° Ğ¸ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´ Ğ½Ğ° Streamlit
# ----------------------
def main():
    st.set_page_config(layout="wide")
    st.title("Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¹ ÑƒÑ‡Ğ°Ñ‰Ğ¸Ñ…ÑÑ")

    with st.expander("â„¹ï¸ Ğ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğµ: Ñ‡Ñ‚Ğ¾ ÑÑ‚Ğ¾ Ğ¸ ĞºĞ°Ğº Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ?", expanded=False):
        st.markdown("""
        **Ğ¦ĞµĞ»ÑŒ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´Ğ°** â€” Ğ¿Ğ¾Ğ¼Ğ¾Ñ‡ÑŒ Ğ¿ĞµĞ´Ğ°Ğ³Ğ¾Ğ³Ğ°Ğ¼ Ğ¸ ĞºÑƒÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°Ğ¼ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾ Ğ¾Ñ†ĞµĞ½Ğ¸Ñ‚ÑŒ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ³Ñ€ÑƒĞ¿Ğ¿Ñ‹, Ğ²Ñ‹ÑĞ²Ğ¸Ñ‚ÑŒ Ğ¾Ğ±Ñ‰Ğ¸Ğµ Ñ‚ĞµĞ½Ğ´ĞµĞ½Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ÑŒ ÑƒÑ‡Ğ°Ñ‰Ğ¸Ñ…ÑÑ, Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ñ… Ğ¾ÑĞ¾Ğ±Ğ¾Ğ³Ğ¾ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ, Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¸Ñ… Ğ¿Ğ¸ÑÑŒĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¹.

        **ĞšĞ°Ğº ÑÑ‚Ğ¾ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚?**
        1.  Ğ”Ğ»Ñ **Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°** Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ Excel-Ñ„Ğ°Ğ¹Ğ» Ñ Ñ‚ĞµĞºÑÑ‚Ğ°Ğ¼Ğ¸ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¹.
        2.  Ğ§Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ **ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹ Ğ¾Ñ‚Ñ‡ĞµÑ‚**, Ğ²Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ ĞµĞ³Ğ¾ Ğ¸Ğ· Ğ²Ñ‹Ğ¿Ğ°Ğ´Ğ°ÑÑ‰ĞµĞ³Ğ¾ ÑĞ¿Ğ¸ÑĞºĞ°. Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ÑÑ‚ÑÑ Ğ¸Ğ· Ğ¾Ğ±Ğ»Ğ°Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°.
        3.  ĞŸÑ€Ğ¸ Ğ½Ğ¾Ğ²Ğ¾Ğ¼ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğµ Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚ (DeepSeek) Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚.
        4.  ĞŸĞ¾ÑĞ»Ğµ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ²Ñ‹ Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ **ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ² Ğ°Ñ€Ñ…Ğ¸Ğ²**, Ğ½Ğ°Ğ¶Ğ°Ğ² ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰ÑƒÑ ĞºĞ½Ğ¾Ğ¿ĞºÑƒ. ĞÑ‚Ñ‡ĞµÑ‚ ÑÑ‚Ğ°Ğ½ĞµÑ‚ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½ Ğ´Ğ»Ñ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ° Ğ¿Ñ€Ğ¸ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¼ Ğ·Ğ°Ğ¿ÑƒÑĞºĞµ.
        5.  Ğ’ **Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ñ„ÑƒĞ½ĞºÑ†Ğ¸ÑÑ…** Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑˆÑƒÑ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ğ½Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¸ Ğ´Ğ»Ñ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¾Ğ².
        """)

    supabase = init_supabase_client()
    if not supabase:
        st.stop()

    st.sidebar.header("ğŸ—‚ï¸ Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…")
    report_files = get_report_list_from_supabase(supabase)
    data_source_options = ["ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·"] + report_files
    selected_source = st.sidebar.selectbox("Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ¾Ñ‚Ñ‡ĞµÑ‚ Ğ¸Ğ· Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ° Ğ¸Ğ»Ğ¸ Ğ½Ğ°Ñ‡Ğ½Ğ¸Ñ‚Ğµ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·:", data_source_options)

    df = None
    uploaded_file = None

    if selected_source != "ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·":
        st.sidebar.success(f"Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ğ¾Ñ‚Ñ‡ĞµÑ‚ Ğ¸Ğ· Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°: {selected_source}")
        df = load_report_from_supabase(supabase, selected_source)
        st.session_state['current_file_name'] = selected_source
    else:
        st.sidebar.header("ğŸ“„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ»Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°")
        uploaded_file = st.sidebar.file_uploader("Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ Excel-Ñ„Ğ°Ğ¹Ğ» Ñ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸ÑĞ¼Ğ¸", type="xlsx")
        if uploaded_file:
            st.session_state['current_file_name'] = uploaded_file.name
            df = load_data(uploaded_file)
            df['text'] = df['text'].astype(str).fillna('')

    if df is None:
        st.info("ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ Ñ„Ğ°Ğ¹Ğ» Ğ´Ğ»Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¸Ğ»Ğ¸ Ğ²Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ¾Ñ‚Ñ‡ĞµÑ‚ Ğ² Ğ±Ğ¾ĞºĞ¾Ğ²Ğ¾Ğ¹ Ğ¿Ğ°Ğ½ĞµĞ»Ğ¸.")
        return

    client = None
    if selected_source == "ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·":
        try:
            api_key = st.secrets["DEEPSEEK_API_KEY"]
            client = AsyncOpenAI(base_url=DEESEEK_API_URL, api_key=api_key)
        except KeyError:
            st.sidebar.error("API-ĞºĞ»ÑÑ‡ DeepSeek Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ² Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°Ñ… Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ.")
            st.error("ĞÑˆĞ¸Ğ±ĞºĞ° ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸: Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ ĞºĞ»ÑÑ‡ `DEEPSEEK_API_KEY`. "
                     "ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ´Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ ĞµĞ³Ğ¾ Ğ² Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ ÑĞµĞºÑ€ĞµÑ‚Ğ¾Ğ² Ğ² Streamlit Cloud.")
            st.stop()

    session_key = f"df_processed_{st.session_state.get('current_file_name', 'default')}"

    if session_key not in st.session_state:
        if selected_source == "ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·" and client:
            with st.spinner('Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ÑÑ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¹... Ğ­Ñ‚Ğ¾ Ğ·Ğ°Ğ¹Ğ¼ĞµÑ‚ Ğ½ĞµĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğµ Ğ²Ñ€ĞµĞ¼Ñ.'):
                tasks = [analyze_reflection_with_deepseek(client, text) for text in df['text']]
                async def gather_tasks():
                    return await asyncio.gather(*tasks)
                results = asyncio.run(gather_tasks())
                results_df = pd.DataFrame(results)
                df = pd.concat([df.reset_index(drop=True), results_df.reset_index(drop=True)], axis=1)
        
        for col in ['sentiment_score', 'learning_sentiment_score', 'teamwork_sentiment_score', 'organization_sentiment_score']:
            if col in df.columns:
                 df[col.replace('_score', '_10_point')] = df[col].apply(convert_sentiment_to_10_point)
        
        st.session_state[session_key] = df
    else:
        df = st.session_state[session_key]

    if selected_source == "ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·" and uploaded_file:
        st.sidebar.header("ğŸ’¾ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ")
        if st.sidebar.button("Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ² Ğ°Ñ€Ñ…Ğ¸Ğ²"):
            with st.spinner("Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ° Ğ² Ğ¾Ğ±Ğ»Ğ°ĞºĞ¾..."):
                timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M")
                base_filename = os.path.splitext(uploaded_file.name)[0]
                report_filename = f"{base_filename}_processed_{timestamp}"
                processed_df_to_save = st.session_state[session_key].copy()
                processed_df_to_save['report_name'] = report_filename
                if 'data' in processed_df_to_save.columns:
                    processed_df_to_save['data'] = pd.to_datetime(processed_df_to_save['data']).dt.strftime('%Y-%m-%dT%H:%M:%S')
                df_for_upload = processed_df_to_save.replace({pd.NaT: None, np.nan: None})
                df_for_upload = df_for_upload.drop(columns=['id'], errors='ignore')
                data_to_upload = df_for_upload.to_dict(orient='records')
                try:
                    supabase.table('reports').upsert(data_to_upload, on_conflict='username,data').execute()
                    st.sidebar.success(f"ĞĞ½Ğ°Ğ»Ğ¸Ğ· ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½ ĞºĞ°Ğº:\n**{report_filename}**\nĞ”ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ñ‹ Ğ¿Ñ€Ğ¾Ğ¸Ğ³Ğ½Ğ¾Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹.")
                    st.cache_data.clear()
                    st.rerun()
                except Exception as e:
                    st.sidebar.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ² Supabase: {e}")
    if df.empty:
        st.error("ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ. ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ñ‚Ğµ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹ Ğ¸Ğ»Ğ¸ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ Ğ´Ñ€ÑƒĞ³Ğ¾Ğ¹ Ñ„Ğ°Ğ¹Ğ».")
        return
        
    filtered_df = df.copy()

    st.sidebar.header("ğŸ“Š Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹")
    if 'data' in filtered_df.columns and not filtered_df['data'].dropna().empty:
        min_date = filtered_df['data'].min().date()
        max_date = filtered_df['data'].max().date()
        if min_date != max_date:
            date_range = st.sidebar.slider(
                "Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ Ğ´Ğ°Ñ‚:",
                min_value=min_date, max_value=max_date,
                value=(min_date, max_date), format="DD.MM.YYYY"
            )
            start_date, end_date = date_range
            mask = (filtered_df['data'].dt.date >= start_date) & (filtered_df['data'].dt.date <= end_date)
            filtered_df = filtered_df.loc[mask]
        else:
             st.sidebar.info("Ğ’ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¾Ğ´Ğ¸Ğ½ Ğ´ĞµĞ½ÑŒ, Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€ Ğ¿Ğ¾ Ğ´Ğ°Ñ‚Ğµ Ğ½ĞµĞ°ĞºÑ‚Ğ¸Ğ²ĞµĞ½.")
    else:
        st.sidebar.warning("Ğ’ Ñ„Ğ°Ğ¹Ğ»Ğµ Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒÑÑ‚ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ñ‹Ğµ Ğ´Ğ°Ñ‚Ñ‹ Ğ´Ğ»Ñ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸.")

    if filtered_df.empty:
        st.error("ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ñ‹Ğ¼ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ğ¼.")
        return

    # --- ĞĞĞ’Ğ«Ğ™ Ğ‘Ğ›ĞĞš: Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ĞµĞ¼ ---
    if 'view_mode' not in st.session_state:
        st.session_state.view_mode = 'dashboard'

    # ĞšĞ½Ğ¾Ğ¿ĞºĞ¸ Ğ´Ğ»Ñ Ğ¿ĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğ²Ğ¸Ğ´Ğ° Ğ² Ğ±Ğ¾ĞºĞ¾Ğ²Ğ¾Ğ¹ Ğ¿Ğ°Ğ½ĞµĞ»Ğ¸
    st.sidebar.header("ğŸ‰ Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸")
    if st.sidebar.button("Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑˆÑƒÑ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ğ½Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸"):
        st.session_state.view_mode = 'nominations'
        st.rerun()

    if st.sidebar.button("Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ´Ñ€ÑƒĞ¶ĞµĞ»ÑĞ±Ğ½Ñ‹Ğµ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¸"):
        st.session_state.view_mode = 'reflections'
        st.rerun()

    # ĞšĞ½Ğ¾Ğ¿ĞºĞ° Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ° Ğ½Ğ° Ğ³Ğ»Ğ°Ğ²Ğ½Ñ‹Ğ¹ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´
    if st.session_state.view_mode != 'dashboard':
        if st.sidebar.button("â—€ï¸ Ğ’ĞµÑ€Ğ½ÑƒÑ‚ÑŒÑÑ Ğº Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¼Ñƒ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´Ñƒ"):
            st.session_state.view_mode = 'dashboard'
            st.rerun()
            
    # --- ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ° ---
    if st.session_state.view_mode == 'dashboard':
        # --- ĞĞ°Ñ‡Ğ°Ğ»Ğ¾ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ±Ğ»Ğ¾ĞºĞ° Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´Ğ° ---
        st.header("ĞĞ±Ñ‰Ğ°Ñ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ° Ğ¸ Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ¾Ğ²Ğ¾Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·")
        # ... (Ğ·Ğ´ĞµÑÑŒ ĞºĞ¾Ğ´ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´Ğ° Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹) ...
        daily_groups = filtered_df.groupby(filtered_df['data'].dt.date)
        agg_dict = {
            'avg_emotion': ('emotion', 'mean'),
            'avg_sentiment_10_point': ('sentiment_10_point', 'mean'),
            'avg_learning_sentiment': ('learning_sentiment_10_point', 'mean'),
            'avg_teamwork_sentiment': ('teamwork_sentiment_10_point', 'mean'),
            'avg_organization_sentiment': ('organization_sentiment_10_point', 'mean')
        }
        valid_agg_dict = {k: v for k, v in agg_dict.items() if v[0] in filtered_df.columns}
        if valid_agg_dict:
            daily_df = daily_groups.agg(**valid_agg_dict).reset_index()
            daily_df.rename(columns={'data': 'Ğ”Ğ°Ñ‚Ğ°'}, inplace=True)
            if not daily_df.empty:
                daily_df.sort_values('Ğ”Ğ°Ñ‚Ğ°', inplace=True)
                # ... Ğ¾ÑÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ĞºĞ¾Ğ´ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¾Ğ² ...
        st.header("ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ğ¾ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğ¼ ÑƒÑ‡Ğ°Ñ‰Ğ¸Ğ¼ÑÑ")
        # ... Ğ¾ÑÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ĞºĞ¾Ğ´ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´Ğ° ...
        # --- ĞšĞ¾Ğ½ĞµÑ† Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ±Ğ»Ğ¾ĞºĞ° Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´Ğ° ---

    elif st.session_state.view_mode == 'nominations':
        st.header("ğŸ† Ğ¨ÑƒÑ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ğ½Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¾Ğ²")
        nominations_key = f"nominations_{session_key}"
        
        if client is None:
            st.error("Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ° Ğ¿Ñ€Ğ¸ Ğ¿Ñ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€Ğµ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ° Ğ¸Ğ· Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°. Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ 'ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·' Ğ² Ğ±Ğ¾ĞºĞ¾Ğ²Ğ¾Ğ¹ Ğ¿Ğ°Ğ½ĞµĞ»Ğ¸.")
        else:
            if nominations_key not in st.session_state:
                with st.spinner("Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ½Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸... Ğ­Ñ‚Ğ¾ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ·Ğ°Ğ½ÑÑ‚ÑŒ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ¼Ğ¸Ğ½ÑƒÑ‚..."):
                    # Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ˜Ğ•: Ğ’Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ½Ğ¾Ğ²ÑƒÑ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½ÑƒÑ ĞºĞµÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ
                    nominations_df = get_cached_nominations(filtered_df, client)
                    st.session_state[nominations_key] = nominations_df
            
            st.dataframe(st.session_state[nominations_key], use_container_width=True)

    elif st.session_state.view_mode == 'reflections':
        st.header("ğŸŒŸ Ğ”Ñ€ÑƒĞ¶ĞµĞ»ÑĞ±Ğ½Ñ‹Ğµ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¸ Ğ¸ Ğ½Ğ°Ğ¿ÑƒÑ‚ÑÑ‚Ğ²Ğ¸Ñ")
        reflections_key = f"friendly_reflections_{session_key}"

        if client is None:
            st.error("Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ° Ğ¿Ñ€Ğ¸ Ğ¿Ñ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€Ğµ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ° Ğ¸Ğ· Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°. Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ 'ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·' Ğ² Ğ±Ğ¾ĞºĞ¾Ğ²Ğ¾Ğ¹ Ğ¿Ğ°Ğ½ĞµĞ»Ğ¸.")
        else:
            if reflections_key not in st.session_state:
                with st.spinner("ĞŸĞ¸ÑˆĞµĞ¼ Ğ´Ñ€ÑƒĞ¶ĞµÑĞºĞ¸Ğµ Ğ¿Ğ¾ÑĞ»Ğ°Ğ½Ğ¸Ñ... Ğ­Ñ‚Ğ¾ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ·Ğ°Ğ½ÑÑ‚ÑŒ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ¼Ğ¸Ğ½ÑƒÑ‚..."):
                    # Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ˜Ğ•: Ğ’Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ½Ğ¾Ğ²ÑƒÑ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½ÑƒÑ ĞºĞµÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ
                    reflections_df = get_cached_friendly_reflections(filtered_df, client)
                    st.session_state[reflections_key] = reflections_df

            df_to_display = st.session_state[reflections_key].copy()
            df_to_display['Ğ ĞµÑ„Ğ»ĞµĞºÑĞ¸Ñ Ğ¸ Ğ½Ğ°Ğ¿ÑƒÑ‚ÑÑ‚Ğ²Ğ¸Ğµ'] = df_to_display['Ğ ĞµÑ„Ğ»ĞµĞºÑĞ¸Ñ'] + '\n\n**ĞŸĞ¾Ğ¶ĞµĞ»Ğ°Ğ½Ğ¸Ğµ:** ' + df_to_display['ĞŸĞ¾Ğ¶ĞµĞ»Ğ°Ğ½Ğ¸Ğµ']
            st.dataframe(df_to_display[['Ğ¤Ğ˜Ğ', 'Ğ ĞµÑ„Ğ»ĞµĞºÑĞ¸Ñ Ğ¸ Ğ½Ğ°Ğ¿ÑƒÑ‚ÑÑ‚Ğ²Ğ¸Ğµ']], use_container_width=True)

if __name__ == "__main__":
    main()
