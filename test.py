# 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
# ----------------------
import subprocess
import sys


# ----------------------
# 2. –ò–º–ø–æ—Ä—Ç—ã –∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
# ----------------------
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import json
from openai import AsyncOpenAI
import asyncio
import numpy as np
import os
from supabase import create_client, Client

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è API DeepSeek
DEESEEK_API_URL = "https://api.studio.nebius.ai/v1/"

# ----------------------
# 3. –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
# ----------------------
@st.cache_data
def load_data(file_path: str) -> pd.DataFrame:
    df = pd.read_excel(file_path)
    df.columns = [str(col).strip().lower() if isinstance(col, str) else col for col in df.columns]
    if 'data' in df.columns:
        df['data'] = pd.to_datetime(df['data'], errors='coerce')
    return df

# ----------------------
# 4. DeepSeek API –∞–Ω–∞–ª–∏–∑
# ----------------------
async def analyze_reflection_with_deepseek(client: AsyncOpenAI, text: str) -> dict:
    error_result = {
        "sentiment_score": 0.0, "learning_feedback": "N/A", "teamwork_feedback": "N/A",
        "organization_feedback": "N/A", "learning_sentiment_score": 0.0,
        "teamwork_sentiment_score": 0.0, "organization_sentiment_score": 0.0,
    }
    if not text or not isinstance(text, str) or not text.strip():
        return error_result
    prompt = (
        "–¢—ã ‚Äî –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–æ–≤ —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–µ—Ñ–ª–µ–∫—Å–∏—é —à–∫–æ–ª—å–Ω–∏–∫–∞. "
        "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –≤–µ—Ä–Ω—É—Ç—å JSON-–æ–±—ä–µ–∫—Ç —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –∫–ª—é—á–∞–º–∏:\n"
        "1. 'sentiment_score': –æ–±—â–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞, —á–∏—Å–ª–æ –æ—Ç -1.0 –¥–æ 1.0.\n"
        "2. 'learning_feedback': –∫—Ä–∞—Ç–∫–∞—è –≤—ã–∂–∏–º–∫–∞ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –æ–± –æ—Ü–µ–Ω–∫–µ —É—á–µ–±–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞.\n"
        "3. 'teamwork_feedback': –∫—Ä–∞—Ç–∫–∞—è –≤—ã–∂–∏–º–∫–∞ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –æ —Ä–∞–±–æ—Ç–µ –≤ –∫–æ–º–∞–Ω–¥–µ.\n"
        "4. 'organization_feedback': –∫—Ä–∞—Ç–∫–∞—è –≤—ã–∂–∏–º–∫–∞ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –æ–± –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏ –¥–æ—Å—É–≥–µ.\n"
        "5. 'learning_sentiment_score': —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –¢–û–õ–¨–ö–û —á–∞—Å—Ç–∏ –ø—Ä–æ —É—á—ë–±—É (–æ—Ç -1.0 –¥–æ 1.0). –ï—Å–ª–∏ –Ω–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è, –≤–µ—Ä–Ω–∏ 0.0.\n"
        "6. 'teamwork_sentiment_score': —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –¢–û–õ–¨–ö–û —á–∞—Å—Ç–∏ –ø—Ä–æ –∫–æ–º–∞–Ω–¥—É (–æ—Ç -1.0 –¥–æ 1.0). –ï—Å–ª–∏ –Ω–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è, –≤–µ—Ä–Ω–∏ 0.0.\n"
        "7. 'organization_sentiment_score': —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –¢–û–õ–¨–ö–û —á–∞—Å—Ç–∏ –ø—Ä–æ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é (–æ—Ç -1.0 –¥–æ 1.0). –ï—Å–ª–∏ –Ω–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è, –≤–µ—Ä–Ω–∏ 0.0.\n\n"
        f"–¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: \"{text}\""
    )
    try:
        response = await client.chat.completions.create(
            model="deepseek-ai/DeepSeek-V3", messages=[{"role": "user", "content": prompt}],
            temperature=0.2, response_format={"type": "json_object"}
        )
        result = json.loads(response.choices[0].message.content)
        for key, value in error_result.items():
            if key not in result: result[key] = value
        return result
    except Exception as e:
        print(f"Error processing text: '{text[:50]}...'. Error: {e}")
        return error_result

# ----------------------
# 5. –ù–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
# ----------------------
async def _get_one_nomination(client: AsyncOpenAI, username: str, text: str, style: str, examples: str) -> dict:
    prompt = (
        f"–¢—ã ‚Äî –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏ —à–∫–æ–ª—å–Ω–∏–∫–∞ –∏ –ø—Ä–∏–¥—É–º–∞—Ç—å –¥–ª—è –Ω–µ–≥–æ —à—É—Ç–æ—á–Ω—É—é –Ω–æ–º–∏–Ω–∞—Ü–∏—é.\n"
        f"–°—Ç–∏–ª—å –Ω–æ–º–∏–Ω–∞—Ü–∏–∏: {style}.\n"
        f"–í–æ—Ç –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –≤–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏—è:\n{examples}\n\n"
        f"–ù–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π —É—á–∞—Å—Ç–Ω–∏–∫–∞ –ø–æ –∏–º–µ–Ω–∏ {username}: \"{text}\", –ø—Ä–∏—Å–≤–æ–π –µ–º—É —É–Ω–∏–∫–∞–ª—å–Ω—É—é —à—É—Ç–æ—á–Ω—É—é –Ω–æ–º–∏–Ω–∞—Ü–∏—é –≤ –∑–∞–¥–∞–Ω–Ω–æ–º —Å—Ç–∏–ª–µ –∏ –¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –æ–±–µ–∑–ª–∏—á–µ–Ω–Ω–æ–µ. "
        "–í–µ—Ä–Ω–∏ JSON-–æ–±—ä–µ–∫—Ç: {\"nomination\": str, \"justification\": str}."
    )
    default_result = {"nomination": "–ú–æ—Ä—Å–∫–æ–π –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å", "justification": "–ó–∞ –∞–∫—Ç–∏–≤–Ω–æ–µ —É—á–∞—Å—Ç–∏–µ –≤ –ø—Ä–æ–µ–∫—Ç–µ!"}
    try:
        response = await client.chat.completions.create(model="deepseek-ai/DeepSeek-V3", messages=[{"role": "user", "content": prompt}], temperature=0.8, response_format={"type": "json_object"})
        result = json.loads(response.choices[0].message.content)
        return result if 'nomination' in result and 'justification' in result else default_result
    except Exception as e:
        print(f"Error generating nomination for {username}: {e}")
        return default_result

async def _generate_nominations_async(_df: pd.DataFrame, client: AsyncOpenAI, style: str, examples: str) -> pd.DataFrame:
    user_reflections = _df.groupby('username')['text'].apply(lambda texts: ' '.join(texts.astype(str).str.strip())).reset_index()
    tasks = [_get_one_nomination(client, row['username'], row['text'], style, examples) for _, row in user_reflections.iterrows()]
    results = await asyncio.gather(*tasks)
    results_df = pd.DataFrame(results)
    return pd.concat([user_reflections[['username']], results_df], axis=1).rename(columns={'username': '–§–ò–û', 'nomination': '–ù–æ–º–∏–Ω–∞—Ü–∏—è', 'justification': '–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ'})

@st.cache_data(show_spinner=False, hash_funcs={AsyncOpenAI: lambda _: None})
def get_cached_nominations(_df: pd.DataFrame, client: AsyncOpenAI, style: str, examples: str) -> pd.DataFrame:
    return asyncio.run(_generate_nominations_async(_df, client, style, examples))

async def _get_one_friendly_reflection(client: AsyncOpenAI, username: str, text: str) -> dict:
    prompt = (
        "–¢—ã ‚Äî –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, —Å—É–º–º–∏—Ä—É—é—â–∏–π —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏ —à–∫–æ–ª—å–Ω–∏–∫–æ–≤ —Å –º–æ—Ä—Å–∫–æ–π –Ω–∞—É—á–Ω–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–µ–∫—Ç–Ω–æ–π —Å–º–µ–Ω—ã. "
        f"–ù–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π —É—á–∞—Å—Ç–Ω–∏–∫–∞ –ø–æ –∏–º–µ–Ω–∏ {username}: \"{text}\", —Å–æ–∑–¥–∞–π –¥—Ä—É–∂–µ–ª—é–±–Ω–æ–µ, —à—É—Ç–æ—á–Ω—É—é —Ö–∞—Ä–∞–∫–µ—Ç—Ä–∏—Å—Ç–∏–∫—É (2-3 –∞–±–∑–∞—Ü–∞) —Å –∏–Ω—Å–∞–π—Ç–∞–º–∏ –∏–∑ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π "
        "–∏ –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–µ –Ω–∞–ø—É—Ç—Å—Ç–≤–∏–µ (1 –∞–±–∑–∞—Ü). –¢–æ–Ω –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–º, –Ω–µ –æ–±–∏–¥–Ω—ã–º, –º–æ—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ –¥–∞–ª—å–Ω–µ–π—à–µ–µ —Ä–∞–∑–≤–∏—Ç–∏–µ –≤ —É—á–µ–±–µ, –ø—Ä–æ–µ–∫—Ç–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –≤ –∂–∏–∑–Ω–∏ —Å —É—á–µ—Ç–æ–º –º–æ—Ä—Å–∫–æ–π —Ç–µ–º–∞—Ç–∏–∫–∏. "
        "–í–µ—Ä–Ω–∏ JSON-–æ–±—ä–µ–∫—Ç: {\"reflection\": str, \"encouragement\": str}."
    )
    default_result = {"reflection": "–¢—ã –æ—Ç–ª–∏—á–Ω–æ —Å–ø—Ä–∞–≤–ª—è–µ—à—å—Å—è —Å –ø—Ä–æ–µ–∫—Ç–∞–º–∏!", "encouragement": "–ü—Ä–æ–¥–æ–ª–∂–∞–π –≤ —Ç–æ–º –∂–µ –¥—É—Ö–µ –∏ –ø–æ–∫–æ—Ä—è–π –Ω–æ–≤—ã–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç—ã!"}
    try:
        response = await client.chat.completions.create(model="deepseek-ai/DeepSeek-V3", messages=[{"role": "user", "content": prompt}], temperature=0.7, response_format={"type": "json_object"})
        result = json.loads(response.choices[0].message.content)
        return result if 'reflection' in result and 'encouragement' in result else default_result
    except Exception as e:
        print(f"Error generating friendly reflection for {username}: {e}")
        return default_result

async def _generate_friendly_reflections_async(_df: pd.DataFrame, client: AsyncOpenAI) -> pd.DataFrame:
    user_reflections = _df.groupby('username')['text'].apply(lambda texts: ' '.join(texts.astype(str).str.strip())).reset_index()
    tasks = [_get_one_friendly_reflection(client, row['username'], row['text']) for _, row in user_reflections.iterrows()]
    results = await asyncio.gather(*tasks)
    results_df = pd.DataFrame(results)
    return pd.concat([user_reflections[['username']], results_df], axis=1).rename(columns={'username': '–§–ò–û', 'reflection': '–†–µ—Ñ–ª–µ–∫—Å–∏—è', 'encouragement': '–ü–æ–∂–µ–ª–∞–Ω–∏–µ'})

@st.cache_data(show_spinner=False, hash_funcs={AsyncOpenAI: lambda _: None})
def get_cached_friendly_reflections(_df: pd.DataFrame, client: AsyncOpenAI) -> pd.DataFrame:
    return asyncio.run(_generate_friendly_reflections_async(_df, client))

# ----------------------
# 6. –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
# ----------------------
def convert_sentiment_to_10_point(score: float) -> float:
    return (score + 1) * 4.5 + 1 if isinstance(score, (int, float)) else 5.5

@st.cache_resource
def init_supabase_client():
    try:
        return create_client(st.secrets["SUPABASE_URL"], st.secrets["SUPABASE_KEY"])
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Supabase: {e}")
        return None

@st.cache_data(ttl=300)
def get_report_list_from_supabase(_supabase: Client) -> list:
    try:
        response = _supabase.table('reports').select('report_name', count='exact').execute()
        return sorted(list(set(item['report_name'] for item in response.data)), reverse=True) if response.data else []
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –æ—Ç—á–µ—Ç–æ–≤ –∏–∑ Supabase: {e}")
        return []

@st.cache_data
def load_report_from_supabase(_supabase: Client, report_name: str) -> pd.DataFrame:
    try:
        response = _supabase.table('reports').select('*').eq('report_name', report_name).execute()
        df = pd.DataFrame(response.data)
        if 'data' in df.columns:
            df['data'] = pd.to_datetime(df['data'], errors='coerce')
        return df.drop(columns=['id', 'created_at', 'report_name'], errors='ignore') if not df.empty else df
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –æ—Ç—á–µ—Ç–∞ '{report_name}': {e}")
        return pd.DataFrame()

# ----------------------
# 7. –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –∏ –¥–∞—à–±–æ—Ä–¥
# ----------------------
def main():
    st.set_page_config(layout="wide")
    st.title("–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –¥–∞—à–±–æ—Ä–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π —É—á–∞—â–∏—Ö—Å—è")

    with st.expander("‚ÑπÔ∏è –û –ø—Ä–æ–µ–∫—Ç–µ: —á—Ç–æ —ç—Ç–æ –∏ –∫–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è?", expanded=False):
        st.markdown("""...""") # –°–∫—Ä—ã—Ç–æ –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏

    supabase = init_supabase_client()
    if not supabase: st.stop()
    
    client = None
    try:
        client = AsyncOpenAI(base_url=DEESEEK_API_URL, api_key=st.secrets["DEEPSEEK_API_KEY"])
    except KeyError:
        st.sidebar.warning("API-–∫–ª—é—á DeepSeek –Ω–µ –Ω–∞–π–¥–µ–Ω. –§—É–Ω–∫—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –±—É–¥—É—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.")
    except Exception as e:
        st.sidebar.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ API: {e}")

    st.sidebar.header("üóÇÔ∏è –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö")
    report_files = get_report_list_from_supabase(supabase)
    data_source_options = ["–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑"] + report_files
    selected_source = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –æ—Ç—á–µ—Ç:", data_source_options)

    df = None
    uploaded_file = None
    
    if selected_source == "–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑":
        uploaded_file = st.sidebar.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel-—Ñ–∞–π–ª:", type="xlsx")
        if uploaded_file:
            df = load_data(uploaded_file)
            st.session_state['current_file_name'] = uploaded_file.name
    else:
        df = load_report_from_supabase(supabase, selected_source)
        st.session_state['current_file_name'] = selected_source

    file_key = st.session_state.get('current_file_name')
    if 'last_file_key' not in st.session_state or st.session_state.last_file_key != file_key:
        st.session_state.show_nominations = False
        st.session_state.show_reflections = False
        st.session_state.last_file_key = file_key

    if df is None:
        st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –æ—Ç—á–µ—Ç.")
        return

    session_key = f"df_processed_{st.session_state.get('current_file_name', 'default')}"
    if session_key not in st.session_state:
        if selected_source == "–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑" and client:
            with st.spinner('–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∞–Ω–∞–ª–∏–∑ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π...'):
                async def gather_tasks(): return await asyncio.gather(*[analyze_reflection_with_deepseek(client, text) for text in df['text']])
                results = asyncio.run(gather_tasks())
                df = pd.concat([df.reset_index(drop=True), pd.DataFrame(results).reset_index(drop=True)], axis=1)
        
        for col in ['sentiment_score', 'learning_sentiment_score', 'teamwork_sentiment_score', 'organization_sentiment_score']:
            if col in df.columns:
                 df[col.replace('_score', '_10_point')] = df[col].apply(convert_sentiment_to_10_point)
        st.session_state[session_key] = df
    else:
        df = st.session_state[session_key]
    
    if selected_source == "–ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑" and uploaded_file:
        st.sidebar.header("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ")
        if st.sidebar.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –∞—Ä—Ö–∏–≤"):
            with st.spinner("–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –≤ –æ–±–ª–∞–∫–æ..."):
                timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M")
                base_filename = os.path.splitext(uploaded_file.name)[0]
                report_filename = f"{base_filename}_processed_{timestamp}"
                df_to_save = st.session_state[session_key].copy()
                df_to_save['report_name'] = report_filename
                if 'data' in df_to_save.columns:
                    df_to_save['data'] = pd.to_datetime(df_to_save['data']).dt.strftime('%Y-%m-%dT%H:%M:%S')
                data_to_upload = df_to_save.replace({pd.NaT: None, np.nan: None}).to_dict(orient='records')
                try:
                    supabase.table('reports').upsert(data_to_upload, on_conflict='username,data').execute()
                    st.sidebar.success(f"–ê–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫:\n**{report_filename}**")
                    st.cache_data.clear()
                    st.rerun()
                except Exception as e:
                    st.sidebar.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ Supabase: {e}")

    if df.empty:
        st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
        return
        
    filtered_df = df.copy()

    st.sidebar.header("üìä –§–∏–ª—å—Ç—Ä—ã")
    if 'data' in filtered_df.columns and not filtered_df['data'].dropna().empty:
        min_date, max_date = filtered_df['data'].min().date(), filtered_df['data'].max().date()
        if min_date != max_date:
            start_date, end_date = st.sidebar.slider("–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç:", min_date, max_date, (min_date, max_date))
            filtered_df = filtered_df.loc[(filtered_df['data'].dt.date >= start_date) & (filtered_df['data'].dt.date <= end_date)]
    if filtered_df.empty:
        st.error("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º.")
        return

    st.sidebar.header("üéâ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏")
    
    nomination_style = st.sidebar.text_input("–ó–∞–¥–∞–π—Ç–µ —Å—Ç–∏–ª—å –Ω–æ–º–∏–Ω–∞—Ü–∏–π:", "–ú–æ—Ä—Å–∫–∞—è –Ω–∞—É—á–Ω–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —Ç–µ–º–∞—Ç–∏–∫–∞")
    nomination_examples = st.sidebar.text_area("–ü—Ä–∏–º–µ—Ä—ã –Ω–æ–º–∏–Ω–∞—Ü–∏–π (–∫–∞–∂–¥—ã–π —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏):", "–ö–∞–ø–∏—Ç–∞–Ω –ì–µ–Ω–∏–∞–ª—å–Ω–æ—Å—Ç–∏\n–ò–Ω–∂–µ–Ω–µ—Ä –ì–ª—É–±–∏–Ω\n–ê–¥–º–∏—Ä–∞–ª –ò–¥–µ–π")
    if st.sidebar.button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —à—É—Ç–æ—á–Ω—ã–µ –Ω–æ–º–∏–Ω–∞—Ü–∏–∏"): 
        st.session_state.show_nominations = True
        st.rerun()

    st.sidebar.markdown("---") 

    reflection_style = st.sidebar.text_input("–ó–∞–¥–∞–π—Ç–µ —Å—Ç–∏–ª—å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫:", "–î—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∏ –º–æ—Ç–∏–≤–∏—Ä—É—é—â–∏–π, —Å –º–æ—Ä—Å–∫–∏–º–∏ –º–µ—Ç–∞—Ñ–æ—Ä–∞–º–∏")
    reflection_examples = st.sidebar.text_area("–ü—Ä–∏–º–µ—Ä—ã —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ (–ø–æ–º–æ–≥—É—Ç –∑–∞–¥–∞—Ç—å —Ç–æ–Ω):", "–≠—Ç–æ—Ç —é–Ω–≥–∞ –ø–æ–∫–∞–∑–∞–ª —Å–µ–±—è –Ω–∞—Å—Ç–æ—è—â–∏–º –º–æ—Ä—Å–∫–∏–º –≤–æ–ª–∫–æ–º –≤ —Ä–µ—à–µ–Ω–∏–∏ –∑–∞–¥–∞—á, –Ω–µ –±–æ—è–ª—Å—è —à—Ç–æ—Ä–º–æ–≤ –∫—Ä–∏—Ç–∏–∫–∏ –∏ –≤—Å–µ–≥–¥–∞ –¥–µ—Ä–∂–∞–ª –∫—É—Ä—Å –Ω–∞ —É—Å–ø–µ—Ö. –ï–≥–æ –≤–∫–ª–∞–¥ –≤ –ø—Ä–æ–µ–∫—Ç –ø–æ–¥–æ–±–µ–Ω –º–∞—è–∫—É, –æ—Å–≤–µ—â–∞—é—â–µ–º—É –ø—É—Ç—å –≤—Å–µ–π –∫–æ–º–∞–Ω–¥–µ.")
    if st.sidebar.button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏"): 
        st.session_state.show_reflections = True
        st.rerun()
    
    if st.session_state.get('show_nominations') or st.session_state.get('show_reflections'):
        if st.sidebar.button("–°–∫—Ä—ã—Ç—å –¥–æ–ø. —Ç–∞–±–ª–∏—Ü—ã", type="primary"):
            st.session_state.show_nominations = False
            st.session_state.show_reflections = False
            st.rerun()

    # --- 1. –í–°–ï–ì–î–ê –û–¢–û–ë–†–ê–ñ–ê–ï–ú –û–°–ù–û–í–ù–û–ô –î–ê–®–ë–û–†–î ---
    st.header("–û–±—â–∞—è –¥–∏–Ω–∞–º–∏–∫–∞ –∏ –≥—Ä—É–ø–ø–æ–≤–æ–π –∞–Ω–∞–ª–∏–∑")

    daily_groups = filtered_df.groupby(filtered_df['data'].dt.date)
    agg_dict = {'avg_emotion': ('emotion', 'mean'), 'avg_sentiment_10_point': ('sentiment_10_point', 'mean'), 'avg_learning_sentiment': ('learning_sentiment_10_point', 'mean'), 'avg_teamwork_sentiment': ('teamwork_sentiment_10_point', 'mean'), 'avg_organization_sentiment': ('organization_sentiment_10_point', 'mean')}
    valid_agg_dict = {k: v for k, v in agg_dict.items() if v[0] in filtered_df.columns}
    if valid_agg_dict:
        daily_df = daily_groups.agg(**valid_agg_dict).reset_index().rename(columns={'data': '–î–∞—Ç–∞'}).sort_values('–î–∞—Ç–∞')
        if not daily_df.empty:
            c1, c2 = st.columns(2)
            with c1:
                if 'avg_sentiment_10_point' in daily_df.columns and 'avg_emotion' in daily_df.columns:
                    st.plotly_chart(px.line(daily_df, x='–î–∞—Ç–∞', y=['avg_sentiment_10_point', 'avg_emotion'], title='–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å vs. –°–∞–º–æ–æ—Ü–µ–Ω–∫–∞'), use_container_width=True)
            with c2: 
                aspect_cols = ['avg_learning_sentiment', 'avg_teamwork_sentiment', 'avg_organization_sentiment']
                if all(c in daily_df.columns for c in aspect_cols):
                    fig = px.line(daily_df, x='–î–∞—Ç–∞', y=aspect_cols, title='–î–∏–Ω–∞–º–∏–∫–∞ –ø–æ –∞—Å–ø–µ–∫—Ç–∞–º')
                    fig.for_each_trace(lambda t: t.update(name = {'avg_learning_sentiment': '–£—á—ë–±–∞', 'avg_teamwork_sentiment': '–ö–æ–º–∞–Ω–¥–∞', 'avg_organization_sentiment': '–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è'}.get(t.name, t.name)))
                    st.plotly_chart(fig, use_container_width=True)

    st.subheader("–¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –≥—Ä—É–ø–ø—ã")
    if 'sentiment_10_point' in filtered_df.columns:
        heatmap_data = filtered_df.pivot_table(index='username', columns=filtered_df['data'].dt.date, values='sentiment_10_point', aggfunc='mean')
        if not heatmap_data.empty: st.plotly_chart(px.imshow(heatmap_data, labels=dict(x="–î–∞—Ç–∞", y="–£—á–µ–Ω–∏–∫", color="–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å"), color_continuous_scale='RdYlGn', aspect="auto"), use_container_width=True)
        else: st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã.")

    st.header("–ê–Ω–∞–ª–∏–∑ –ø–æ –æ—Ç–¥–µ–ª—å–Ω—ã–º —É—á–∞—â–∏–º—Å—è")
    student_list = sorted(filtered_df['username'].unique())
    if student_list:
        if student := st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —É—á–µ–Ω–∏–∫–∞:", student_list):
            student_df = filtered_df[filtered_df['username'] == student].sort_values('data')
            c1, c2 = st.columns([3, 2])
            with c1:
                if 'sentiment_10_point' in student_df.columns and 'emotion' in student_df.columns:
                    st.plotly_chart(px.line(student_df, x='data', y=['sentiment_10_point', 'emotion'], title=f'–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å vs. –°–∞–º–æ–æ—Ü–µ–Ω–∫–∞'), use_container_width=True)
            with c2:
                radar_cols = ['emotion', 'learning_sentiment_10_point', 'teamwork_sentiment_10_point', 'organization_sentiment_10_point']
                if all(c in student_df.columns for c in radar_cols):
                    radar_values = [student_df[col].mean() for col in radar_cols]
                    fig_radar = go.Figure(data=go.Scatterpolar(r=radar_values, theta=['–°–∞–º–æ–æ—Ü–µ–Ω–∫–∞', '–£—á—ë–±–∞', '–ö–æ–º–∞–Ω–¥–∞', '–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è'], fill='toself'))
                    fig_radar.update_layout(polar=dict(radialaxis=dict(visible=True, range=[1, 10])), title=f"–°—Ä–µ–¥–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏ –¥–ª—è {student}")
                    st.plotly_chart(fig_radar, use_container_width=True)
            
            display_cols = ['data', 'text', 'emotion', 'sentiment_10_point', 'learning_sentiment_10_point', 'teamwork_sentiment_10_point', 'organization_sentiment_10_point', 'learning_feedback', 'teamwork_feedback', 'organization_feedback']
            st.dataframe(student_df[[col for col in display_cols if col in student_df.columns]])

    st.header("–ê–Ω–∞–ª–∏–∑ \"–ó–æ–Ω—ã —Ä–∏—Å–∫–∞\"")
    if 'sentiment_score' in filtered_df.columns:
        risk_users = filtered_df[filtered_df['sentiment_score'] < 0].groupby('username').size().reset_index(name='negative_count').query('negative_count > 1').sort_values('negative_count', ascending=False)
        if not risk_users.empty:
            st.warning("–í—ã—è–≤–ª–µ–Ω—ã —É—á–∞—Å—Ç–Ω–∏–∫–∏ —Å –º–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω–æ–π –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–π —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é:")
            st.dataframe(risk_users)
        else: st.success("–£—á–∞—Å—Ç–Ω–∏–∫–æ–≤ —Å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–º—Å—è –Ω–µ–≥–∞—Ç–∏–≤–æ–º –Ω–µ –≤—ã—è–≤–ª–µ–Ω–æ.")

    # --- –ò–ó–ú–ï–ù–ï–ù–ò–ï: –î–û–ë–ê–í–õ–ï–ù –ë–õ–û–ö –° –û–ë–©–ï–ô –°–í–û–î–ù–û–ô –¢–ê–ë–õ–ò–¶–ï–ô ---
    st.header("–û–±—â–∞—è —Å–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Ä–µ—Ñ–ª–µ–∫—Å–∏–π")
    st.markdown("–ó–¥–µ—Å—å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –≤—Å–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞. –¢–∞–±–ª–∏—Ü—É –º–æ–∂–Ω–æ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å, –Ω–∞–∂–∏–º–∞—è –Ω–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ç–æ–ª–±—Ü–æ–≤.")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä—è–¥–æ–∫ –∏ —Å–æ—Å—Ç–∞–≤ —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è –≤—ã–≤–æ–¥–∞
    summary_display_cols = [
        'username', 'data', 'text', 'emotion', 
        'sentiment_10_point', 'learning_sentiment_10_point', 
        'teamwork_sentiment_10_point', 'organization_sentiment_10_point',
        'learning_feedback', 'teamwork_feedback', 'organization_feedback'
    ]
    # –û—Ç–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ —Å—Ç–æ–ª–±—Ü—ã, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–µ, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–æ–∫
    available_cols = [col for col in summary_display_cols if col in filtered_df.columns]
    
    if available_cols:
        st.dataframe(filtered_df[available_cols], use_container_width=True)
    else:
        st.info("–ù–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü–µ.")
    # --- –ö–û–ù–ï–¶ –ò–ó–ú–ï–ù–ï–ù–ò–Ø ---

    # --- 2. –£–°–õ–û–í–ù–û –û–¢–û–ë–†–ê–ñ–ê–ï–ú –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –¢–ê–ë–õ–ò–¶–´ ---
    if st.session_state.get('show_nominations'):
        if not client:
            st.error("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–º–∏–Ω–∞—Ü–∏–π –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞: API-–∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω.")
        else:
            st.header("üèÜ –®—É—Ç–æ—á–Ω—ã–µ –Ω–æ–º–∏–Ω–∞—Ü–∏–∏ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤")
            nominations_key = f"nominations_{session_key}_{hash(nomination_style)}_{hash(nomination_examples)}"
            if nominations_key not in st.session_state:
                with st.spinner("–°–æ–∑–¥–∞–µ–º –Ω–æ–º–∏–Ω–∞—Ü–∏–∏ –ø–æ –≤–∞—à–µ–º—É —Å—Ç–∏–ª—é..."):
                    st.session_state[nominations_key] = get_cached_nominations(filtered_df, client, nomination_style, nomination_examples)
            st.dataframe(st.session_state[nominations_key], use_container_width=True)

    if st.session_state.get('show_reflections'):
        if not client:
            st.error("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞: API-–∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω.")
        else:
            st.header("üåü –î—Ä—É–∂–µ–ª—é–±–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏ –Ω–∞–ø—É—Ç—Å—Ç–≤–∏—è")
            reflections_key = f"reflections_{session_key}_{hash(reflection_style)}_{hash(reflection_examples)}"
            if reflections_key not in st.session_state:
                with st.spinner("–ü–∏—à–µ–º –¥—Ä—É–∂–µ—Å–∫–∏–µ –ø–æ—Å–ª–∞–Ω–∏—è –≤ –∑–∞–¥–∞–Ω–Ω–æ–º —Å—Ç–∏–ª–µ..."):
                    st.session_state[reflections_key] = get_cached_friendly_reflections(filtered_df, client, reflection_style, reflection_examples)
            
            df_to_display = st.session_state[reflections_key].copy()
            df_to_display['–†–µ—Ñ–ª–µ–∫—Å–∏—è –∏ –Ω–∞–ø—É—Ç—Å—Ç–≤–∏–µ'] = df_to_display['–†–µ—Ñ–ª–µ–∫—Å–∏—è'] + '\n\n**–ü–æ–∂–µ–ª–∞–Ω–∏–µ:** ' + df_to_display['–ü–æ–∂–µ–ª–∞–Ω–∏–µ']
            st.dataframe(df_to_display[['–§–ò–û', '–†–µ—Ñ–ª–µ–∫—Å–∏—è –∏ –Ω–∞–ø—É—Ç—Å—Ç–≤–∏–µ']], use_container_width=True)

if __name__ == "__main__":
    main()
