# 1. Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹
# Ğ£Ğ±ĞµĞ´Ğ¸Ñ‚ĞµÑÑŒ, Ñ‡Ñ‚Ğ¾ Ğ²ÑĞµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ñ‹. Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚Ğµ Ğ² Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ°Ğ»Ğµ:
# pip install streamlit pandas plotly supabase openai openpyxl
# ----------------------
import io
import os
import json
import asyncio
from datetime import datetime

import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
from openai import AsyncOpenAI
from supabase import create_client, Client


# ----------------------
# 2. ĞšĞ¾Ğ½ÑÑ‚Ğ°Ğ½Ñ‚Ñ‹
# ----------------------
DEESEEK_API_URL = "https://api.studio.nebius.ai/v1/"


# ----------------------
# 3. Ğ’ÑĞ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸
# ----------------------

@st.cache_data
def load_data(file_path: str) -> pd.DataFrame:
    """Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ· Excel-Ñ„Ğ°Ğ¹Ğ»Ğ°."""
    df = pd.read_excel(file_path)
    df.columns = [str(col).strip().lower() if isinstance(col, str) else col for col in df.columns]
    if 'data' in df.columns:
        df['data'] = pd.to_datetime(df['data'], errors='coerce')
    return df

def to_excel(df: pd.DataFrame) -> bytes:
    """ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ DataFrame Ğ² Ğ±Ğ°Ğ¹Ñ‚Ñ‹ Excel-Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ´Ğ»Ñ ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ."""
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='Ğ¥Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸')
    return output.getvalue()

def convert_sentiment_to_10_point(score: float) -> float:
    """ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‚Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¸Ğ· Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğ° [-1, 1] Ğ² [1, 10]."""
    if not isinstance(score, (int, float)):
        return 5.5
    return (score + 1) * 4.5 + 1


# ----------------------
# 4. Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ API (Supabase Ğ¸ LLM)
# ----------------------

@st.cache_resource
def init_supabase_client():
    """Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¸ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ĞºĞ»Ğ¸ĞµĞ½Ñ‚ Supabase."""
    try:
        supabase_url = st.secrets["SUPABASE_URL"]
        supabase_key = st.secrets["SUPABASE_KEY"]
        return create_client(supabase_url, supabase_key)
    except KeyError as e:
        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ°: ĞºĞ»ÑÑ‡ '{e.args[0]}' Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ² ÑĞµĞºÑ€ĞµÑ‚Ğ°Ñ… Streamlit.")
        return None
    except Exception as e:
        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğº Supabase: {e}")
        return None

@st.cache_data(ttl=300)
def get_report_list_from_supabase(_supabase: Client) -> list:
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ ÑĞ¿Ğ¸ÑĞ¾Ğº ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¸Ğ¼ĞµĞ½ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ¾Ğ² Ğ¸Ğ· Supabase."""
    try:
        response = _supabase.table('reports').select('report_name', count='exact').execute()
        return sorted(list(set(item['report_name'] for item in response.data)), reverse=True) if response.data else []
    except Exception as e:
        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ ÑĞ¿Ğ¸ÑĞºĞ° Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ¾Ğ² Ğ¸Ğ· Supabase: {e}")
        return []

@st.cache_data
def load_report_from_supabase(_supabase: Client, report_name: str) -> pd.DataFrame:
    """Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ Ğ²ÑĞµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ° Ğ¸Ğ· Supabase Ğ² DataFrame."""
    try:
        response = _supabase.table('reports').select('*').eq('report_name', report_name).execute()
        df = pd.DataFrame(response.data)
        if 'data' in df.columns:
            df['data'] = pd.to_datetime(df['data'], errors='coerce')
        if not df.empty:
            df = df.drop(columns=['id', 'created_at', 'report_name'], errors='ignore')
        return df
    except Exception as e:
        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞµ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ° '{report_name}': {e}")
        return pd.DataFrame()

async def analyze_reflection_with_deepseek(client: AsyncOpenAI, text: str) -> dict:
    """ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‚ĞµĞºÑÑ‚ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¸ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…."""
    error_result = {"sentiment_score": 0.0, "learning_feedback": "N/A", "teamwork_feedback": "N/A", "organization_feedback": "N/A", "learning_sentiment_score": 0.0, "teamwork_sentiment_score": 0.0, "organization_sentiment_score": 0.0}
    if not text or not isinstance(text, str) or not text.strip(): return error_result
    prompt = ("Ğ¢Ñ‹ â€” Ğ˜Ğ˜-Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ² Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¸. ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ñ ÑˆĞºĞ¾Ğ»ÑŒĞ½Ğ¸ĞºĞ°. Ğ¢Ğ²Ğ¾Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ° â€” Ğ²ĞµÑ€Ğ½ÑƒÑ‚ÑŒ JSON-Ğ¾Ğ±ÑŠĞµĞºÑ‚ ÑĞ¾ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¼Ğ¸ ĞºĞ»ÑÑ‡Ğ°Ğ¼Ğ¸:\n1. 'sentiment_score': Ğ¾Ğ±Ñ‰Ğ°Ñ Ñ‚Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ñ‚ĞµĞºÑÑ‚Ğ°, Ñ‡Ğ¸ÑĞ»Ğ¾ Ğ¾Ñ‚ -1.0 (Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²) Ğ´Ğ¾ 1.0 (Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²).\n2. 'learning_feedback': ĞºÑ€Ğ°Ñ‚ĞºĞ°Ñ Ğ²Ñ‹Ğ¶Ğ¸Ğ¼ĞºĞ° (1-2 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ) Ğ¸Ğ· Ñ‚ĞµĞºÑÑ‚Ğ° Ğ¾Ğ± Ğ¾Ñ†ĞµĞ½ĞºĞµ ÑƒÑ‡ĞµĞ±Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ°.\n3. 'teamwork_feedback': ĞºÑ€Ğ°Ñ‚ĞºĞ°Ñ Ğ²Ñ‹Ğ¶Ğ¸Ğ¼ĞºĞ° (1-2 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ) Ğ¾Ğ± Ğ¾Ñ†ĞµĞ½ĞºĞµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ğ² ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğµ.\n4. 'organization_feedback': ĞºÑ€Ğ°Ñ‚ĞºĞ°Ñ Ğ²Ñ‹Ğ¶Ğ¸Ğ¼ĞºĞ° (1-2 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ) Ğ¾Ğ± Ğ¾Ñ†ĞµĞ½ĞºĞµ Ğ¾Ñ€Ğ³Ğ°Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ğ´Ğ¾ÑÑƒĞ³Ğ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ².\n5. 'learning_sentiment_score': Ñ‚Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¢ĞĞ›Ğ¬ĞšĞ Ñ‡Ğ°ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¾ ÑƒÑ‡Ñ‘Ğ±Ñƒ (Ğ¾Ñ‚ -1.0 Ğ´Ğ¾ 1.0). Ğ•ÑĞ»Ğ¸ Ğ½Ğµ ÑƒĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°ĞµÑ‚ÑÑ, Ğ²ĞµÑ€Ğ½Ğ¸ 0.0.\n6. 'teamwork_sentiment_score': Ñ‚Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¢ĞĞ›Ğ¬ĞšĞ Ñ‡Ğ°ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¾ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñƒ (Ğ¾Ñ‚ -1.0 Ğ´Ğ¾ 1.0). Ğ•ÑĞ»Ğ¸ Ğ½Ğµ ÑƒĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°ĞµÑ‚ÑÑ, Ğ²ĞµÑ€Ğ½Ğ¸ 0.0.\n7. 'organization_sentiment_score': Ñ‚Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¢ĞĞ›Ğ¬ĞšĞ Ñ‡Ğ°ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¾ Ğ¾Ñ€Ğ³Ğ°Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ (Ğ¾Ñ‚ -1.0 Ğ´Ğ¾ 1.0). Ğ•ÑĞ»Ğ¸ Ğ½Ğµ ÑƒĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°ĞµÑ‚ÑÑ, Ğ²ĞµÑ€Ğ½Ğ¸ 0.0.\n\nĞ•ÑĞ»Ğ¸ ĞºĞ°ĞºĞ¾Ğ¹-Ñ‚Ğ¾ Ğ°ÑĞ¿ĞµĞºÑ‚ Ğ² Ñ‚ĞµĞºÑÑ‚Ğµ Ğ½Ğµ ÑƒĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°ĞµÑ‚ÑÑ, Ğ´Ğ»Ñ ĞºĞ»ÑÑ‡ĞµĞ¹ feedback Ğ¾ÑÑ‚Ğ°Ğ²ÑŒ Ğ¿ÑƒÑÑ‚ÑƒÑ ÑÑ‚Ñ€Ğ¾ĞºÑƒ, Ğ° Ğ´Ğ»Ñ ĞºĞ»ÑÑ‡ĞµĞ¹ sentiment_score Ğ²ĞµÑ€Ğ½Ğ¸ 0.0.\n\n" f"Ğ¢ĞµĞºÑÑ‚ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°: \"{text}\"")
    try:
        response = await client.chat.completions.create(model="deepseek-ai/DeepSeek-V3", messages=[{"role": "user", "content": prompt}], temperature=0.2, response_format={"type": "json_object"})
        result = json.loads(response.choices[0].message.content)
        for key, value in error_result.items(): result.setdefault(key, value)
        return result
    except Exception as e:
        print(f"Error processing text: '{text[:50]}...'. Error: {e}")
        return error_result

async def generate_nomination_with_llm(client: AsyncOpenAI, reflections: str) -> str:
    """Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑˆÑƒÑ‚Ğ¾Ñ‡Ğ½ÑƒÑ Ğ½Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¹ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ°."""
    if not reflections or not reflections.strip():
        reflections = "Ğ£Ñ‡Ğ°ÑÑ‚Ğ½Ğ¸Ğº Ğ±Ñ‹Ğ» ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ¿Ğ¾Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ğ² Ğ²ĞµĞ»Ğ¸ĞºĞ¸Ğµ Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ğµ Ğ´ĞµĞ»Ğ° Ğ¸ Ğ½Ğµ Ğ¾ÑÑ‚Ğ°Ğ²Ğ¸Ğ» Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¹."
    prompt = ("Ğ¢Ñ‹ â€” ĞºÑ€ĞµĞ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ°Ğ¹Ñ‚ĞµÑ€ Ğ´Ğ»Ñ Ğ´ĞµÑ‚ÑĞºĞ¾Ğ³Ğ¾ Ğ½Ğ°ÑƒÑ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ»Ğ°Ğ³ĞµÑ€Ñ. Ğ¢Ğ²Ğ¾Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ° â€” Ğ¿Ñ€Ğ¸Ğ´ÑƒĞ¼Ğ°Ñ‚ÑŒ ÑˆÑƒÑ‚Ğ¾Ñ‡Ğ½ÑƒÑ Ğ½Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ Ğ´Ğ»Ñ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ° Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ĞµĞ³Ğ¾ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¹. ĞĞ¾Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ° Ğ±Ñ‹Ñ‚ÑŒ ÑĞ²ÑĞ·Ğ°Ğ½Ğ° Ñ Ğ½Ğ°ÑƒĞºĞ¾Ğ¹, Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°Ğ¼Ğ¸, Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸ÑĞ¼Ğ¸, ĞºĞ¾Ğ´Ğ¾Ğ¼, Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¸ Ñ‚.Ğ´.\n\nĞŸÑ€Ğ°Ğ²Ğ¸Ğ»Ğ°:\n1. Ğ•ÑĞ»Ğ¸ Ğ² Ñ‚ĞµĞºÑÑ‚Ğµ ĞµÑÑ‚ÑŒ ÑĞ»Ğ¾Ğ²Ğ° Ğ¿Ñ€Ğ¾ Ñ‚Ñ€ÑƒĞ´Ğ½Ğ¾ÑÑ‚Ğ¸, Ğ±Ğ¾Ñ€ÑŒĞ±Ñƒ Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°Ğ¼Ğ¸, Ğ´ĞµĞ±Ğ°Ğ³Ğ³Ğ¸Ğ½Ğ³ â€” Ğ¿Ñ€Ğ¸Ğ´ÑƒĞ¼Ğ°Ğ¹ Ğ½Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾ ÑƒĞ¿Ğ¾Ñ€ÑÑ‚Ğ²Ğ¾ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, 'ĞŸĞ¾Ğ²ĞµĞ»Ğ¸Ñ‚ĞµĞ»ÑŒ Ğ”ĞµĞ±Ğ°Ğ³Ğ°', 'Ğ£ĞºÑ€Ğ¾Ñ‚Ğ¸Ñ‚ĞµĞ»ÑŒ Ğ‘Ğ°Ğ³Ğ¾Ğ²').\n2. Ğ•ÑĞ»Ğ¸ Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸Ñ‚ÑÑ Ğ¿Ñ€Ğ¾ Ğ¸Ğ´ĞµĞ¸, ĞºÑ€ĞµĞ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ, Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½ â€” Ğ¿Ñ€Ğ¾ ÑÑ‚Ğ¾ ('Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Ğ“ĞµĞ½Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ“Ğ¸Ğ¿Ğ¾Ñ‚ĞµĞ·', 'ĞœĞ°Ğ³Ğ¸ÑÑ‚Ñ€ ĞšÑ€ĞµĞ°Ñ‚Ğ¸Ğ²Ğ°').\n3. Ğ•ÑĞ»Ğ¸ ÑƒĞ¿Ğ¾Ñ€ Ğ½Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ, Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·, Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸ â€” Ğ¿Ñ€Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºÑƒ ('Ğ›Ğ¾Ñ€Ğ´ ĞĞ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ”Ğ°Ğ½Ğ½Ñ‹Ñ…', 'Ğ’Ğ¸Ñ€Ñ‚ÑƒĞ¾Ğ· Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¹').\n4. Ğ•ÑĞ»Ğ¸ Ñ‚ĞµĞºÑÑ‚ Ğ¾ Ñ‚Ğ°Ğ¸Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸Ğ»Ğ¸ ĞµĞ³Ğ¾ Ğ½ĞµÑ‚ â€” Ğ¾Ğ±Ñ‹Ğ³Ñ€Ğ°Ğ¹ ÑÑ‚Ğ¾ ('Ğ¥Ñ€Ğ°Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒ ĞĞ°ÑƒÑ‡Ğ½Ñ‹Ñ… Ğ¢Ğ°Ğ¹Ğ½', 'ĞĞ³ĞµĞ½Ñ‚ \"ĞĞ¾Ğ»ÑŒ ĞšĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸ĞµĞ²\"').\n\nĞ’ĞµÑ€Ğ½Ğ¸ Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸ Ğ² Ğ²Ğ¸Ğ´Ğµ Ğ¾Ğ´Ğ½Ğ¾Ğ¹ ÑÑ‚Ñ€Ğ¾ĞºĞ¸. Ğ‘ĞµĞ· ĞºĞ°Ğ²Ñ‹Ñ‡ĞµĞº Ğ¸ Ğ»Ğ¸ÑˆĞ½Ğ¸Ñ… ÑĞ»Ğ¾Ğ².\n\n" f"Ğ¢ĞµĞºÑÑ‚ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¸ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°: \"{reflections}\"")
    try:
        response = await client.chat.completions.create(model="deepseek-ai/DeepSeek-V3", messages=[{"role": "user", "content": prompt}], temperature=0.7, max_tokens=50)
        return response.choices[0].message.content.strip().strip('"')
    except Exception as e:
        print(f"Error generating nomination: {e}")
        return "ĞœĞ°ÑÑ‚ĞµÑ€ ĞĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸"

async def generate_character_description_with_llm(client: AsyncOpenAI, name: str, reflections: str) -> str:
    """Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑˆÑƒÑ‚Ğ¾Ñ‡Ğ½ÑƒÑ, Ğ½Ğ¾ Ğ´Ğ¾Ğ±Ñ€ÑƒÑ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºÑƒ Ğ½Ğ° ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ°."""
    is_empty_reflection = not reflections or not reflections.strip()
    if is_empty_reflection:
        reflections = "Ğ ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¸ Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒÑÑ‚. Ğ’ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾, ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸Ğº Ğ±Ñ‹Ğ» Ğ·Ğ°ÑĞµĞºÑ€ĞµÑ‡ĞµĞ½Ğ½Ñ‹Ğ¼ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ¼, Ñ‡ÑŒÑ Ğ¼Ğ¸ÑÑĞ¸Ñ Ğ±Ñ‹Ğ»Ğ° Ğ½Ğ°ÑÑ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ²Ğ°Ğ¶Ğ½Ğ°, Ñ‡Ñ‚Ğ¾ Ğ½Ğµ Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞ»Ğ° ÑĞ»ĞµĞ´Ğ¾Ğ² Ğ² Ğ²Ğ¸Ğ´Ğµ Ñ‚ĞµĞºÑÑ‚Ğ°."
    prompt = (f"Ğ¢Ñ‹ â€” Ğ´Ğ¾Ğ±Ñ€Ñ‹Ğ¹ Ğ¸ Ğ¼ÑƒĞ´Ñ€Ñ‹Ğ¹ Ğ½Ğ°ÑÑ‚Ğ°Ğ²Ğ½Ğ¸Ğº Ğ² Ğ½Ğ°ÑƒÑ‡Ğ½Ğ¾Ğ¼ Ğ»Ğ°Ğ³ĞµÑ€Ğµ. Ğ¢Ğ²Ğ¾Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ° â€” Ğ½Ğ°Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ ÑˆÑƒÑ‚Ğ¾Ñ‡Ğ½ÑƒÑ, Ğ½Ğ¾ Ğ¾Ñ‡ĞµĞ½ÑŒ Ğ´Ğ¾Ğ±Ñ€ÑƒÑ Ğ¸ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ÑÑ‰ÑƒÑ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºÑƒ Ğ´Ğ»Ñ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ° Ğ¿Ğ¾ Ğ¸Ğ¼ĞµĞ½Ğ¸ {name} Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ĞµĞ³Ğ¾ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¹. Ğ¢ĞµĞºÑÑ‚ Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ Markdown.\n\nĞ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°:\n1.  **ĞŸĞµÑ€Ğ²Ñ‹Ğ¹ Ğ°Ğ±Ğ·Ğ°Ñ†:** Ğ¡ Ğ»ĞµĞ³ĞºĞ¸Ğ¼ ÑĞ¼Ğ¾Ñ€Ğ¾Ğ¼ Ğ¾Ğ¿Ğ¸ÑˆĞ¸ Ğ³Ğ»Ğ°Ğ²Ğ½ÑƒÑ Ñ‡ĞµÑ€Ñ‚Ñƒ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ°, Ğ¿Ñ€Ğ¾ÑĞ²Ğ»ĞµĞ½Ğ½ÑƒÑ Ğ½Ğ° ÑĞ¼ĞµĞ½Ğµ (ÑƒĞ¿Ğ¾Ñ€ÑÑ‚Ğ²Ğ¾, ĞºÑ€ĞµĞ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ, ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ½Ñ‹Ğ¹ Ğ´ÑƒÑ…, Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ ÑĞºĞ»Ğ°Ğ´ ÑƒĞ¼Ğ°, Ñ‚Ğ°Ğ¸Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ).\n2.  **Ğ’Ñ‚Ğ¾Ñ€Ğ¾Ğ¹ Ğ°Ğ±Ğ·Ğ°Ñ†:** Ğ Ğ°ÑĞºÑ€Ğ¾Ğ¹ ÑÑ‚Ñƒ Ğ¼Ñ‹ÑĞ»ÑŒ, Ğ¿Ñ€Ğ¸Ğ²ĞµĞ´Ñ 'Ğ¿ÑĞµĞ²Ğ´Ğ¾-Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğ°' Ğ¸Ğ· ĞµĞ³Ğ¾ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ½Ğ¾Ğ¹ Ğ¶Ğ¸Ğ·Ğ½Ğ¸. ĞœĞ¾Ğ¶Ğ½Ğ¾ Ğ½ĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€ĞµÑƒĞ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ñ‚ÑŒ Ğ´Ğ»Ñ ĞºĞ¾Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ ÑÑ„Ñ„ĞµĞºÑ‚Ğ°.\n3.  **ĞĞ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ğµ:** Ğ’ ĞºĞ¾Ğ½Ñ†Ğµ Ğ´Ğ¾Ğ±Ğ°Ğ²ÑŒ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ±Ğ·Ğ°Ñ† Ñ Ğ¼ÑƒĞ´Ñ€Ñ‹Ğ¼Ğ¸ Ğ¸ Ğ´Ğ¾Ğ±Ñ€Ñ‹Ğ¼Ğ¸ Ğ¿Ğ¾Ğ¶ĞµĞ»Ğ°Ğ½Ğ¸ÑĞ¼Ğ¸ Ğ½Ğ° Ğ±ÑƒĞ´ÑƒÑ‰ĞµĞµ (Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ¸Ñ, Ğ²ĞµÑ€Ğ° Ğ² ÑĞµĞ±Ñ, Ğ½Ğµ Ğ±Ğ¾ÑÑ‚ÑŒÑÑ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº).\n\n" f"ĞÑĞ¾Ğ±Ñ‹Ğ¹ ÑĞ»ÑƒÑ‡Ğ°Ğ¹: {'Ğ•ÑĞ»Ğ¸ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¹ Ğ½Ğµ Ğ±Ñ‹Ğ»Ğ¾, Ğ¿Ğ¾ÑˆÑƒÑ‚Ğ¸ Ğ½Ğ°Ğ´ ĞµĞ³Ğ¾ Ñ‚Ğ°Ğ¸Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒÑ, ÑĞºĞ°Ğ¶Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ¾Ğ½ Ğ±Ñ‹Ğ» Ñ‚Ğ°Ğº ÑƒĞ²Ğ»ĞµÑ‡ĞµĞ½ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ¾Ğ¼, Ñ‡Ñ‚Ğ¾ ĞµĞ¼Ñƒ Ğ±Ñ‹Ğ»Ğ¾ Ğ½Ğµ Ğ´Ğ¾ ÑĞ»Ğ¾Ğ². ĞŸĞ¾Ğ´Ñ‡ĞµÑ€ĞºĞ½Ğ¸, Ñ‡Ñ‚Ğ¾ ĞµĞ³Ğ¾ Ğ´ĞµĞ»Ğ° Ğ³Ğ¾Ğ²Ğ¾Ñ€ÑÑ‚ Ğ³Ñ€Ğ¾Ğ¼Ñ‡Ğµ.' if is_empty_reflection else ''}\n\n" f"Ğ¢ĞµĞºÑÑ‚ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¸ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°: \"{reflections}\"")
    try:
        response = await client.chat.completions.create(model="deepseek-ai/DeepSeek-V3", messages=[{"role": "user", "content": prompt}], temperature=0.8, max_tokens=400)
        return response.choices[0].message.content
    except Exception as e:
        print(f"Error generating description: {e}")
        return f"Ğš ÑĞ¾Ğ¶Ğ°Ğ»ĞµĞ½Ğ¸Ñ, Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸ Ğ´Ğ»Ñ {name} Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ¾ÑˆĞ»Ğ° ĞºĞ¾ÑĞ¼Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ñ. ĞĞ¾ Ğ¼Ñ‹ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ·Ğ½Ğ°ĞµĞ¼, Ñ‡Ñ‚Ğ¾ {name} â€” Ğ·Ğ°Ğ¼ĞµÑ‡Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞº, Ğ¸ Ğ¶ĞµĞ»Ğ°ĞµĞ¼ ĞµĞ¼Ñƒ Ğ¾Ğ³Ñ€Ğ¾Ğ¼Ğ½Ñ‹Ñ… ÑƒÑĞ¿ĞµÑ…Ğ¾Ğ² Ğ²Ğ¾ Ğ²ÑĞµÑ… Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°Ğ½Ğ¸ÑÑ…!"


# ----------------------
# 5. ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° Ğ¸ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´ Ğ½Ğ° Streamlit
# ----------------------
def main():
    st.set_page_config(layout="wide", page_title="ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¹")
    st.title("Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¹ ÑƒÑ‡Ğ°Ñ‰Ğ¸Ñ…ÑÑ")

    with st.expander("â„¹ï¸ Ğ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğµ: Ñ‡Ñ‚Ğ¾ ÑÑ‚Ğ¾ Ğ¸ ĞºĞ°Ğº Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ?", expanded=False):
        st.markdown("""**Ğ¦ĞµĞ»ÑŒ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´Ğ°** â€” Ğ¿Ğ¾Ğ¼Ğ¾Ñ‡ÑŒ Ğ¿ĞµĞ´Ğ°Ğ³Ğ¾Ğ³Ğ°Ğ¼ Ğ¸ ĞºÑƒÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°Ğ¼ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾ Ğ¾Ñ†ĞµĞ½Ğ¸Ñ‚ÑŒ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ³Ñ€ÑƒĞ¿Ğ¿Ñ‹, Ğ²Ñ‹ÑĞ²Ğ¸Ñ‚ÑŒ Ğ¾Ğ±Ñ‰Ğ¸Ğµ Ñ‚ĞµĞ½Ğ´ĞµĞ½Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ÑŒ ÑƒÑ‡Ğ°Ñ‰Ğ¸Ñ…ÑÑ, Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ñ… Ğ¾ÑĞ¾Ğ±Ğ¾Ğ³Ğ¾ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ, Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¸Ñ… Ğ¿Ğ¸ÑÑŒĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¹.""")

    # --- Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ² ---
    supabase = init_supabase_client()
    if not supabase:
        st.stop()
    try:
        api_key = st.secrets["DEEPSEEK_API_KEY"]
        client = AsyncOpenAI(base_url=DEESEEK_API_URL, api_key=api_key)
    except KeyError:
        st.error("ĞÑˆĞ¸Ğ±ĞºĞ° ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸: Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ ĞºĞ»ÑÑ‡ `DEEPSEEK_API_KEY` Ğ² ÑĞµĞºÑ€ĞµÑ‚Ğ°Ñ… Streamlit.")
        st.stop()

    # --- Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ---
    st.sidebar.header("ğŸ—‚ï¸ Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…")
    report_files = get_report_list_from_supabase(supabase)
    data_source_options = ["ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·"] + report_files
    selected_source = st.sidebar.selectbox("Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ¾Ñ‚Ñ‡ĞµÑ‚ Ğ¸Ğ»Ğ¸ Ğ½Ğ°Ñ‡Ğ½Ğ¸Ñ‚Ğµ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·:", data_source_options)

    df = None
    if selected_source != "ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·":
        df = load_report_from_supabase(supabase, selected_source)
        st.session_state['current_file_name'] = selected_source
    else:
        uploaded_file = st.sidebar.file_uploader("Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ Excel-Ñ„Ğ°Ğ¹Ğ»:", type="xlsx")
        if uploaded_file:
            st.session_state['current_file_name'] = uploaded_file.name
            df = load_data(uploaded_file)
            if 'text' in df.columns:
                df['text'] = df['text'].astype(str).fillna('')

    if df is None:
        st.info("ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ Ñ„Ğ°Ğ¹Ğ» Ğ¸Ğ»Ğ¸ Ğ²Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ¾Ñ‚Ñ‡ĞµÑ‚ Ğ² Ğ±Ğ¾ĞºĞ¾Ğ²Ğ¾Ğ¹ Ğ¿Ğ°Ğ½ĞµĞ»Ğ¸.")
        st.stop()

    # --- ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¸ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ---
    session_key = f"df_processed_{st.session_state.get('current_file_name', 'default')}"
    if session_key not in st.session_state:
        if selected_source == "ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·":
            with st.spinner('Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ÑÑ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¹... Ğ­Ñ‚Ğ¾ Ğ·Ğ°Ğ¹Ğ¼ĞµÑ‚ Ğ½ĞµĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğµ Ğ²Ñ€ĞµĞ¼Ñ.'):
                tasks = [analyze_reflection_with_deepseek(client, text) for text in df['text']]
                # Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ˜Ğ•: Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğ¹ asyncio.run
                results = asyncio.run(asyncio.gather(*tasks))
                results_df = pd.DataFrame(results)
                df = pd.concat([df.reset_index(drop=True), results_df.reset_index(drop=True)], axis=1)

        for col in ['sentiment_score', 'learning_sentiment_score', 'teamwork_sentiment_score', 'organization_sentiment_score']:
            if col in df.columns:
                df[col.replace('_score', '_10_point')] = df[col].apply(convert_sentiment_to_10_point)
        st.session_state[session_key] = df
    
    df = st.session_state[session_key]

    # --- Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹ ---
    st.sidebar.header("ğŸ“Š Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹")
    filtered_df = df.copy()
    if 'data' in filtered_df.columns and not filtered_df['data'].dropna().empty:
        min_date, max_date = filtered_df['data'].min().date(), filtered_df['data'].max().date()
        if min_date != max_date:
            start_date, end_date = st.sidebar.slider("Ğ”Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ Ğ´Ğ°Ñ‚:", min_value=min_date, max_value=max_date, value=(min_date, max_date))
            mask = (filtered_df['data'].dt.date >= start_date) & (filtered_df['data'].dt.date <= end_date)
            filtered_df = filtered_df.loc[mask]

    if filtered_df.empty:
        st.warning("ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ñ‹Ğ¼ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ğ¼.")
        st.stop()

    # --- Ğ‘Ğ›ĞĞš ĞœĞĞ¡Ğ¡ĞĞ’ĞĞ™ Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ˜ Ğ˜ Ğ¡ĞšĞĞ§Ğ˜Ğ’ĞĞĞ˜Ğ¯ ---
    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ“ Ğ’Ñ‹Ğ¿ÑƒÑĞºĞ½Ñ‹Ğµ Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»Ñ‹")
    if st.sidebar.button("Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸ Ğ´Ğ»Ñ Ğ²ÑĞµÑ…"):
        unique_students = filtered_df['username'].unique()
        
        async def generate_all_creative_content():
            tasks = []
            for student_name in unique_students:
                student_reflections = " ".join(filtered_df[filtered_df['username'] == student_name]['text'].dropna().astype(str))
                tasks.append(generate_nomination_with_llm(client, student_reflections))
                tasks.append(generate_character_description_with_llm(client, student_name, student_reflections))
            
            all_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            final_data = []
            for i, student_name in enumerate(unique_students):
                nomination, description = all_results[i*2], all_results[i*2 + 1]
                final_data.append({
                    "Ğ£Ñ‡ĞµĞ½Ğ¸Ğº": student_name,
                    "ĞĞ¾Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ": "ĞÑˆĞ¸Ğ±ĞºĞ°" if isinstance(nomination, Exception) else nomination,
                    "Ğ¥Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ°": f"ĞÑˆĞ¸Ğ±ĞºĞ°: {description}" if isinstance(description, Exception) else description,
                })
            return pd.DataFrame(final_data)

        with st.sidebar.spinner(f"Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ° Ğ´Ğ»Ñ {len(unique_students)} ÑƒÑ‡ĞµĞ½Ğ¸ĞºĞ¾Ğ²..."):
            # Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ˜Ğ•: Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğ¹ asyncio.run
            creative_df = asyncio.run(generate_all_creative_content())
            if not creative_df.empty:
                st.session_state['downloadable_excel'] = to_excel(creative_df)
                st.session_state['excel_filename'] = f"Ğ¥Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸_{datetime.now().strftime('%Y-%m-%d')}.xlsx"
                st.sidebar.success("Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾! Ğ¤Ğ°Ğ¹Ğ» Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ ÑĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ.")
            else:
                st.sidebar.error("ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ.")

    if 'downloadable_excel' in st.session_state:
        st.sidebar.download_button(
            label="ğŸ“¥ Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ñ„Ğ°Ğ¹Ğ» Excel",
            data=st.session_state['downloadable_excel'],
            file_name=st.session_state['excel_filename'],
            mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )

    # --- ĞĞ¡ĞĞĞ’ĞĞĞ™ ĞšĞĞĞ¢Ğ•ĞĞ¢ Ğ”ĞĞ¨Ğ‘ĞĞ Ğ”Ğ ---
    st.header("ĞĞ±Ñ‰Ğ°Ñ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ° Ğ¸ Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ¾Ğ²Ğ¾Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·")
    # ... (Ğ·Ğ´ĞµÑÑŒ Ğ²Ğ°Ñˆ ĞºĞ¾Ğ´ Ğ´Ğ»Ñ Ğ¾Ñ‚Ñ€Ğ¸ÑĞ¾Ğ²ĞºĞ¸ Ğ¾Ğ±Ñ‰Ğ¸Ñ… Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¾Ğ² Ğ¸ Ñ‚ĞµĞ¿Ğ»Ğ¾Ğ²Ğ¾Ğ¹ ĞºĞ°Ñ€Ñ‚Ñ‹)

    st.header("ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ğ¾ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğ¼ ÑƒÑ‡Ğ°Ñ‰Ğ¸Ğ¼ÑÑ")
    student_list = sorted(filtered_df['username'].unique())
    if student_list:
        student = st.selectbox("Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ ÑƒÑ‡ĞµĞ½Ğ¸ĞºĞ°:", student_list)
        if student:
            student_df = filtered_df[filtered_df['username'] == student].sort_values('data')
            # ... (Ğ·Ğ´ĞµÑÑŒ Ğ²Ğ°Ñˆ ĞºĞ¾Ğ´ Ğ´Ğ»Ñ Ğ¾Ñ‚Ñ€Ğ¸ÑĞ¾Ğ²ĞºĞ¸ Ğ¸Ğ½Ğ´Ğ¸Ğ²Ğ¸Ğ´ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¾Ğ² ÑƒÑ‡ĞµĞ½Ğ¸ĞºĞ°)

            # --- Ğ‘Ğ›ĞĞš Ğ˜ĞĞ”Ğ˜Ğ’Ğ˜Ğ”Ğ£ĞĞ›Ğ¬ĞĞĞ™ Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ˜ ---
            st.markdown("---")
            st.subheader(f"âœ¨ ĞšÑ€ĞµĞ°Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ´Ğ»Ñ {student}")
            full_reflection_text = " ".join(student_df['text'].dropna().astype(str))
            if st.button(f"Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ´Ğ»Ñ {student}"):
                with st.spinner("ĞœĞ°Ğ³Ğ¸Ñ Ñ‚Ğ²Ğ¾Ñ€Ğ¸Ñ‚ÑÑ..."):
                    async def get_content():
                        return await asyncio.gather(
                            generate_nomination_with_llm(client, full_reflection_text),
                            generate_character_description_with_llm(client, student, full_reflection_text)
                        )
                    # Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ˜Ğ•: Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğ¹ asyncio.run
                    nomination, description = asyncio.run(get_content())
                    st.session_state[f'nomination_{student}'] = nomination
                    st.session_state[f'description_{student}'] = description

            if f'nomination_{student}' in st.session_state:
                st.success(f"**ĞĞ¾Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ:** {st.session_state[f'nomination_{student}']}")
            if f'description_{student}' in st.session_state:
                st.markdown(st.session_state[f'description_{student}'])
            
            st.markdown("---")
            st.subheader("Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¹")
            # ... (Ğ·Ğ´ĞµÑÑŒ Ğ²Ğ°Ñˆ ĞºĞ¾Ğ´ Ğ´Ğ»Ñ expander Ğ¸ st.dataframe Ñ Ğ´ĞµÑ‚Ğ°Ğ»ÑĞ¼Ğ¸ Ğ¿Ğ¾ ÑƒÑ‡ĞµĞ½Ğ¸ĞºÑƒ)

    # ... (Ğ·Ğ´ĞµÑÑŒ Ğ²Ğ°Ñˆ ĞºĞ¾Ğ´ Ğ´Ğ»Ñ Ğ·Ğ¾Ğ½Ñ‹ Ñ€Ğ¸ÑĞºĞ° Ğ¸ Ñ‚.Ğ´.)


# ----------------------
# 6. Ğ¢Ğ¾Ñ‡ĞºĞ° Ğ²Ñ…Ğ¾Ğ´Ğ° Ğ² Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ
# ----------------------
if __name__ == "__main__":
    main()
